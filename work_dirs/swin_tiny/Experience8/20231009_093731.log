2023-10-09 09:37:32,043 - mmcls - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.17 | packaged by conda-forge | (default, Jun 16 2023, 07:06:00) [GCC 11.4.0]
CUDA available: True
GPU 0: NVIDIA GeForce RTX 3090
CUDA_HOME: /usr/local/cuda-11.6
NVCC: Build cuda_11.6.r11.6/compiler.31057947_0
GCC: gcc (GCC) 7.3.0
PyTorch: 1.8.0+cu111
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.7.0 (Git Hash 7aed236906b1f7a05c0917e5257a1af05e9ff683)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.8.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.9.0+cu111
OpenCV: 4.8.0
MMCV: 1.4.2
MMCV Compiler: n/a
MMCV CUDA Compiler: n/a
MMClassification: 0.24.0+
------------------------------------------------------------

2023-10-09 09:37:32,044 - mmcls - INFO - Distributed training: False
2023-10-09 09:37:33,126 - mmcls - INFO - Config:
model = dict(
    type='ImageClassifier',
    backbone=dict(
        type='SwinTransformer',
        arch='tiny',
        init_cfg=dict(
            type='Pretrained',
            checkpoint=
            '/data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth',
            prefix='backbone'),
        img_size=224,
        drop_path_rate=0.2),
    neck=dict(type='GlobalAveragePooling'),
    head=dict(
        type='LinearClsHead',
        num_classes=46,
        in_channels=768,
        init_cfg=None,
        loss=dict(
            type='LabelSmoothLoss',
            label_smooth_val=0.1,
            mode='original',
            loss_weight=[
                0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
                1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1.2, 1,
                1, 1, 1, 1, 1, 1
            ]),
        cal_acc=False),
    init_cfg=[
        dict(type='TruncNormal', layer='Linear', std=0.02, bias=0.0),
        dict(type='Constant', layer='LayerNorm', val=1.0, bias=0.0)
    ],
    train_cfg=dict(augments=[
        dict(type='BatchMixup', alpha=0.8, num_classes=46, prob=0.5),
        dict(type='BatchCutMix', alpha=1.0, num_classes=46, prob=0.5)
    ]))
rand_increasing_policies = [
    dict(type='AutoContrast'),
    dict(type='Equalize'),
    dict(type='Invert'),
    dict(type='Rotate', magnitude_key='angle', magnitude_range=(0, 90)),
    dict(type='Posterize', magnitude_key='bits', magnitude_range=(4, 0)),
    dict(type='Solarize', magnitude_key='thr', magnitude_range=(256, 0)),
    dict(
        type='SolarizeAdd',
        magnitude_key='magnitude',
        magnitude_range=(0, 110)),
    dict(
        type='ColorTransform',
        magnitude_key='magnitude',
        magnitude_range=(0, 0.9)),
    dict(type='Contrast', magnitude_key='magnitude', magnitude_range=(0, 0.9)),
    dict(
        type='Brightness', magnitude_key='magnitude',
        magnitude_range=(0, 0.9)),
    dict(
        type='Sharpness', magnitude_key='magnitude', magnitude_range=(0, 0.9)),
    dict(
        type='Shear',
        magnitude_key='magnitude',
        magnitude_range=(0, 0.3),
        direction='horizontal'),
    dict(
        type='Shear',
        magnitude_key='magnitude',
        magnitude_range=(0, 0.3),
        direction='vertical'),
    dict(
        type='Translate',
        magnitude_key='magnitude',
        magnitude_range=(0, 0.45),
        direction='horizontal'),
    dict(
        type='Translate',
        magnitude_key='magnitude',
        magnitude_range=(0, 0.45),
        direction='vertical')
]
dataset_type = 'CustomDataset'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='RandomFlip', flip_prob=0.5, direction='horizontal'),
    dict(
        type='RandAugment',
        policies=[
            dict(type='AutoContrast'),
            dict(type='Equalize'),
            dict(type='Invert'),
            dict(
                type='Rotate', magnitude_key='angle', magnitude_range=(0, 90)),
            dict(
                type='Posterize', magnitude_key='bits',
                magnitude_range=(4, 0)),
            dict(
                type='Solarize', magnitude_key='thr',
                magnitude_range=(256, 0)),
            dict(
                type='SolarizeAdd',
                magnitude_key='magnitude',
                magnitude_range=(0, 110)),
            dict(
                type='ColorTransform',
                magnitude_key='magnitude',
                magnitude_range=(0, 0.9)),
            dict(
                type='Contrast',
                magnitude_key='magnitude',
                magnitude_range=(0, 0.9)),
            dict(
                type='Brightness',
                magnitude_key='magnitude',
                magnitude_range=(0, 0.9)),
            dict(
                type='Sharpness',
                magnitude_key='magnitude',
                magnitude_range=(0, 0.9)),
            dict(
                type='Shear',
                magnitude_key='magnitude',
                magnitude_range=(0, 0.5),
                direction='horizontal'),
            dict(
                type='Shear',
                magnitude_key='magnitude',
                magnitude_range=(0, 0.5),
                direction='vertical'),
            dict(
                type='Translate',
                magnitude_key='magnitude',
                magnitude_range=(0, 0.45),
                direction='horizontal'),
            dict(
                type='Translate',
                magnitude_key='magnitude',
                magnitude_range=(0, 0.45),
                direction='vertical')
        ],
        num_policies=2,
        total_level=10,
        magnitude_level=9,
        magnitude_std=0.5,
        hparams=dict(pad_val=[104, 116, 124], interpolation='bicubic')),
    dict(
        type='RandomErasing',
        erase_prob=0.25,
        mode='rand',
        min_area_ratio=0.02,
        max_area_ratio=0.3333333333333333,
        fill_color=[103.53, 116.28, 123.675],
        fill_std=[57.375, 57.12, 58.395]),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='ImageToTensor', keys=['img']),
    dict(type='ToTensor', keys=['gt_label']),
    dict(type='Collect', keys=['img', 'gt_label'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='ImageToTensor', keys=['img']),
    dict(type='Collect', keys=['img'])
]
data = dict(
    samples_per_gpu=60,
    workers_per_gpu=4,
    train=dict(
        type='CustomDataset',
        data_prefix='/data4/lj/Dataset/JML/Experience3/Benchmark',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='Jie_Pad', pad_size_h=224, pad_size_w=224),
            dict(type='RandomFlip', flip_prob=0.5, direction='horizontal'),
            dict(
                type='RandAugment',
                policies=[
                    dict(type='AutoContrast'),
                    dict(type='Equalize'),
                    dict(type='Invert'),
                    dict(
                        type='Rotate',
                        magnitude_key='angle',
                        magnitude_range=(0, 180)),
                    dict(
                        type='Posterize',
                        magnitude_key='bits',
                        magnitude_range=(4, 0)),
                    dict(
                        type='Solarize',
                        magnitude_key='thr',
                        magnitude_range=(256, 0)),
                    dict(
                        type='SolarizeAdd',
                        magnitude_key='magnitude',
                        magnitude_range=(0, 110)),
                    dict(
                        type='ColorTransform',
                        magnitude_key='magnitude',
                        magnitude_range=(0, 0.9)),
                    dict(
                        type='Contrast',
                        magnitude_key='magnitude',
                        magnitude_range=(0, 0.9)),
                    dict(
                        type='Brightness',
                        magnitude_key='magnitude',
                        magnitude_range=(0, 0.9)),
                    dict(
                        type='Sharpness',
                        magnitude_key='magnitude',
                        magnitude_range=(0, 0.9)),
                    dict(
                        type='Shear',
                        magnitude_key='magnitude',
                        magnitude_range=(0, 0.7),
                        direction='horizontal'),
                    dict(
                        type='Shear',
                        magnitude_key='magnitude',
                        magnitude_range=(0, 0.7),
                        direction='vertical'),
                    dict(
                        type='Translate',
                        magnitude_key='magnitude',
                        magnitude_range=(0, 0.45),
                        direction='horizontal'),
                    dict(
                        type='Translate',
                        magnitude_key='magnitude',
                        magnitude_range=(0, 0.45),
                        direction='vertical')
                ],
                num_policies=2,
                total_level=10,
                magnitude_level=9,
                magnitude_std=0.5,
                hparams=dict(pad_val=[104, 116, 124],
                             interpolation='bicubic')),
            dict(
                type='RandomErasing',
                erase_prob=0.25,
                mode='rand',
                min_area_ratio=0.02,
                max_area_ratio=0.3333333333333333,
                fill_color=[103.53, 116.28, 123.675],
                fill_std=[57.375, 57.12, 58.395]),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='ToTensor', keys=['gt_label']),
            dict(type='Collect', keys=['img', 'gt_label'])
        ]),
    val=dict(
        type='CustomDataset',
        data_prefix='/data4/lj/Dataset/JML/Integrate_test',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='Jie_Pad', pad_size_h=224, pad_size_w=224),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ]),
    test=dict(
        type='CustomDataset',
        data_prefix='/data4/lj/Dataset/JML/Integrate_test',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='Jie_Pad', pad_size_h=224, pad_size_w=224),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ]))
evaluation = dict(interval=10, metric='accuracy')
paramwise_cfg = dict(
    norm_decay_mult=0.0,
    bias_decay_mult=0.0,
    custom_keys=dict({
        '.absolute_pos_embed': dict(decay_mult=0.0),
        '.relative_position_bias_table': dict(decay_mult=0.0)
    }))
optimizer = dict(
    type='AdamW',
    lr=0.001,
    weight_decay=0.05,
    eps=1e-08,
    betas=(0.9, 0.999),
    paramwise_cfg=dict(
        norm_decay_mult=0.0,
        bias_decay_mult=0.0,
        custom_keys=dict({
            '.absolute_pos_embed': dict(decay_mult=0.0),
            '.relative_position_bias_table': dict(decay_mult=0.0)
        })))
optimizer_config = dict(grad_clip=dict(max_norm=5.0))
lr_config = dict(
    policy='CosineAnnealing',
    by_epoch=False,
    min_lr_ratio=0.01,
    warmup='linear',
    warmup_ratio=0.001,
    warmup_iters=20,
    warmup_by_epoch=True)
runner = dict(type='EpochBasedRunner', max_epochs=150)
checkpoint_config = dict(interval=30, save_optimizer=True)
log_config = dict(interval=100, hooks=[dict(type='TextLoggerHook')])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
work_dir = '/data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience8'
gpu_ids = [0]

2023-10-09 09:37:33,127 - mmcls - INFO - Set random seed to 1791085802, deterministic: False
2023-10-09 09:37:37,958 - mmcls - INFO - initialize ImageClassifier with init_cfg [{'type': 'TruncNormal', 'layer': 'Linear', 'std': 0.02, 'bias': 0.0}, {'type': 'Constant', 'layer': 'LayerNorm', 'val': 1.0, 'bias': 0.0}]
2023-10-09 09:37:38,242 - mmcls - INFO - initialize SwinTransformer with init_cfg {'type': 'Pretrained', 'checkpoint': '/data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth', 'prefix': 'backbone'}
2023-10-09 09:40:06,976 - mmcls - INFO - Resize the relative_position_bias_table from torch.Size([49, 3]) to torch.Size([169, 3])
2023-10-09 09:40:06,978 - mmcls - INFO - Resize the relative_position_bias_table from torch.Size([49, 3]) to torch.Size([169, 3])
2023-10-09 09:40:06,981 - mmcls - INFO - Resize the relative_position_bias_table from torch.Size([49, 6]) to torch.Size([169, 6])
2023-10-09 09:40:06,984 - mmcls - INFO - Resize the relative_position_bias_table from torch.Size([49, 6]) to torch.Size([169, 6])
2023-10-09 09:40:06,989 - mmcls - INFO - Resize the relative_position_bias_table from torch.Size([49, 12]) to torch.Size([169, 12])
2023-10-09 09:40:06,994 - mmcls - INFO - Resize the relative_position_bias_table from torch.Size([49, 12]) to torch.Size([169, 12])
2023-10-09 09:40:06,998 - mmcls - INFO - Resize the relative_position_bias_table from torch.Size([49, 12]) to torch.Size([169, 12])
2023-10-09 09:40:07,003 - mmcls - INFO - Resize the relative_position_bias_table from torch.Size([49, 12]) to torch.Size([169, 12])
2023-10-09 09:40:07,007 - mmcls - INFO - Resize the relative_position_bias_table from torch.Size([49, 12]) to torch.Size([169, 12])
2023-10-09 09:40:07,011 - mmcls - INFO - Resize the relative_position_bias_table from torch.Size([49, 12]) to torch.Size([169, 12])
2023-10-09 09:40:07,018 - mmcls - INFO - Resize the relative_position_bias_table from torch.Size([49, 24]) to torch.Size([169, 24])
2023-10-09 09:40:07,025 - mmcls - INFO - Resize the relative_position_bias_table from torch.Size([49, 24]) to torch.Size([169, 24])
Name of parameter - Initialization information

backbone.patch_embed.projection.weight - torch.Size([96, 3, 4, 4]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.patch_embed.projection.bias - torch.Size([96]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.patch_embed.norm.weight - torch.Size([96]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.patch_embed.norm.bias - torch.Size([96]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.0.blocks.0.norm1.weight - torch.Size([96]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.0.blocks.0.norm1.bias - torch.Size([96]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([169, 3]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.0.blocks.0.attn.w_msa.qkv.weight - torch.Size([288, 96]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.0.blocks.0.attn.w_msa.qkv.bias - torch.Size([288]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.0.blocks.0.attn.w_msa.proj.weight - torch.Size([96, 96]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.0.blocks.0.attn.w_msa.proj.bias - torch.Size([96]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.0.blocks.0.norm2.weight - torch.Size([96]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.0.blocks.0.norm2.bias - torch.Size([96]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.0.blocks.0.ffn.layers.0.0.weight - torch.Size([384, 96]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.0.blocks.0.ffn.layers.0.0.bias - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.0.blocks.0.ffn.layers.1.weight - torch.Size([96, 384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.0.blocks.0.ffn.layers.1.bias - torch.Size([96]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.0.blocks.1.norm1.weight - torch.Size([96]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.0.blocks.1.norm1.bias - torch.Size([96]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([169, 3]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.0.blocks.1.attn.w_msa.qkv.weight - torch.Size([288, 96]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.0.blocks.1.attn.w_msa.qkv.bias - torch.Size([288]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.0.blocks.1.attn.w_msa.proj.weight - torch.Size([96, 96]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.0.blocks.1.attn.w_msa.proj.bias - torch.Size([96]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.0.blocks.1.norm2.weight - torch.Size([96]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.0.blocks.1.norm2.bias - torch.Size([96]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.0.blocks.1.ffn.layers.0.0.weight - torch.Size([384, 96]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.0.blocks.1.ffn.layers.0.0.bias - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.0.blocks.1.ffn.layers.1.weight - torch.Size([96, 384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.0.blocks.1.ffn.layers.1.bias - torch.Size([96]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.0.downsample.norm.weight - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.0.downsample.norm.bias - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.0.downsample.reduction.weight - torch.Size([192, 384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.1.blocks.0.norm1.weight - torch.Size([192]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.1.blocks.0.norm1.bias - torch.Size([192]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([169, 6]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.1.blocks.0.attn.w_msa.qkv.weight - torch.Size([576, 192]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.1.blocks.0.attn.w_msa.qkv.bias - torch.Size([576]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.1.blocks.0.attn.w_msa.proj.weight - torch.Size([192, 192]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.1.blocks.0.attn.w_msa.proj.bias - torch.Size([192]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.1.blocks.0.norm2.weight - torch.Size([192]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.1.blocks.0.norm2.bias - torch.Size([192]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.1.blocks.0.ffn.layers.0.0.weight - torch.Size([768, 192]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.1.blocks.0.ffn.layers.0.0.bias - torch.Size([768]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.1.blocks.0.ffn.layers.1.weight - torch.Size([192, 768]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.1.blocks.0.ffn.layers.1.bias - torch.Size([192]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.1.blocks.1.norm1.weight - torch.Size([192]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.1.blocks.1.norm1.bias - torch.Size([192]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([169, 6]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.1.blocks.1.attn.w_msa.qkv.weight - torch.Size([576, 192]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.1.blocks.1.attn.w_msa.qkv.bias - torch.Size([576]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.1.blocks.1.attn.w_msa.proj.weight - torch.Size([192, 192]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.1.blocks.1.attn.w_msa.proj.bias - torch.Size([192]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.1.blocks.1.norm2.weight - torch.Size([192]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.1.blocks.1.norm2.bias - torch.Size([192]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.1.blocks.1.ffn.layers.0.0.weight - torch.Size([768, 192]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.1.blocks.1.ffn.layers.0.0.bias - torch.Size([768]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.1.blocks.1.ffn.layers.1.weight - torch.Size([192, 768]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.1.blocks.1.ffn.layers.1.bias - torch.Size([192]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.1.downsample.norm.weight - torch.Size([768]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.1.downsample.norm.bias - torch.Size([768]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.1.downsample.reduction.weight - torch.Size([384, 768]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.0.norm1.weight - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.0.norm1.bias - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.0.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.0.attn.w_msa.qkv.bias - torch.Size([1152]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.0.attn.w_msa.proj.weight - torch.Size([384, 384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.0.attn.w_msa.proj.bias - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.0.norm2.weight - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.0.norm2.bias - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.0.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.0.ffn.layers.0.0.bias - torch.Size([1536]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.0.ffn.layers.1.weight - torch.Size([384, 1536]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.0.ffn.layers.1.bias - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.1.norm1.weight - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.1.norm1.bias - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.1.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.1.attn.w_msa.qkv.bias - torch.Size([1152]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.1.attn.w_msa.proj.weight - torch.Size([384, 384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.1.attn.w_msa.proj.bias - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.1.norm2.weight - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.1.norm2.bias - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.1.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.1.ffn.layers.0.0.bias - torch.Size([1536]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.1.ffn.layers.1.weight - torch.Size([384, 1536]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.1.ffn.layers.1.bias - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.2.norm1.weight - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.2.norm1.bias - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.2.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.2.attn.w_msa.qkv.bias - torch.Size([1152]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.2.attn.w_msa.proj.weight - torch.Size([384, 384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.2.attn.w_msa.proj.bias - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.2.norm2.weight - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.2.norm2.bias - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.2.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.2.ffn.layers.0.0.bias - torch.Size([1536]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.2.ffn.layers.1.weight - torch.Size([384, 1536]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.2.ffn.layers.1.bias - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.3.norm1.weight - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.3.norm1.bias - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.3.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.3.attn.w_msa.qkv.bias - torch.Size([1152]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.3.attn.w_msa.proj.weight - torch.Size([384, 384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.3.attn.w_msa.proj.bias - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.3.norm2.weight - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.3.norm2.bias - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.3.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.3.ffn.layers.0.0.bias - torch.Size([1536]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.3.ffn.layers.1.weight - torch.Size([384, 1536]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.3.ffn.layers.1.bias - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.4.norm1.weight - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.4.norm1.bias - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.4.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.4.attn.w_msa.qkv.bias - torch.Size([1152]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.4.attn.w_msa.proj.weight - torch.Size([384, 384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.4.attn.w_msa.proj.bias - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.4.norm2.weight - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.4.norm2.bias - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.4.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.4.ffn.layers.0.0.bias - torch.Size([1536]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.4.ffn.layers.1.weight - torch.Size([384, 1536]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.4.ffn.layers.1.bias - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.5.norm1.weight - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.5.norm1.bias - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.5.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.5.attn.w_msa.qkv.bias - torch.Size([1152]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.5.attn.w_msa.proj.weight - torch.Size([384, 384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.5.attn.w_msa.proj.bias - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.5.norm2.weight - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.5.norm2.bias - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.5.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.5.ffn.layers.0.0.bias - torch.Size([1536]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.5.ffn.layers.1.weight - torch.Size([384, 1536]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.5.ffn.layers.1.bias - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.downsample.norm.weight - torch.Size([1536]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.downsample.norm.bias - torch.Size([1536]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.downsample.reduction.weight - torch.Size([768, 1536]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.3.blocks.0.norm1.weight - torch.Size([768]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.3.blocks.0.norm1.bias - torch.Size([768]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([169, 24]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.3.blocks.0.attn.w_msa.qkv.weight - torch.Size([2304, 768]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.3.blocks.0.attn.w_msa.qkv.bias - torch.Size([2304]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.3.blocks.0.attn.w_msa.proj.weight - torch.Size([768, 768]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.3.blocks.0.attn.w_msa.proj.bias - torch.Size([768]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.3.blocks.0.norm2.weight - torch.Size([768]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.3.blocks.0.norm2.bias - torch.Size([768]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.3.blocks.0.ffn.layers.0.0.weight - torch.Size([3072, 768]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.3.blocks.0.ffn.layers.0.0.bias - torch.Size([3072]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.3.blocks.0.ffn.layers.1.weight - torch.Size([768, 3072]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.3.blocks.0.ffn.layers.1.bias - torch.Size([768]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.3.blocks.1.norm1.weight - torch.Size([768]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.3.blocks.1.norm1.bias - torch.Size([768]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([169, 24]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.3.blocks.1.attn.w_msa.qkv.weight - torch.Size([2304, 768]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.3.blocks.1.attn.w_msa.qkv.bias - torch.Size([2304]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.3.blocks.1.attn.w_msa.proj.weight - torch.Size([768, 768]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.3.blocks.1.attn.w_msa.proj.bias - torch.Size([768]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.3.blocks.1.norm2.weight - torch.Size([768]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.3.blocks.1.norm2.bias - torch.Size([768]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.3.blocks.1.ffn.layers.0.0.weight - torch.Size([3072, 768]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.3.blocks.1.ffn.layers.0.0.bias - torch.Size([3072]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.3.blocks.1.ffn.layers.1.weight - torch.Size([768, 3072]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.3.blocks.1.ffn.layers.1.bias - torch.Size([768]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.norm3.weight - torch.Size([768]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.norm3.bias - torch.Size([768]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

head.fc.weight - torch.Size([46, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

head.fc.bias - torch.Size([46]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 
2023-10-09 09:40:10,168 - mmcls - INFO - Start running, host: root@8F-02-37u-AItest29, work_dir: /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience8
2023-10-09 09:40:10,169 - mmcls - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2023-10-09 09:40:10,170 - mmcls - INFO - workflow: [('train', 1)], max: 150 epochs
2023-10-09 09:40:10,171 - mmcls - INFO - Checkpoints will be saved to /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience8 by HardDiskBackend.
2023-10-09 09:41:02,121 - mmcls - INFO - Epoch [1][100/671]	lr: 8.370e-06, eta: 14:30:29, time: 0.519, data_time: 0.030, memory: 7111, loss: 3.5689, grad_norm: 2.9311
2023-10-09 09:41:50,277 - mmcls - INFO - Epoch [1][200/671]	lr: 1.581e-05, eta: 13:57:54, time: 0.482, data_time: 0.002, memory: 7111, loss: 2.7791, grad_norm: 3.8482
2023-10-09 09:42:38,653 - mmcls - INFO - Epoch [1][300/671]	lr: 2.326e-05, eta: 13:47:43, time: 0.484, data_time: 0.001, memory: 7111, loss: 2.5910, grad_norm: 2.8238
2023-10-09 09:43:24,818 - mmcls - INFO - Epoch [1][400/671]	lr: 3.070e-05, eta: 13:33:01, time: 0.462, data_time: 0.001, memory: 7111, loss: 2.5574, grad_norm: 2.8343
2023-10-09 09:44:13,039 - mmcls - INFO - Epoch [1][500/671]	lr: 3.814e-05, eta: 13:30:44, time: 0.482, data_time: 0.001, memory: 7111, loss: 2.4349, grad_norm: 3.1522
2023-10-09 09:45:01,066 - mmcls - INFO - Epoch [1][600/671]	lr: 4.559e-05, eta: 13:28:24, time: 0.480, data_time: 0.001, memory: 7111, loss: 2.3168, grad_norm: 3.5156
2023-10-09 09:46:26,733 - mmcls - INFO - Epoch [2][100/671]	lr: 5.831e-05, eta: 12:18:34, time: 0.512, data_time: 0.027, memory: 7111, loss: 2.1406, grad_norm: 3.8319
2023-10-09 09:47:15,107 - mmcls - INFO - Epoch [2][200/671]	lr: 6.575e-05, eta: 12:25:29, time: 0.484, data_time: 0.001, memory: 7111, loss: 2.1089, grad_norm: 3.5341
2023-10-09 09:48:03,316 - mmcls - INFO - Epoch [2][300/671]	lr: 7.319e-05, eta: 12:30:31, time: 0.482, data_time: 0.001, memory: 7111, loss: 2.0687, grad_norm: 3.3808
2023-10-09 09:48:49,573 - mmcls - INFO - Epoch [2][400/671]	lr: 8.063e-05, eta: 12:31:26, time: 0.463, data_time: 0.001, memory: 7111, loss: 2.0291, grad_norm: 3.1433
2023-10-09 09:49:38,035 - mmcls - INFO - Epoch [2][500/671]	lr: 8.807e-05, eta: 12:35:11, time: 0.485, data_time: 0.001, memory: 7111, loss: 1.9653, grad_norm: 3.0737
2023-10-09 09:50:26,485 - mmcls - INFO - Epoch [2][600/671]	lr: 9.550e-05, eta: 12:38:13, time: 0.484, data_time: 0.001, memory: 7111, loss: 1.9564, grad_norm: 3.0338
2023-10-09 09:51:52,057 - mmcls - INFO - Epoch [3][100/671]	lr: 1.082e-04, eta: 12:05:28, time: 0.509, data_time: 0.026, memory: 7111, loss: 1.8676, grad_norm: 2.9575
2023-10-09 09:52:40,511 - mmcls - INFO - Epoch [3][200/671]	lr: 1.156e-04, eta: 12:09:39, time: 0.485, data_time: 0.001, memory: 7111, loss: 1.8706, grad_norm: 3.0098
2023-10-09 09:53:29,325 - mmcls - INFO - Epoch [3][300/671]	lr: 1.231e-04, eta: 12:13:34, time: 0.488, data_time: 0.001, memory: 7111, loss: 1.8225, grad_norm: 2.7598
2023-10-09 09:54:15,151 - mmcls - INFO - Epoch [3][400/671]	lr: 1.305e-04, eta: 12:14:08, time: 0.458, data_time: 0.001, memory: 7111, loss: 1.8176, grad_norm: 2.7348
2023-10-09 09:55:03,162 - mmcls - INFO - Epoch [3][500/671]	lr: 1.379e-04, eta: 12:16:29, time: 0.480, data_time: 0.001, memory: 7111, loss: 1.7922, grad_norm: 2.7190
2023-10-09 09:55:51,453 - mmcls - INFO - Epoch [3][600/671]	lr: 1.454e-04, eta: 12:18:46, time: 0.483, data_time: 0.001, memory: 7111, loss: 1.8126, grad_norm: 2.6446
2023-10-09 09:57:17,081 - mmcls - INFO - Epoch [4][100/671]	lr: 1.580e-04, eta: 11:57:30, time: 0.511, data_time: 0.027, memory: 7111, loss: 1.8045, grad_norm: 2.5932
2023-10-09 09:58:05,458 - mmcls - INFO - Epoch [4][200/671]	lr: 1.655e-04, eta: 12:00:15, time: 0.484, data_time: 0.001, memory: 7111, loss: 1.7765, grad_norm: 2.4852
2023-10-09 09:58:53,850 - mmcls - INFO - Epoch [4][300/671]	lr: 1.729e-04, eta: 12:02:42, time: 0.484, data_time: 0.001, memory: 7111, loss: 1.7298, grad_norm: 2.5040
2023-10-09 09:59:40,067 - mmcls - INFO - Epoch [4][400/671]	lr: 1.803e-04, eta: 12:03:24, time: 0.462, data_time: 0.001, memory: 7111, loss: 1.7767, grad_norm: 2.4718
2023-10-09 10:00:28,401 - mmcls - INFO - Epoch [4][500/671]	lr: 1.877e-04, eta: 12:05:22, time: 0.483, data_time: 0.001, memory: 7111, loss: 1.7386, grad_norm: 2.4743
2023-10-09 10:01:16,733 - mmcls - INFO - Epoch [4][600/671]	lr: 1.951e-04, eta: 12:07:07, time: 0.483, data_time: 0.001, memory: 7111, loss: 1.7374, grad_norm: 2.4688
2023-10-09 10:02:42,264 - mmcls - INFO - Epoch [5][100/671]	lr: 2.078e-04, eta: 11:51:08, time: 0.510, data_time: 0.027, memory: 7111, loss: 1.7390, grad_norm: 2.3520
2023-10-09 10:03:30,662 - mmcls - INFO - Epoch [5][200/671]	lr: 2.152e-04, eta: 11:53:07, time: 0.484, data_time: 0.001, memory: 7111, loss: 1.6924, grad_norm: 2.4954
2023-10-09 10:04:18,994 - mmcls - INFO - Epoch [5][300/671]	lr: 2.226e-04, eta: 11:54:53, time: 0.483, data_time: 0.001, memory: 7111, loss: 1.7571, grad_norm: 2.4068
2023-10-09 10:05:05,158 - mmcls - INFO - Epoch [5][400/671]	lr: 2.300e-04, eta: 11:55:20, time: 0.462, data_time: 0.001, memory: 7111, loss: 1.6850, grad_norm: 2.2978
2023-10-09 10:05:53,878 - mmcls - INFO - Epoch [5][500/671]	lr: 2.374e-04, eta: 11:57:01, time: 0.487, data_time: 0.001, memory: 7111, loss: 1.7020, grad_norm: 2.3487
2023-10-09 10:06:42,490 - mmcls - INFO - Epoch [5][600/671]	lr: 2.448e-04, eta: 11:58:29, time: 0.486, data_time: 0.001, memory: 7111, loss: 1.7107, grad_norm: 2.3247
2023-10-09 10:08:08,438 - mmcls - INFO - Epoch [6][100/671]	lr: 2.574e-04, eta: 11:45:45, time: 0.512, data_time: 0.028, memory: 7111, loss: 1.7125, grad_norm: 2.3896
2023-10-09 10:08:57,112 - mmcls - INFO - Epoch [6][200/671]	lr: 2.648e-04, eta: 11:47:21, time: 0.487, data_time: 0.001, memory: 7111, loss: 1.7356, grad_norm: 2.1944
2023-10-09 10:09:45,837 - mmcls - INFO - Epoch [6][300/671]	lr: 2.721e-04, eta: 11:48:50, time: 0.487, data_time: 0.001, memory: 7111, loss: 1.6884, grad_norm: 2.1368
2023-10-09 10:10:32,106 - mmcls - INFO - Epoch [6][400/671]	lr: 2.795e-04, eta: 11:49:09, time: 0.463, data_time: 0.001, memory: 7111, loss: 1.7248, grad_norm: 2.1302
2023-10-09 10:11:20,753 - mmcls - INFO - Epoch [6][500/671]	lr: 2.869e-04, eta: 11:50:24, time: 0.486, data_time: 0.001, memory: 7111, loss: 1.6901, grad_norm: 2.0785
2023-10-09 10:12:09,364 - mmcls - INFO - Epoch [6][600/671]	lr: 2.942e-04, eta: 11:51:32, time: 0.486, data_time: 0.001, memory: 7111, loss: 1.6675, grad_norm: 2.1880
2023-10-09 10:13:35,670 - mmcls - INFO - Epoch [7][100/671]	lr: 3.068e-04, eta: 11:40:57, time: 0.516, data_time: 0.027, memory: 7111, loss: 1.6759, grad_norm: 2.1371
2023-10-09 10:14:24,224 - mmcls - INFO - Epoch [7][200/671]	lr: 3.142e-04, eta: 11:42:07, time: 0.486, data_time: 0.001, memory: 7111, loss: 1.6651, grad_norm: 2.2178
2023-10-09 10:15:13,469 - mmcls - INFO - Epoch [7][300/671]	lr: 3.215e-04, eta: 11:43:27, time: 0.492, data_time: 0.001, memory: 7111, loss: 1.6514, grad_norm: 2.1960
2023-10-09 10:15:59,715 - mmcls - INFO - Epoch [7][400/671]	lr: 3.288e-04, eta: 11:43:36, time: 0.462, data_time: 0.001, memory: 7111, loss: 1.6501, grad_norm: 2.0907
2023-10-09 10:16:48,558 - mmcls - INFO - Epoch [7][500/671]	lr: 3.362e-04, eta: 11:44:37, time: 0.488, data_time: 0.001, memory: 7111, loss: 1.6308, grad_norm: 2.0547
2023-10-09 10:17:37,155 - mmcls - INFO - Epoch [7][600/671]	lr: 3.435e-04, eta: 11:45:29, time: 0.486, data_time: 0.001, memory: 7111, loss: 1.6572, grad_norm: 2.1202
2023-10-09 10:19:03,421 - mmcls - INFO - Epoch [8][100/671]	lr: 3.560e-04, eta: 11:36:16, time: 0.515, data_time: 0.027, memory: 7111, loss: 1.6925, grad_norm: 2.1005
2023-10-09 10:19:52,100 - mmcls - INFO - Epoch [8][200/671]	lr: 3.634e-04, eta: 11:37:12, time: 0.487, data_time: 0.001, memory: 7111, loss: 1.6572, grad_norm: 2.0615
2023-10-09 10:20:40,953 - mmcls - INFO - Epoch [8][300/671]	lr: 3.707e-04, eta: 11:38:08, time: 0.489, data_time: 0.001, memory: 7111, loss: 1.6896, grad_norm: 2.0205
2023-10-09 10:21:27,107 - mmcls - INFO - Epoch [8][400/671]	lr: 3.780e-04, eta: 11:38:08, time: 0.462, data_time: 0.001, memory: 7111, loss: 1.6838, grad_norm: 2.0153
2023-10-09 10:22:15,905 - mmcls - INFO - Epoch [8][500/671]	lr: 3.853e-04, eta: 11:38:55, time: 0.488, data_time: 0.001, memory: 7111, loss: 1.6452, grad_norm: 1.9321
2023-10-09 10:23:04,639 - mmcls - INFO - Epoch [8][600/671]	lr: 3.926e-04, eta: 11:39:38, time: 0.487, data_time: 0.001, memory: 7111, loss: 1.7006, grad_norm: 1.9737
2023-10-09 10:24:31,100 - mmcls - INFO - Epoch [9][100/671]	lr: 4.050e-04, eta: 11:31:26, time: 0.514, data_time: 0.027, memory: 7111, loss: 1.6896, grad_norm: 1.9906
2023-10-09 10:25:19,821 - mmcls - INFO - Epoch [9][200/671]	lr: 4.123e-04, eta: 11:32:10, time: 0.487, data_time: 0.001, memory: 7111, loss: 1.6581, grad_norm: 1.9148
2023-10-09 10:26:08,813 - mmcls - INFO - Epoch [9][300/671]	lr: 4.196e-04, eta: 11:32:55, time: 0.490, data_time: 0.001, memory: 7111, loss: 1.5938, grad_norm: 1.9444
2023-10-09 10:26:59,143 - mmcls - INFO - Epoch [9][400/671]	lr: 4.269e-04, eta: 11:33:59, time: 0.503, data_time: 0.001, memory: 7111, loss: 1.5849, grad_norm: 1.8359
2023-10-09 10:27:46,357 - mmcls - INFO - Epoch [9][500/671]	lr: 4.341e-04, eta: 11:34:09, time: 0.472, data_time: 0.001, memory: 7111, loss: 1.5850, grad_norm: 1.9318
2023-10-09 10:28:35,193 - mmcls - INFO - Epoch [9][600/671]	lr: 4.414e-04, eta: 11:34:43, time: 0.488, data_time: 0.001, memory: 7111, loss: 1.6048, grad_norm: 1.9358
2023-10-09 10:30:01,947 - mmcls - INFO - Epoch [10][100/671]	lr: 4.538e-04, eta: 11:27:28, time: 0.519, data_time: 0.027, memory: 7111, loss: 1.6389, grad_norm: 1.9768
2023-10-09 10:30:50,865 - mmcls - INFO - Epoch [10][200/671]	lr: 4.610e-04, eta: 11:28:05, time: 0.489, data_time: 0.001, memory: 7111, loss: 1.6211, grad_norm: 1.8054
2023-10-09 10:31:39,812 - mmcls - INFO - Epoch [10][300/671]	lr: 4.682e-04, eta: 11:28:38, time: 0.489, data_time: 0.001, memory: 7111, loss: 1.6238, grad_norm: 1.9054
2023-10-09 10:32:28,470 - mmcls - INFO - Epoch [10][400/671]	lr: 4.755e-04, eta: 11:29:06, time: 0.487, data_time: 0.001, memory: 7111, loss: 1.6400, grad_norm: 1.8337
2023-10-09 10:33:14,546 - mmcls - INFO - Epoch [10][500/671]	lr: 4.827e-04, eta: 11:28:53, time: 0.461, data_time: 0.001, memory: 7111, loss: 1.6225, grad_norm: 1.8616
2023-10-09 10:34:03,698 - mmcls - INFO - Epoch [10][600/671]	lr: 4.899e-04, eta: 11:29:23, time: 0.492, data_time: 0.001, memory: 7111, loss: 1.5981, grad_norm: 1.7724
2023-10-09 10:35:15,670 - mmcls - INFO - Epoch(val) [10][256]	accuracy_top-1: 91.5027, accuracy_top-5: 99.8241
2023-10-09 10:36:07,050 - mmcls - INFO - Epoch [11][100/671]	lr: 5.022e-04, eta: 11:22:39, time: 0.514, data_time: 0.026, memory: 7111, loss: 1.7288, grad_norm: 1.6946
2023-10-09 10:36:55,904 - mmcls - INFO - Epoch [11][200/671]	lr: 5.094e-04, eta: 11:23:06, time: 0.489, data_time: 0.001, memory: 7111, loss: 1.6628, grad_norm: 1.7267
2023-10-09 10:37:44,700 - mmcls - INFO - Epoch [11][300/671]	lr: 5.166e-04, eta: 11:23:30, time: 0.488, data_time: 0.001, memory: 7111, loss: 1.5989, grad_norm: 1.7796
2023-10-09 10:38:31,108 - mmcls - INFO - Epoch [11][400/671]	lr: 5.238e-04, eta: 11:23:21, time: 0.464, data_time: 0.001, memory: 7111, loss: 1.6310, grad_norm: 1.8367
2023-10-09 10:39:19,702 - mmcls - INFO - Epoch [11][500/671]	lr: 5.309e-04, eta: 11:23:39, time: 0.486, data_time: 0.001, memory: 7111, loss: 1.6437, grad_norm: 1.7319
2023-10-09 10:40:08,529 - mmcls - INFO - Epoch [11][600/671]	lr: 5.381e-04, eta: 11:23:58, time: 0.488, data_time: 0.001, memory: 7111, loss: 1.6063, grad_norm: 1.8478
2023-10-09 10:41:34,603 - mmcls - INFO - Epoch [12][100/671]	lr: 5.503e-04, eta: 11:17:46, time: 0.514, data_time: 0.026, memory: 7111, loss: 1.5971, grad_norm: 1.8447
2023-10-09 10:42:23,319 - mmcls - INFO - Epoch [12][200/671]	lr: 5.575e-04, eta: 11:18:04, time: 0.487, data_time: 0.001, memory: 7111, loss: 1.6642, grad_norm: 1.7766
2023-10-09 10:43:12,124 - mmcls - INFO - Epoch [12][300/671]	lr: 5.646e-04, eta: 11:18:22, time: 0.488, data_time: 0.001, memory: 7111, loss: 1.6664, grad_norm: 1.8129
2023-10-09 10:43:58,630 - mmcls - INFO - Epoch [12][400/671]	lr: 5.717e-04, eta: 11:18:11, time: 0.465, data_time: 0.001, memory: 7111, loss: 1.6510, grad_norm: 1.7180
2023-10-09 10:44:47,413 - mmcls - INFO - Epoch [12][500/671]	lr: 5.788e-04, eta: 11:18:26, time: 0.488, data_time: 0.001, memory: 7111, loss: 1.6810, grad_norm: 1.6859
2023-10-09 10:45:36,239 - mmcls - INFO - Epoch [12][600/671]	lr: 5.860e-04, eta: 11:18:39, time: 0.488, data_time: 0.001, memory: 7111, loss: 1.6230, grad_norm: 1.8513
2023-10-09 10:47:02,869 - mmcls - INFO - Epoch [13][100/671]	lr: 5.981e-04, eta: 11:12:55, time: 0.514, data_time: 0.027, memory: 7111, loss: 1.6208, grad_norm: 1.7365
2023-10-09 10:47:51,572 - mmcls - INFO - Epoch [13][200/671]	lr: 6.052e-04, eta: 11:13:08, time: 0.487, data_time: 0.001, memory: 7111, loss: 1.6058, grad_norm: 1.8120
2023-10-09 10:48:40,395 - mmcls - INFO - Epoch [13][300/671]	lr: 6.122e-04, eta: 11:13:21, time: 0.488, data_time: 0.001, memory: 7111, loss: 1.6364, grad_norm: 1.7330
2023-10-09 10:49:26,997 - mmcls - INFO - Epoch [13][400/671]	lr: 6.193e-04, eta: 11:13:08, time: 0.466, data_time: 0.001, memory: 7111, loss: 1.6508, grad_norm: 1.6549
2023-10-09 10:50:15,813 - mmcls - INFO - Epoch [13][500/671]	lr: 6.264e-04, eta: 11:13:18, time: 0.488, data_time: 0.001, memory: 7111, loss: 1.6452, grad_norm: 1.6727
2023-10-09 10:51:04,642 - mmcls - INFO - Epoch [13][600/671]	lr: 6.334e-04, eta: 11:13:27, time: 0.488, data_time: 0.001, memory: 7111, loss: 1.6401, grad_norm: 1.7119
2023-10-09 10:52:30,800 - mmcls - INFO - Epoch [14][100/671]	lr: 6.455e-04, eta: 11:08:05, time: 0.513, data_time: 0.026, memory: 7111, loss: 1.6500, grad_norm: 1.7799
2023-10-09 10:53:19,600 - mmcls - INFO - Epoch [14][200/671]	lr: 6.525e-04, eta: 11:08:14, time: 0.488, data_time: 0.001, memory: 7111, loss: 1.6628, grad_norm: 1.6162
2023-10-09 10:54:08,415 - mmcls - INFO - Epoch [14][300/671]	lr: 6.595e-04, eta: 11:08:22, time: 0.488, data_time: 0.001, memory: 7111, loss: 1.6227, grad_norm: 1.7820
2023-10-09 10:54:54,955 - mmcls - INFO - Epoch [14][400/671]	lr: 6.665e-04, eta: 11:08:06, time: 0.465, data_time: 0.001, memory: 7111, loss: 1.6617, grad_norm: 1.7709
2023-10-09 10:55:44,007 - mmcls - INFO - Epoch [14][500/671]	lr: 6.735e-04, eta: 11:08:14, time: 0.491, data_time: 0.001, memory: 7111, loss: 1.6889, grad_norm: 1.6620
2023-10-09 10:56:33,399 - mmcls - INFO - Epoch [14][600/671]	lr: 6.805e-04, eta: 11:08:25, time: 0.494, data_time: 0.001, memory: 7111, loss: 1.6113, grad_norm: 1.6345
2023-10-09 10:58:00,921 - mmcls - INFO - Epoch [15][100/671]	lr: 6.924e-04, eta: 11:03:30, time: 0.523, data_time: 0.027, memory: 7111, loss: 1.6367, grad_norm: 1.8212
2023-10-09 10:58:50,691 - mmcls - INFO - Epoch [15][200/671]	lr: 6.994e-04, eta: 11:03:45, time: 0.498, data_time: 0.001, memory: 7111, loss: 1.7159, grad_norm: 1.6561
2023-10-09 10:59:40,339 - mmcls - INFO - Epoch [15][300/671]	lr: 7.063e-04, eta: 11:03:56, time: 0.496, data_time: 0.001, memory: 7111, loss: 1.6190, grad_norm: 1.6411
2023-10-09 11:00:27,940 - mmcls - INFO - Epoch [15][400/671]	lr: 7.133e-04, eta: 11:03:48, time: 0.476, data_time: 0.001, memory: 7111, loss: 1.6610, grad_norm: 1.5677
2023-10-09 11:01:17,689 - mmcls - INFO - Epoch [15][500/671]	lr: 7.202e-04, eta: 11:03:58, time: 0.497, data_time: 0.001, memory: 7111, loss: 1.6357, grad_norm: 1.6092
2023-10-09 11:02:07,540 - mmcls - INFO - Epoch [15][600/671]	lr: 7.271e-04, eta: 11:04:08, time: 0.498, data_time: 0.001, memory: 7111, loss: 1.6098, grad_norm: 1.7848
2023-10-09 11:03:35,637 - mmcls - INFO - Epoch [16][100/671]	lr: 7.389e-04, eta: 10:59:31, time: 0.524, data_time: 0.027, memory: 7111, loss: 1.7056, grad_norm: 1.6293
2023-10-09 11:04:25,498 - mmcls - INFO - Epoch [16][200/671]	lr: 7.458e-04, eta: 10:59:41, time: 0.499, data_time: 0.001, memory: 7111, loss: 1.6386, grad_norm: 1.6734
2023-10-09 11:05:14,944 - mmcls - INFO - Epoch [16][300/671]	lr: 7.527e-04, eta: 10:59:46, time: 0.494, data_time: 0.001, memory: 7111, loss: 1.6841, grad_norm: 1.6808
2023-10-09 11:06:01,738 - mmcls - INFO - Epoch [16][400/671]	lr: 7.595e-04, eta: 10:59:28, time: 0.468, data_time: 0.001, memory: 7111, loss: 1.6553, grad_norm: 1.6312
2023-10-09 11:06:51,895 - mmcls - INFO - Epoch [16][500/671]	lr: 7.664e-04, eta: 10:59:38, time: 0.502, data_time: 0.001, memory: 7111, loss: 1.6928, grad_norm: 1.7218
2023-10-09 11:07:41,920 - mmcls - INFO - Epoch [16][600/671]	lr: 7.732e-04, eta: 10:59:45, time: 0.500, data_time: 0.001, memory: 7111, loss: 1.6480, grad_norm: 1.6378
2023-10-09 11:09:10,181 - mmcls - INFO - Epoch [17][100/671]	lr: 7.849e-04, eta: 10:55:23, time: 0.527, data_time: 0.026, memory: 7111, loss: 1.6892, grad_norm: 1.6702
2023-10-09 11:09:59,917 - mmcls - INFO - Epoch [17][200/671]	lr: 7.917e-04, eta: 10:55:28, time: 0.497, data_time: 0.001, memory: 7111, loss: 1.6268, grad_norm: 1.5416
2023-10-09 11:10:49,908 - mmcls - INFO - Epoch [17][300/671]	lr: 7.985e-04, eta: 10:55:34, time: 0.500, data_time: 0.001, memory: 7111, loss: 1.6665, grad_norm: 1.6859
2023-10-09 11:11:37,390 - mmcls - INFO - Epoch [17][400/671]	lr: 8.053e-04, eta: 10:55:19, time: 0.475, data_time: 0.001, memory: 7111, loss: 1.6320, grad_norm: 1.5851
2023-10-09 11:12:27,378 - mmcls - INFO - Epoch [17][500/671]	lr: 8.121e-04, eta: 10:55:23, time: 0.500, data_time: 0.001, memory: 7111, loss: 1.7124, grad_norm: 1.6119
2023-10-09 11:13:17,427 - mmcls - INFO - Epoch [17][600/671]	lr: 8.189e-04, eta: 10:55:26, time: 0.499, data_time: 0.002, memory: 7111, loss: 1.6683, grad_norm: 1.6103
2023-10-09 11:14:45,474 - mmcls - INFO - Epoch [18][100/671]	lr: 8.304e-04, eta: 10:51:15, time: 0.526, data_time: 0.027, memory: 7111, loss: 1.7163, grad_norm: 1.5770
2023-10-09 11:15:35,394 - mmcls - INFO - Epoch [18][200/671]	lr: 8.372e-04, eta: 10:51:18, time: 0.499, data_time: 0.001, memory: 7111, loss: 1.6459, grad_norm: 1.6371
2023-10-09 11:16:25,139 - mmcls - INFO - Epoch [18][300/671]	lr: 8.439e-04, eta: 10:51:18, time: 0.497, data_time: 0.001, memory: 7111, loss: 1.6547, grad_norm: 1.5993
2023-10-09 11:17:13,465 - mmcls - INFO - Epoch [18][400/671]	lr: 8.506e-04, eta: 10:51:08, time: 0.483, data_time: 0.001, memory: 7111, loss: 1.6382, grad_norm: 1.7794
2023-10-09 11:18:03,369 - mmcls - INFO - Epoch [18][500/671]	lr: 8.573e-04, eta: 10:51:08, time: 0.499, data_time: 0.001, memory: 7111, loss: 1.7077, grad_norm: 1.5838
2023-10-09 11:18:53,536 - mmcls - INFO - Epoch [18][600/671]	lr: 8.640e-04, eta: 10:51:09, time: 0.502, data_time: 0.003, memory: 7111, loss: 1.7117, grad_norm: 1.5473
2023-10-09 11:20:21,627 - mmcls - INFO - Epoch [19][100/671]	lr: 8.754e-04, eta: 10:47:08, time: 0.526, data_time: 0.027, memory: 7111, loss: 1.6105, grad_norm: 1.6265
2023-10-09 11:21:11,594 - mmcls - INFO - Epoch [19][200/671]	lr: 8.821e-04, eta: 10:47:08, time: 0.500, data_time: 0.001, memory: 7111, loss: 1.6123, grad_norm: 1.6330
2023-10-09 11:22:01,413 - mmcls - INFO - Epoch [19][300/671]	lr: 8.887e-04, eta: 10:47:06, time: 0.498, data_time: 0.001, memory: 7111, loss: 1.6600, grad_norm: 1.6401
2023-10-09 11:22:43,190 - mmcls - INFO - Epoch [19][400/671]	lr: 8.953e-04, eta: 10:46:07, time: 0.418, data_time: 0.001, memory: 7111, loss: 1.6927, grad_norm: 1.4961
2023-10-09 11:23:10,193 - mmcls - INFO - Epoch [19][500/671]	lr: 9.020e-04, eta: 10:43:24, time: 0.270, data_time: 0.001, memory: 7111, loss: 1.7038, grad_norm: 1.4572
2023-10-09 11:23:38,434 - mmcls - INFO - Epoch [19][600/671]	lr: 9.086e-04, eta: 10:40:52, time: 0.282, data_time: 0.003, memory: 7111, loss: 1.6490, grad_norm: 1.5551
2023-10-09 11:24:26,527 - mmcls - INFO - Epoch [20][100/671]	lr: 9.198e-04, eta: 10:34:25, time: 0.291, data_time: 0.027, memory: 7111, loss: 1.6656, grad_norm: 1.5883
2023-10-09 11:24:54,423 - mmcls - INFO - Epoch [20][200/671]	lr: 9.264e-04, eta: 10:31:57, time: 0.279, data_time: 0.001, memory: 7111, loss: 1.6509, grad_norm: 1.5173
2023-10-09 11:25:20,792 - mmcls - INFO - Epoch [20][300/671]	lr: 9.329e-04, eta: 10:29:20, time: 0.264, data_time: 0.001, memory: 7111, loss: 1.6643, grad_norm: 1.5405
2023-10-09 11:25:48,634 - mmcls - INFO - Epoch [20][400/671]	lr: 9.395e-04, eta: 10:26:56, time: 0.278, data_time: 0.001, memory: 7111, loss: 1.6957, grad_norm: 1.5099
2023-10-09 11:26:15,191 - mmcls - INFO - Epoch [20][500/671]	lr: 9.460e-04, eta: 10:24:24, time: 0.266, data_time: 0.001, memory: 7111, loss: 1.7022, grad_norm: 1.4392
2023-10-09 11:26:42,981 - mmcls - INFO - Epoch [20][600/671]	lr: 9.525e-04, eta: 10:22:03, time: 0.278, data_time: 0.003, memory: 7111, loss: 1.6245, grad_norm: 1.5874
2023-10-09 11:41:32,322 - mmcls - INFO - Epoch(val) [20][256]	accuracy_top-1: 90.4405, accuracy_top-5: 99.7002
2023-10-09 11:42:23,240 - mmcls - INFO - Epoch [21][100/671]	lr: 9.566e-04, eta: 10:18:27, time: 0.509, data_time: 0.027, memory: 7111, loss: 1.7315, grad_norm: 1.5021
2023-10-09 11:43:12,912 - mmcls - INFO - Epoch [21][200/671]	lr: 9.559e-04, eta: 10:18:29, time: 0.497, data_time: 0.001, memory: 7111, loss: 1.6600, grad_norm: 1.4539
2023-10-09 11:44:03,688 - mmcls - INFO - Epoch [21][300/671]	lr: 9.553e-04, eta: 10:18:38, time: 0.508, data_time: 0.001, memory: 7111, loss: 1.6807, grad_norm: 1.5040
2023-10-09 11:44:54,085 - mmcls - INFO - Epoch [21][400/671]	lr: 9.547e-04, eta: 10:18:44, time: 0.504, data_time: 0.001, memory: 7111, loss: 1.6820, grad_norm: 1.4623
2023-10-09 11:45:43,896 - mmcls - INFO - Epoch [21][500/671]	lr: 9.540e-04, eta: 10:18:45, time: 0.498, data_time: 0.001, memory: 7111, loss: 1.6690, grad_norm: 1.4887
2023-10-09 11:46:33,803 - mmcls - INFO - Epoch [21][600/671]	lr: 9.534e-04, eta: 10:18:46, time: 0.499, data_time: 0.002, memory: 7111, loss: 1.6697, grad_norm: 1.4774
2023-10-09 11:48:01,681 - mmcls - INFO - Epoch [22][100/671]	lr: 9.522e-04, eta: 10:15:25, time: 0.523, data_time: 0.027, memory: 7111, loss: 1.6956, grad_norm: 1.4376
2023-10-09 11:48:51,453 - mmcls - INFO - Epoch [22][200/671]	lr: 9.516e-04, eta: 10:15:25, time: 0.498, data_time: 0.001, memory: 7111, loss: 1.6911, grad_norm: 1.5073
2023-10-09 11:49:41,209 - mmcls - INFO - Epoch [22][300/671]	lr: 9.509e-04, eta: 10:15:24, time: 0.498, data_time: 0.001, memory: 7111, loss: 1.6724, grad_norm: 1.4684
2023-10-09 11:50:30,941 - mmcls - INFO - Epoch [22][400/671]	lr: 9.502e-04, eta: 10:15:22, time: 0.497, data_time: 0.001, memory: 7111, loss: 1.6895, grad_norm: 1.4886
2023-10-09 11:51:20,612 - mmcls - INFO - Epoch [22][500/671]	lr: 9.496e-04, eta: 10:15:20, time: 0.497, data_time: 0.001, memory: 7111, loss: 1.6928, grad_norm: 1.5684
2023-10-09 11:52:10,525 - mmcls - INFO - Epoch [22][600/671]	lr: 9.489e-04, eta: 10:15:18, time: 0.499, data_time: 0.002, memory: 7111, loss: 1.7289, grad_norm: 1.4000
2023-10-09 11:53:38,063 - mmcls - INFO - Epoch [23][100/671]	lr: 9.477e-04, eta: 10:12:02, time: 0.521, data_time: 0.027, memory: 7111, loss: 1.6731, grad_norm: 1.5458
2023-10-09 11:54:28,004 - mmcls - INFO - Epoch [23][200/671]	lr: 9.470e-04, eta: 10:12:00, time: 0.499, data_time: 0.001, memory: 7111, loss: 1.7249, grad_norm: 1.3052
2023-10-09 11:55:17,895 - mmcls - INFO - Epoch [23][300/671]	lr: 9.463e-04, eta: 10:11:57, time: 0.499, data_time: 0.001, memory: 7111, loss: 1.6758, grad_norm: 1.5043
2023-10-09 11:56:07,838 - mmcls - INFO - Epoch [23][400/671]	lr: 9.456e-04, eta: 10:11:54, time: 0.499, data_time: 0.001, memory: 7111, loss: 1.6377, grad_norm: 1.4022
2023-10-09 11:56:57,748 - mmcls - INFO - Epoch [23][500/671]	lr: 9.449e-04, eta: 10:11:50, time: 0.499, data_time: 0.001, memory: 7111, loss: 1.7183, grad_norm: 1.4476
2023-10-09 11:57:47,678 - mmcls - INFO - Epoch [23][600/671]	lr: 9.442e-04, eta: 10:11:45, time: 0.499, data_time: 0.002, memory: 7111, loss: 1.6882, grad_norm: 1.4042
2023-10-09 11:59:15,083 - mmcls - INFO - Epoch [24][100/671]	lr: 9.430e-04, eta: 10:08:33, time: 0.519, data_time: 0.026, memory: 7111, loss: 1.6685, grad_norm: 1.4360
2023-10-09 12:00:05,069 - mmcls - INFO - Epoch [24][200/671]	lr: 9.422e-04, eta: 10:08:28, time: 0.500, data_time: 0.001, memory: 7111, loss: 1.6843, grad_norm: 1.3847
2023-10-09 12:00:54,890 - mmcls - INFO - Epoch [24][300/671]	lr: 9.415e-04, eta: 10:08:22, time: 0.498, data_time: 0.001, memory: 7111, loss: 1.6552, grad_norm: 1.5260
2023-10-09 12:01:44,749 - mmcls - INFO - Epoch [24][400/671]	lr: 9.408e-04, eta: 10:08:16, time: 0.499, data_time: 0.001, memory: 7111, loss: 1.6193, grad_norm: 1.3954
2023-10-09 12:02:34,632 - mmcls - INFO - Epoch [24][500/671]	lr: 9.400e-04, eta: 10:08:10, time: 0.499, data_time: 0.001, memory: 7111, loss: 1.7000, grad_norm: 1.4312
2023-10-09 12:03:24,497 - mmcls - INFO - Epoch [24][600/671]	lr: 9.393e-04, eta: 10:08:02, time: 0.499, data_time: 0.002, memory: 7111, loss: 1.6473, grad_norm: 1.3560
2023-10-09 12:04:51,867 - mmcls - INFO - Epoch [25][100/671]	lr: 9.380e-04, eta: 10:04:55, time: 0.519, data_time: 0.027, memory: 7111, loss: 1.6419, grad_norm: 1.4295
2023-10-09 12:05:41,907 - mmcls - INFO - Epoch [25][200/671]	lr: 9.373e-04, eta: 10:04:48, time: 0.500, data_time: 0.001, memory: 7111, loss: 1.6545, grad_norm: 1.4508
2023-10-09 12:06:31,708 - mmcls - INFO - Epoch [25][300/671]	lr: 9.365e-04, eta: 10:04:40, time: 0.498, data_time: 0.001, memory: 7111, loss: 1.6469, grad_norm: 1.3596
2023-10-09 12:07:21,826 - mmcls - INFO - Epoch [25][400/671]	lr: 9.358e-04, eta: 10:04:33, time: 0.501, data_time: 0.001, memory: 7111, loss: 1.6885, grad_norm: 1.3409
2023-10-09 12:08:12,340 - mmcls - INFO - Epoch [25][500/671]	lr: 9.350e-04, eta: 10:04:27, time: 0.505, data_time: 0.001, memory: 7111, loss: 1.6806, grad_norm: 1.3951
2023-10-09 12:09:02,700 - mmcls - INFO - Epoch [25][600/671]	lr: 9.342e-04, eta: 10:04:20, time: 0.504, data_time: 0.004, memory: 7111, loss: 1.6636, grad_norm: 1.4105
2023-10-09 12:10:31,194 - mmcls - INFO - Epoch [26][100/671]	lr: 9.329e-04, eta: 10:01:20, time: 0.524, data_time: 0.029, memory: 7111, loss: 1.6772, grad_norm: 1.4242
2023-10-09 12:11:21,315 - mmcls - INFO - Epoch [26][200/671]	lr: 9.321e-04, eta: 10:01:11, time: 0.501, data_time: 0.001, memory: 7111, loss: 1.6848, grad_norm: 1.3673
2023-10-09 12:12:10,913 - mmcls - INFO - Epoch [26][300/671]	lr: 9.314e-04, eta: 10:01:00, time: 0.496, data_time: 0.001, memory: 7111, loss: 1.6313, grad_norm: 1.3350
2023-10-09 12:13:00,273 - mmcls - INFO - Epoch [26][400/671]	lr: 9.306e-04, eta: 10:00:47, time: 0.494, data_time: 0.001, memory: 7111, loss: 1.6389, grad_norm: 1.4217
2023-10-09 12:13:49,729 - mmcls - INFO - Epoch [26][500/671]	lr: 9.298e-04, eta: 10:00:34, time: 0.495, data_time: 0.001, memory: 7111, loss: 1.6865, grad_norm: 1.3787
2023-10-09 12:14:38,819 - mmcls - INFO - Epoch [26][600/671]	lr: 9.290e-04, eta: 10:00:19, time: 0.491, data_time: 0.003, memory: 7111, loss: 1.6685, grad_norm: 1.3842
2023-10-09 12:16:04,633 - mmcls - INFO - Epoch [27][100/671]	lr: 9.276e-04, eta: 9:57:14, time: 0.505, data_time: 0.029, memory: 7111, loss: 1.6972, grad_norm: 1.3577
2023-10-09 12:16:53,814 - mmcls - INFO - Epoch [27][200/671]	lr: 9.268e-04, eta: 9:57:00, time: 0.492, data_time: 0.001, memory: 7111, loss: 1.6513, grad_norm: 1.4899
2023-10-09 12:17:43,337 - mmcls - INFO - Epoch [27][300/671]	lr: 9.260e-04, eta: 9:56:46, time: 0.495, data_time: 0.001, memory: 7111, loss: 1.6671, grad_norm: 1.3460
2023-10-09 12:18:32,209 - mmcls - INFO - Epoch [27][400/671]	lr: 9.252e-04, eta: 9:56:29, time: 0.489, data_time: 0.001, memory: 7111, loss: 1.6169, grad_norm: 1.4083
2023-10-09 12:19:21,375 - mmcls - INFO - Epoch [27][500/671]	lr: 9.244e-04, eta: 9:56:13, time: 0.492, data_time: 0.001, memory: 7111, loss: 1.6622, grad_norm: 1.3020
2023-10-09 12:20:11,020 - mmcls - INFO - Epoch [27][600/671]	lr: 9.235e-04, eta: 9:55:59, time: 0.496, data_time: 0.004, memory: 7111, loss: 1.6399, grad_norm: 1.3985
2023-10-09 12:21:36,119 - mmcls - INFO - Epoch [28][100/671]	lr: 9.221e-04, eta: 9:52:55, time: 0.497, data_time: 0.028, memory: 7111, loss: 1.6671, grad_norm: 1.3672
2023-10-09 12:22:24,612 - mmcls - INFO - Epoch [28][200/671]	lr: 9.213e-04, eta: 9:52:36, time: 0.485, data_time: 0.001, memory: 7111, loss: 1.6803, grad_norm: 1.3734
2023-10-09 12:23:14,344 - mmcls - INFO - Epoch [28][300/671]	lr: 9.204e-04, eta: 9:52:22, time: 0.497, data_time: 0.001, memory: 7111, loss: 1.6792, grad_norm: 1.3731
2023-10-09 12:24:03,592 - mmcls - INFO - Epoch [28][400/671]	lr: 9.196e-04, eta: 9:52:06, time: 0.492, data_time: 0.002, memory: 7111, loss: 1.6046, grad_norm: 1.3872
2023-10-09 12:24:53,082 - mmcls - INFO - Epoch [28][500/671]	lr: 9.188e-04, eta: 9:51:50, time: 0.495, data_time: 0.001, memory: 7111, loss: 1.6423, grad_norm: 1.4161
2023-10-09 12:25:42,525 - mmcls - INFO - Epoch [28][600/671]	lr: 9.179e-04, eta: 9:51:34, time: 0.494, data_time: 0.002, memory: 7111, loss: 1.6317, grad_norm: 1.3264
2023-10-09 12:26:50,474 - mmcls - INFO - Epoch [29][100/671]	lr: 9.164e-04, eta: 9:47:20, time: 0.326, data_time: 0.027, memory: 7111, loss: 1.6411, grad_norm: 1.3954
2023-10-09 12:27:17,344 - mmcls - INFO - Epoch [29][200/671]	lr: 9.156e-04, eta: 9:45:27, time: 0.269, data_time: 0.001, memory: 7111, loss: 1.6347, grad_norm: 1.3172
2023-10-09 12:27:45,070 - mmcls - INFO - Epoch [29][300/671]	lr: 9.147e-04, eta: 9:43:39, time: 0.277, data_time: 0.001, memory: 7111, loss: 1.6749, grad_norm: 1.2517
2023-10-09 12:28:11,691 - mmcls - INFO - Epoch [29][400/671]	lr: 9.139e-04, eta: 9:41:47, time: 0.266, data_time: 0.001, memory: 7111, loss: 1.6667, grad_norm: 1.3878
2023-10-09 12:28:39,795 - mmcls - INFO - Epoch [29][500/671]	lr: 9.130e-04, eta: 9:40:02, time: 0.281, data_time: 0.001, memory: 7111, loss: 1.7075, grad_norm: 1.3110
2023-10-09 12:29:06,674 - mmcls - INFO - Epoch [29][600/671]	lr: 9.121e-04, eta: 9:38:12, time: 0.269, data_time: 0.002, memory: 7111, loss: 1.6332, grad_norm: 1.3254
2023-10-09 12:29:55,964 - mmcls - INFO - Epoch [30][100/671]	lr: 9.106e-04, eta: 9:34:03, time: 0.304, data_time: 0.027, memory: 7111, loss: 1.6584, grad_norm: 1.3470
2023-10-09 12:30:22,890 - mmcls - INFO - Epoch [30][200/671]	lr: 9.097e-04, eta: 9:32:16, time: 0.269, data_time: 0.001, memory: 7111, loss: 1.6431, grad_norm: 1.3759
2023-10-09 12:30:50,980 - mmcls - INFO - Epoch [30][300/671]	lr: 9.088e-04, eta: 9:30:35, time: 0.281, data_time: 0.001, memory: 7111, loss: 1.6939, grad_norm: 1.3793
2023-10-09 12:31:17,633 - mmcls - INFO - Epoch [30][400/671]	lr: 9.079e-04, eta: 9:28:49, time: 0.267, data_time: 0.001, memory: 7111, loss: 1.6267, grad_norm: 1.4012
2023-10-09 12:31:52,043 - mmcls - INFO - Epoch [30][500/671]	lr: 9.070e-04, eta: 9:27:35, time: 0.344, data_time: 0.001, memory: 7111, loss: 1.6705, grad_norm: 1.3435
2023-10-09 12:32:40,175 - mmcls - INFO - Epoch [30][600/671]	lr: 9.061e-04, eta: 9:27:17, time: 0.481, data_time: 0.002, memory: 7111, loss: 1.6446, grad_norm: 1.3611
2023-10-09 12:33:16,253 - mmcls - INFO - Saving checkpoint at 30 epochs
2023-10-09 12:33:53,192 - mmcls - INFO - Epoch(val) [30][256]	accuracy_top-1: 91.2160, accuracy_top-5: 99.8436
2023-10-09 12:34:45,754 - mmcls - INFO - Epoch [31][100/671]	lr: 9.046e-04, eta: 9:24:46, time: 0.526, data_time: 0.027, memory: 7111, loss: 1.6342, grad_norm: 1.3017
2023-10-09 12:35:35,779 - mmcls - INFO - Epoch [31][200/671]	lr: 9.036e-04, eta: 9:24:35, time: 0.500, data_time: 0.001, memory: 7111, loss: 1.6390, grad_norm: 1.3432
2023-10-09 12:36:25,904 - mmcls - INFO - Epoch [31][300/671]	lr: 9.027e-04, eta: 9:24:24, time: 0.501, data_time: 0.001, memory: 7111, loss: 1.6470, grad_norm: 1.4197
2023-10-09 12:37:15,860 - mmcls - INFO - Epoch [31][400/671]	lr: 9.018e-04, eta: 9:24:12, time: 0.500, data_time: 0.001, memory: 7111, loss: 1.6414, grad_norm: 1.3335
2023-10-09 12:38:03,718 - mmcls - INFO - Epoch [31][500/671]	lr: 9.009e-04, eta: 9:23:52, time: 0.479, data_time: 0.001, memory: 7111, loss: 1.6156, grad_norm: 1.3850
2023-10-09 12:38:54,355 - mmcls - INFO - Epoch [31][600/671]	lr: 9.000e-04, eta: 9:23:42, time: 0.506, data_time: 0.002, memory: 7111, loss: 1.5765, grad_norm: 1.3946
2023-10-09 12:40:22,969 - mmcls - INFO - Epoch [32][100/671]	lr: 8.984e-04, eta: 9:21:14, time: 0.526, data_time: 0.027, memory: 7111, loss: 1.6384, grad_norm: 1.3361
2023-10-09 12:41:13,094 - mmcls - INFO - Epoch [32][200/671]	lr: 8.974e-04, eta: 9:21:02, time: 0.501, data_time: 0.001, memory: 7111, loss: 1.6505, grad_norm: 1.3435
2023-10-09 12:42:03,113 - mmcls - INFO - Epoch [32][300/671]	lr: 8.965e-04, eta: 9:20:49, time: 0.500, data_time: 0.001, memory: 7111, loss: 1.6115, grad_norm: 1.3185
2023-10-09 12:42:53,011 - mmcls - INFO - Epoch [32][400/671]	lr: 8.955e-04, eta: 9:20:35, time: 0.499, data_time: 0.001, memory: 7111, loss: 1.6414, grad_norm: 1.2674
2023-10-09 12:43:40,947 - mmcls - INFO - Epoch [32][500/671]	lr: 8.946e-04, eta: 9:20:13, time: 0.479, data_time: 0.001, memory: 7111, loss: 1.6083, grad_norm: 1.3752
2023-10-09 12:44:31,432 - mmcls - INFO - Epoch [32][600/671]	lr: 8.936e-04, eta: 9:20:01, time: 0.505, data_time: 0.002, memory: 7111, loss: 1.6384, grad_norm: 1.2809
2023-10-09 12:45:59,755 - mmcls - INFO - Epoch [33][100/671]	lr: 8.920e-04, eta: 9:17:36, time: 0.528, data_time: 0.027, memory: 7111, loss: 1.6022, grad_norm: 1.3928
2023-10-09 12:46:50,550 - mmcls - INFO - Epoch [33][200/671]	lr: 8.910e-04, eta: 9:17:25, time: 0.508, data_time: 0.001, memory: 7111, loss: 1.6761, grad_norm: 1.3179
2023-10-09 12:47:40,610 - mmcls - INFO - Epoch [33][300/671]	lr: 8.900e-04, eta: 9:17:10, time: 0.501, data_time: 0.001, memory: 7111, loss: 1.6294, grad_norm: 1.2734
2023-10-09 12:48:30,460 - mmcls - INFO - Epoch [33][400/671]	lr: 8.891e-04, eta: 9:16:55, time: 0.498, data_time: 0.001, memory: 7111, loss: 1.6548, grad_norm: 1.3331
2023-10-09 12:49:18,235 - mmcls - INFO - Epoch [33][500/671]	lr: 8.881e-04, eta: 9:16:32, time: 0.478, data_time: 0.001, memory: 7111, loss: 1.6113, grad_norm: 1.3467
2023-10-09 12:50:08,423 - mmcls - INFO - Epoch [33][600/671]	lr: 8.871e-04, eta: 9:16:17, time: 0.502, data_time: 0.002, memory: 7111, loss: 1.5980, grad_norm: 1.3402
2023-10-09 12:51:36,643 - mmcls - INFO - Epoch [34][100/671]	lr: 8.854e-04, eta: 9:13:54, time: 0.526, data_time: 0.027, memory: 7111, loss: 1.6274, grad_norm: 1.3604
2023-10-09 12:52:26,485 - mmcls - INFO - Epoch [34][200/671]	lr: 8.844e-04, eta: 9:13:38, time: 0.498, data_time: 0.001, memory: 7111, loss: 1.6428, grad_norm: 1.3815
2023-10-09 12:53:16,439 - mmcls - INFO - Epoch [34][300/671]	lr: 8.834e-04, eta: 9:13:21, time: 0.500, data_time: 0.001, memory: 7111, loss: 1.6413, grad_norm: 1.2819
2023-10-09 12:54:06,135 - mmcls - INFO - Epoch [34][400/671]	lr: 8.824e-04, eta: 9:13:04, time: 0.497, data_time: 0.001, memory: 7111, loss: 1.6367, grad_norm: 1.3232
2023-10-09 12:54:53,902 - mmcls - INFO - Epoch [34][500/671]	lr: 8.814e-04, eta: 9:12:40, time: 0.478, data_time: 0.001, memory: 7111, loss: 1.6348, grad_norm: 1.2501
2023-10-09 12:55:43,848 - mmcls - INFO - Epoch [34][600/671]	lr: 8.804e-04, eta: 9:12:23, time: 0.499, data_time: 0.002, memory: 7111, loss: 1.5523, grad_norm: 1.3134
2023-10-09 12:57:11,416 - mmcls - INFO - Epoch [35][100/671]	lr: 8.787e-04, eta: 9:10:01, time: 0.524, data_time: 0.027, memory: 7111, loss: 1.6708, grad_norm: 1.3278
2023-10-09 12:58:01,409 - mmcls - INFO - Epoch [35][200/671]	lr: 8.777e-04, eta: 9:09:44, time: 0.500, data_time: 0.001, memory: 7111, loss: 1.6044, grad_norm: 1.3065
2023-10-09 12:58:51,238 - mmcls - INFO - Epoch [35][300/671]	lr: 8.767e-04, eta: 9:09:26, time: 0.498, data_time: 0.001, memory: 7111, loss: 1.6442, grad_norm: 1.2796
2023-10-09 12:59:40,991 - mmcls - INFO - Epoch [35][400/671]	lr: 8.757e-04, eta: 9:09:08, time: 0.498, data_time: 0.001, memory: 7111, loss: 1.6522, grad_norm: 1.3532
2023-10-09 13:00:28,629 - mmcls - INFO - Epoch [35][500/671]	lr: 8.746e-04, eta: 9:08:42, time: 0.476, data_time: 0.001, memory: 7111, loss: 1.6355, grad_norm: 1.3234
2023-10-09 13:01:18,831 - mmcls - INFO - Epoch [35][600/671]	lr: 8.736e-04, eta: 9:08:25, time: 0.502, data_time: 0.002, memory: 7111, loss: 1.6093, grad_norm: 1.2742
2023-10-09 13:02:47,050 - mmcls - INFO - Epoch [36][100/671]	lr: 8.718e-04, eta: 9:06:05, time: 0.526, data_time: 0.027, memory: 7111, loss: 1.5795, grad_norm: 1.3957
2023-10-09 13:03:37,043 - mmcls - INFO - Epoch [36][200/671]	lr: 8.708e-04, eta: 9:05:47, time: 0.500, data_time: 0.001, memory: 7111, loss: 1.5830, grad_norm: 1.2597
2023-10-09 13:04:26,961 - mmcls - INFO - Epoch [36][300/671]	lr: 8.697e-04, eta: 9:05:28, time: 0.499, data_time: 0.001, memory: 7111, loss: 1.6214, grad_norm: 1.2748
2023-10-09 13:05:16,881 - mmcls - INFO - Epoch [36][400/671]	lr: 8.687e-04, eta: 9:05:09, time: 0.499, data_time: 0.001, memory: 7111, loss: 1.6067, grad_norm: 1.2833
2023-10-09 13:06:04,446 - mmcls - INFO - Epoch [36][500/671]	lr: 8.677e-04, eta: 9:04:43, time: 0.476, data_time: 0.001, memory: 7111, loss: 1.6044, grad_norm: 1.3433
2023-10-09 13:06:54,444 - mmcls - INFO - Epoch [36][600/671]	lr: 8.666e-04, eta: 9:04:23, time: 0.500, data_time: 0.002, memory: 7111, loss: 1.6320, grad_norm: 1.3970
2023-10-09 13:08:22,255 - mmcls - INFO - Epoch [37][100/671]	lr: 8.648e-04, eta: 9:02:06, time: 0.524, data_time: 0.027, memory: 7111, loss: 1.6153, grad_norm: 1.3368
2023-10-09 13:09:12,231 - mmcls - INFO - Epoch [37][200/671]	lr: 8.637e-04, eta: 9:01:46, time: 0.500, data_time: 0.001, memory: 7111, loss: 1.5977, grad_norm: 1.3267
2023-10-09 13:10:01,942 - mmcls - INFO - Epoch [37][300/671]	lr: 8.627e-04, eta: 9:01:26, time: 0.497, data_time: 0.001, memory: 7111, loss: 1.6150, grad_norm: 1.2714
2023-10-09 13:10:51,671 - mmcls - INFO - Epoch [37][400/671]	lr: 8.616e-04, eta: 9:01:05, time: 0.497, data_time: 0.001, memory: 7111, loss: 1.6336, grad_norm: 1.2371
2023-10-09 13:11:39,205 - mmcls - INFO - Epoch [37][500/671]	lr: 8.605e-04, eta: 9:00:38, time: 0.475, data_time: 0.001, memory: 7111, loss: 1.6110, grad_norm: 1.2842
2023-10-09 13:12:29,065 - mmcls - INFO - Epoch [37][600/671]	lr: 8.594e-04, eta: 9:00:17, time: 0.499, data_time: 0.002, memory: 7111, loss: 1.6537, grad_norm: 1.2402
2023-10-09 13:13:57,064 - mmcls - INFO - Epoch [38][100/671]	lr: 8.576e-04, eta: 8:58:01, time: 0.524, data_time: 0.027, memory: 7111, loss: 1.5736, grad_norm: 1.3089
2023-10-09 13:14:46,975 - mmcls - INFO - Epoch [38][200/671]	lr: 8.565e-04, eta: 8:57:41, time: 0.499, data_time: 0.001, memory: 7111, loss: 1.6292, grad_norm: 1.2874
2023-10-09 13:15:36,720 - mmcls - INFO - Epoch [38][300/671]	lr: 8.554e-04, eta: 8:57:19, time: 0.497, data_time: 0.001, memory: 7111, loss: 1.5865, grad_norm: 1.3759
2023-10-09 13:16:26,735 - mmcls - INFO - Epoch [38][400/671]	lr: 8.543e-04, eta: 8:56:59, time: 0.500, data_time: 0.001, memory: 7111, loss: 1.5841, grad_norm: 1.2746
2023-10-09 13:17:14,168 - mmcls - INFO - Epoch [38][500/671]	lr: 8.532e-04, eta: 8:56:30, time: 0.474, data_time: 0.001, memory: 7111, loss: 1.6225, grad_norm: 1.3306
2023-10-09 13:18:04,023 - mmcls - INFO - Epoch [38][600/671]	lr: 8.521e-04, eta: 8:56:08, time: 0.499, data_time: 0.003, memory: 7111, loss: 1.5817, grad_norm: 1.3085
2023-10-09 13:19:31,815 - mmcls - INFO - Epoch [39][100/671]	lr: 8.502e-04, eta: 8:53:54, time: 0.523, data_time: 0.027, memory: 7111, loss: 1.5758, grad_norm: 1.3043
2023-10-09 13:20:21,497 - mmcls - INFO - Epoch [39][200/671]	lr: 8.491e-04, eta: 8:53:32, time: 0.497, data_time: 0.001, memory: 7111, loss: 1.6135, grad_norm: 1.3328
2023-10-09 13:21:11,214 - mmcls - INFO - Epoch [39][300/671]	lr: 8.480e-04, eta: 8:53:09, time: 0.497, data_time: 0.001, memory: 7111, loss: 1.6190, grad_norm: 1.2463
2023-10-09 13:22:00,988 - mmcls - INFO - Epoch [39][400/671]	lr: 8.469e-04, eta: 8:52:47, time: 0.498, data_time: 0.001, memory: 7111, loss: 1.6100, grad_norm: 1.2457
2023-10-09 13:22:48,558 - mmcls - INFO - Epoch [39][500/671]	lr: 8.458e-04, eta: 8:52:18, time: 0.476, data_time: 0.001, memory: 7111, loss: 1.5949, grad_norm: 1.2995
2023-10-09 13:23:38,508 - mmcls - INFO - Epoch [39][600/671]	lr: 8.447e-04, eta: 8:51:56, time: 0.500, data_time: 0.002, memory: 7111, loss: 1.5972, grad_norm: 1.1457
2023-10-09 13:25:06,303 - mmcls - INFO - Epoch [40][100/671]	lr: 8.427e-04, eta: 8:49:44, time: 0.526, data_time: 0.027, memory: 7111, loss: 1.5812, grad_norm: 1.3365
2023-10-09 13:25:55,993 - mmcls - INFO - Epoch [40][200/671]	lr: 8.416e-04, eta: 8:49:21, time: 0.497, data_time: 0.001, memory: 7111, loss: 1.5987, grad_norm: 1.3196
2023-10-09 13:26:45,460 - mmcls - INFO - Epoch [40][300/671]	lr: 8.405e-04, eta: 8:48:57, time: 0.495, data_time: 0.001, memory: 7111, loss: 1.5868, grad_norm: 1.2395
2023-10-09 13:27:34,774 - mmcls - INFO - Epoch [40][400/671]	lr: 8.393e-04, eta: 8:48:32, time: 0.493, data_time: 0.001, memory: 7111, loss: 1.5891, grad_norm: 1.2721
2023-10-09 13:28:15,278 - mmcls - INFO - Epoch [40][500/671]	lr: 8.382e-04, eta: 8:47:43, time: 0.405, data_time: 0.001, memory: 7111, loss: 1.6310, grad_norm: 1.2826
2023-10-09 13:28:42,734 - mmcls - INFO - Epoch [40][600/671]	lr: 8.370e-04, eta: 8:46:18, time: 0.275, data_time: 0.002, memory: 7111, loss: 1.5634, grad_norm: 1.3354
2023-10-09 13:43:32,194 - mmcls - INFO - Epoch(val) [40][256]	accuracy_top-1: 90.8706, accuracy_top-5: 99.7068
2023-10-09 13:44:23,681 - mmcls - INFO - Epoch [41][100/671]	lr: 8.351e-04, eta: 8:44:06, time: 0.515, data_time: 0.027, memory: 7111, loss: 1.6328, grad_norm: 1.3213
2023-10-09 13:45:13,213 - mmcls - INFO - Epoch [41][200/671]	lr: 8.339e-04, eta: 8:43:42, time: 0.495, data_time: 0.001, memory: 7111, loss: 1.5765, grad_norm: 1.2819
2023-10-09 13:46:00,178 - mmcls - INFO - Epoch [41][300/671]	lr: 8.328e-04, eta: 8:43:11, time: 0.470, data_time: 0.001, memory: 7111, loss: 1.6160, grad_norm: 1.2096
2023-10-09 13:46:49,854 - mmcls - INFO - Epoch [41][400/671]	lr: 8.316e-04, eta: 8:42:47, time: 0.497, data_time: 0.001, memory: 7111, loss: 1.6284, grad_norm: 1.2233
2023-10-09 13:47:39,583 - mmcls - INFO - Epoch [41][500/671]	lr: 8.305e-04, eta: 8:42:23, time: 0.497, data_time: 0.001, memory: 7111, loss: 1.6301, grad_norm: 1.3077
2023-10-09 13:48:29,782 - mmcls - INFO - Epoch [41][600/671]	lr: 8.293e-04, eta: 8:42:00, time: 0.502, data_time: 0.002, memory: 7111, loss: 1.6221, grad_norm: 1.3115
2023-10-09 13:49:56,851 - mmcls - INFO - Epoch [42][100/671]	lr: 8.273e-04, eta: 8:39:50, time: 0.517, data_time: 0.027, memory: 7111, loss: 1.5950, grad_norm: 1.2637
2023-10-09 13:50:47,062 - mmcls - INFO - Epoch [42][200/671]	lr: 8.261e-04, eta: 8:39:27, time: 0.502, data_time: 0.001, memory: 7111, loss: 1.6246, grad_norm: 1.2578
2023-10-09 13:51:34,463 - mmcls - INFO - Epoch [42][300/671]	lr: 8.249e-04, eta: 8:38:56, time: 0.474, data_time: 0.001, memory: 7111, loss: 1.6264, grad_norm: 1.3300
2023-10-09 13:52:24,425 - mmcls - INFO - Epoch [42][400/671]	lr: 8.238e-04, eta: 8:38:32, time: 0.500, data_time: 0.001, memory: 7111, loss: 1.6499, grad_norm: 1.2832
2023-10-09 13:53:14,563 - mmcls - INFO - Epoch [42][500/671]	lr: 8.226e-04, eta: 8:38:08, time: 0.500, data_time: 0.001, memory: 7111, loss: 1.5927, grad_norm: 1.2644
2023-10-09 13:54:04,275 - mmcls - INFO - Epoch [42][600/671]	lr: 8.214e-04, eta: 8:37:44, time: 0.499, data_time: 0.002, memory: 7111, loss: 1.6322, grad_norm: 1.2780
2023-10-09 13:55:31,883 - mmcls - INFO - Epoch [43][100/671]	lr: 8.193e-04, eta: 8:35:37, time: 0.523, data_time: 0.027, memory: 7111, loss: 1.5833, grad_norm: 1.3065
2023-10-09 13:56:21,680 - mmcls - INFO - Epoch [43][200/671]	lr: 8.181e-04, eta: 8:35:12, time: 0.498, data_time: 0.001, memory: 7111, loss: 1.5961, grad_norm: 1.2796
2023-10-09 13:57:09,195 - mmcls - INFO - Epoch [43][300/671]	lr: 8.170e-04, eta: 8:34:41, time: 0.475, data_time: 0.001, memory: 7111, loss: 1.5423, grad_norm: 1.1943
2023-10-09 13:57:59,068 - mmcls - INFO - Epoch [43][400/671]	lr: 8.158e-04, eta: 8:34:16, time: 0.499, data_time: 0.001, memory: 7111, loss: 1.5752, grad_norm: 1.1929
2023-10-09 13:58:49,119 - mmcls - INFO - Epoch [43][500/671]	lr: 8.145e-04, eta: 8:33:52, time: 0.501, data_time: 0.002, memory: 7111, loss: 1.6090, grad_norm: 1.2732
2023-10-09 13:59:38,902 - mmcls - INFO - Epoch [43][600/671]	lr: 8.133e-04, eta: 8:33:26, time: 0.498, data_time: 0.001, memory: 7111, loss: 1.5904, grad_norm: 1.2444
2023-10-09 14:01:06,525 - mmcls - INFO - Epoch [44][100/671]	lr: 8.113e-04, eta: 8:31:21, time: 0.522, data_time: 0.027, memory: 7111, loss: 1.5747, grad_norm: 1.2824
2023-10-09 14:01:56,384 - mmcls - INFO - Epoch [44][200/671]	lr: 8.101e-04, eta: 8:30:55, time: 0.499, data_time: 0.001, memory: 7111, loss: 1.5878, grad_norm: 1.3614
2023-10-09 14:02:44,381 - mmcls - INFO - Epoch [44][300/671]	lr: 8.088e-04, eta: 8:30:25, time: 0.480, data_time: 0.001, memory: 7111, loss: 1.6481, grad_norm: 1.2645
2023-10-09 14:03:34,178 - mmcls - INFO - Epoch [44][400/671]	lr: 8.076e-04, eta: 8:29:59, time: 0.498, data_time: 0.001, memory: 7111, loss: 1.6126, grad_norm: 1.2686
2023-10-09 14:04:24,237 - mmcls - INFO - Epoch [44][500/671]	lr: 8.064e-04, eta: 8:29:34, time: 0.501, data_time: 0.002, memory: 7111, loss: 1.6123, grad_norm: 1.2900
2023-10-09 14:05:14,240 - mmcls - INFO - Epoch [44][600/671]	lr: 8.052e-04, eta: 8:29:08, time: 0.500, data_time: 0.001, memory: 7111, loss: 1.5903, grad_norm: 1.2308
2023-10-09 14:06:42,127 - mmcls - INFO - Epoch [45][100/671]	lr: 8.031e-04, eta: 8:27:05, time: 0.523, data_time: 0.026, memory: 7111, loss: 1.5714, grad_norm: 1.3158
2023-10-09 14:07:31,980 - mmcls - INFO - Epoch [45][200/671]	lr: 8.018e-04, eta: 8:26:39, time: 0.499, data_time: 0.001, memory: 7111, loss: 1.6136, grad_norm: 1.3389
2023-10-09 14:08:19,785 - mmcls - INFO - Epoch [45][300/671]	lr: 8.006e-04, eta: 8:26:07, time: 0.478, data_time: 0.001, memory: 7111, loss: 1.6326, grad_norm: 1.2540
2023-10-09 14:09:09,811 - mmcls - INFO - Epoch [45][400/671]	lr: 7.993e-04, eta: 8:25:41, time: 0.500, data_time: 0.001, memory: 7111, loss: 1.5687, grad_norm: 1.2373
2023-10-09 14:09:59,976 - mmcls - INFO - Epoch [45][500/671]	lr: 7.981e-04, eta: 8:25:16, time: 0.502, data_time: 0.002, memory: 7111, loss: 1.5812, grad_norm: 1.3810
2023-10-09 14:10:50,021 - mmcls - INFO - Epoch [45][600/671]	lr: 7.969e-04, eta: 8:24:49, time: 0.500, data_time: 0.001, memory: 7111, loss: 1.6132, grad_norm: 1.3092
2023-10-09 14:12:17,996 - mmcls - INFO - Epoch [46][100/671]	lr: 7.947e-04, eta: 8:22:47, time: 0.525, data_time: 0.026, memory: 7111, loss: 1.5842, grad_norm: 1.2229
2023-10-09 14:13:07,978 - mmcls - INFO - Epoch [46][200/671]	lr: 7.935e-04, eta: 8:22:21, time: 0.500, data_time: 0.001, memory: 7111, loss: 1.5864, grad_norm: 1.2090
2023-10-09 14:13:55,733 - mmcls - INFO - Epoch [46][300/671]	lr: 7.922e-04, eta: 8:21:49, time: 0.478, data_time: 0.001, memory: 7111, loss: 1.5244, grad_norm: 1.3270
2023-10-09 14:14:45,692 - mmcls - INFO - Epoch [46][400/671]	lr: 7.909e-04, eta: 8:21:22, time: 0.500, data_time: 0.001, memory: 7111, loss: 1.5526, grad_norm: 1.3254
2023-10-09 14:15:35,858 - mmcls - INFO - Epoch [46][500/671]	lr: 7.897e-04, eta: 8:20:56, time: 0.502, data_time: 0.002, memory: 7111, loss: 1.5761, grad_norm: 1.2989
2023-10-09 14:16:25,896 - mmcls - INFO - Epoch [46][600/671]	lr: 7.884e-04, eta: 8:20:29, time: 0.500, data_time: 0.001, memory: 7111, loss: 1.6074, grad_norm: 1.3473
2023-10-09 14:17:53,906 - mmcls - INFO - Epoch [47][100/671]	lr: 7.862e-04, eta: 8:18:28, time: 0.524, data_time: 0.027, memory: 7111, loss: 1.6018, grad_norm: 1.3322
2023-10-09 14:18:43,749 - mmcls - INFO - Epoch [47][200/671]	lr: 7.850e-04, eta: 8:18:00, time: 0.498, data_time: 0.001, memory: 7111, loss: 1.5808, grad_norm: 1.3090
2023-10-09 14:19:31,476 - mmcls - INFO - Epoch [47][300/671]	lr: 7.837e-04, eta: 8:17:28, time: 0.477, data_time: 0.001, memory: 7111, loss: 1.5347, grad_norm: 1.3054
2023-10-09 14:20:21,545 - mmcls - INFO - Epoch [47][400/671]	lr: 7.824e-04, eta: 8:17:01, time: 0.501, data_time: 0.001, memory: 7111, loss: 1.5462, grad_norm: 1.2675
2023-10-09 14:21:11,499 - mmcls - INFO - Epoch [47][500/671]	lr: 7.811e-04, eta: 8:16:33, time: 0.500, data_time: 0.002, memory: 7111, loss: 1.6102, grad_norm: 1.2423
2023-10-09 14:22:01,466 - mmcls - INFO - Epoch [47][600/671]	lr: 7.799e-04, eta: 8:16:06, time: 0.500, data_time: 0.001, memory: 7111, loss: 1.5301, grad_norm: 1.2840
2023-10-09 14:23:29,311 - mmcls - INFO - Epoch [48][100/671]	lr: 7.777e-04, eta: 8:14:06, time: 0.524, data_time: 0.027, memory: 7111, loss: 1.5562, grad_norm: 1.2474
2023-10-09 14:24:19,208 - mmcls - INFO - Epoch [48][200/671]	lr: 7.764e-04, eta: 8:13:38, time: 0.499, data_time: 0.001, memory: 7111, loss: 1.5962, grad_norm: 1.2951
2023-10-09 14:25:06,750 - mmcls - INFO - Epoch [48][300/671]	lr: 7.751e-04, eta: 8:13:05, time: 0.475, data_time: 0.001, memory: 7111, loss: 1.6408, grad_norm: 1.2704
2023-10-09 14:25:57,165 - mmcls - INFO - Epoch [48][400/671]	lr: 7.738e-04, eta: 8:12:38, time: 0.504, data_time: 0.001, memory: 7111, loss: 1.5334, grad_norm: 1.2686
2023-10-09 14:26:47,211 - mmcls - INFO - Epoch [48][500/671]	lr: 7.725e-04, eta: 8:12:10, time: 0.500, data_time: 0.002, memory: 7111, loss: 1.5445, grad_norm: 1.2504
2023-10-09 14:27:36,782 - mmcls - INFO - Epoch [48][600/671]	lr: 7.712e-04, eta: 8:11:41, time: 0.496, data_time: 0.001, memory: 7111, loss: 1.5780, grad_norm: 1.3360
2023-10-09 14:29:04,493 - mmcls - INFO - Epoch [49][100/671]	lr: 7.689e-04, eta: 8:09:42, time: 0.523, data_time: 0.027, memory: 7111, loss: 1.5476, grad_norm: 1.2807
2023-10-09 14:29:54,386 - mmcls - INFO - Epoch [49][200/671]	lr: 7.676e-04, eta: 8:09:13, time: 0.499, data_time: 0.001, memory: 7111, loss: 1.5802, grad_norm: 1.3189
2023-10-09 14:30:42,152 - mmcls - INFO - Epoch [49][300/671]	lr: 7.663e-04, eta: 8:08:40, time: 0.478, data_time: 0.001, memory: 7111, loss: 1.5588, grad_norm: 1.1518
2023-10-09 14:31:32,145 - mmcls - INFO - Epoch [49][400/671]	lr: 7.650e-04, eta: 8:08:12, time: 0.500, data_time: 0.001, memory: 7111, loss: 1.5826, grad_norm: 1.2416
2023-10-09 14:32:22,032 - mmcls - INFO - Epoch [49][500/671]	lr: 7.637e-04, eta: 8:07:43, time: 0.499, data_time: 0.002, memory: 7111, loss: 1.6018, grad_norm: 1.2949
2023-10-09 14:33:11,977 - mmcls - INFO - Epoch [49][600/671]	lr: 7.624e-04, eta: 8:07:14, time: 0.499, data_time: 0.001, memory: 7111, loss: 1.5542, grad_norm: 1.3901
2023-10-09 14:34:40,177 - mmcls - INFO - Epoch [50][100/671]	lr: 7.601e-04, eta: 8:05:17, time: 0.523, data_time: 0.027, memory: 7111, loss: 1.5271, grad_norm: 1.2389
2023-10-09 14:35:30,098 - mmcls - INFO - Epoch [50][200/671]	lr: 7.588e-04, eta: 8:04:48, time: 0.499, data_time: 0.001, memory: 7111, loss: 1.6022, grad_norm: 1.1821
2023-10-09 14:36:07,615 - mmcls - INFO - Epoch [50][300/671]	lr: 7.575e-04, eta: 8:03:53, time: 0.375, data_time: 0.001, memory: 7111, loss: 1.5680, grad_norm: 1.2653
2023-10-09 14:36:35,556 - mmcls - INFO - Epoch [50][400/671]	lr: 7.561e-04, eta: 8:02:40, time: 0.279, data_time: 0.001, memory: 7111, loss: 1.5968, grad_norm: 1.2926
2023-10-09 14:37:02,159 - mmcls - INFO - Epoch [50][500/671]	lr: 7.548e-04, eta: 8:01:24, time: 0.266, data_time: 0.002, memory: 7111, loss: 1.5969, grad_norm: 1.2587
2023-10-09 14:37:28,599 - mmcls - INFO - Epoch [50][600/671]	lr: 7.535e-04, eta: 8:00:08, time: 0.264, data_time: 0.001, memory: 7111, loss: 1.5630, grad_norm: 1.3311
2023-10-09 14:52:31,394 - mmcls - INFO - Epoch(val) [50][256]	accuracy_top-1: 91.3593, accuracy_top-5: 99.7719
2023-10-09 14:53:22,333 - mmcls - INFO - Epoch [51][100/671]	lr: 7.512e-04, eta: 7:58:10, time: 0.509, data_time: 0.027, memory: 7111, loss: 1.5577, grad_norm: 1.2342
2023-10-09 14:54:11,030 - mmcls - INFO - Epoch [51][200/671]	lr: 7.498e-04, eta: 7:57:39, time: 0.487, data_time: 0.001, memory: 7111, loss: 1.5810, grad_norm: 1.3019
2023-10-09 14:54:59,883 - mmcls - INFO - Epoch [51][300/671]	lr: 7.485e-04, eta: 7:57:08, time: 0.489, data_time: 0.001, memory: 7111, loss: 1.5781, grad_norm: 1.3180
2023-10-09 14:55:48,796 - mmcls - INFO - Epoch [51][400/671]	lr: 7.471e-04, eta: 7:56:37, time: 0.489, data_time: 0.001, memory: 7111, loss: 1.5976, grad_norm: 1.3255
2023-10-09 14:56:38,265 - mmcls - INFO - Epoch [51][500/671]	lr: 7.458e-04, eta: 7:56:07, time: 0.495, data_time: 0.002, memory: 7111, loss: 1.5576, grad_norm: 1.2360
2023-10-09 14:57:27,877 - mmcls - INFO - Epoch [51][600/671]	lr: 7.444e-04, eta: 7:55:37, time: 0.496, data_time: 0.001, memory: 7111, loss: 1.5564, grad_norm: 1.2122
2023-10-09 14:58:54,778 - mmcls - INFO - Epoch [52][100/671]	lr: 7.421e-04, eta: 7:53:43, time: 0.527, data_time: 0.027, memory: 7111, loss: 1.5430, grad_norm: 1.2528
2023-10-09 14:59:44,991 - mmcls - INFO - Epoch [52][200/671]	lr: 7.408e-04, eta: 7:53:15, time: 0.502, data_time: 0.001, memory: 7111, loss: 1.5611, grad_norm: 1.3075
2023-10-09 15:00:34,884 - mmcls - INFO - Epoch [52][300/671]	lr: 7.394e-04, eta: 7:52:45, time: 0.499, data_time: 0.001, memory: 7111, loss: 1.5903, grad_norm: 1.2862
2023-10-09 15:01:24,792 - mmcls - INFO - Epoch [52][400/671]	lr: 7.380e-04, eta: 7:52:16, time: 0.499, data_time: 0.001, memory: 7111, loss: 1.5680, grad_norm: 1.2621
2023-10-09 15:02:14,409 - mmcls - INFO - Epoch [52][500/671]	lr: 7.367e-04, eta: 7:51:46, time: 0.496, data_time: 0.002, memory: 7111, loss: 1.5651, grad_norm: 1.2977
2023-10-09 15:03:03,953 - mmcls - INFO - Epoch [52][600/671]	lr: 7.353e-04, eta: 7:51:15, time: 0.495, data_time: 0.001, memory: 7111, loss: 1.5622, grad_norm: 1.2796
2023-10-09 15:04:28,924 - mmcls - INFO - Epoch [53][100/671]	lr: 7.330e-04, eta: 7:49:20, time: 0.513, data_time: 0.027, memory: 7111, loss: 1.5679, grad_norm: 1.3459
2023-10-09 15:05:17,589 - mmcls - INFO - Epoch [53][200/671]	lr: 7.316e-04, eta: 7:48:48, time: 0.487, data_time: 0.001, memory: 7111, loss: 1.5494, grad_norm: 1.3245
2023-10-09 15:06:06,247 - mmcls - INFO - Epoch [53][300/671]	lr: 7.302e-04, eta: 7:48:16, time: 0.487, data_time: 0.001, memory: 7111, loss: 1.5546, grad_norm: 1.3037
2023-10-09 15:06:54,831 - mmcls - INFO - Epoch [53][400/671]	lr: 7.289e-04, eta: 7:47:43, time: 0.486, data_time: 0.001, memory: 7111, loss: 1.5508, grad_norm: 1.2896
2023-10-09 15:07:43,478 - mmcls - INFO - Epoch [53][500/671]	lr: 7.275e-04, eta: 7:47:11, time: 0.486, data_time: 0.002, memory: 7111, loss: 1.5780, grad_norm: 1.2966
2023-10-09 15:08:31,997 - mmcls - INFO - Epoch [53][600/671]	lr: 7.261e-04, eta: 7:46:38, time: 0.485, data_time: 0.001, memory: 7111, loss: 1.5791, grad_norm: 1.2415
2023-10-09 15:09:56,478 - mmcls - INFO - Epoch [54][100/671]	lr: 7.237e-04, eta: 7:44:44, time: 0.513, data_time: 0.027, memory: 7111, loss: 1.5759, grad_norm: 1.3106
2023-10-09 15:10:45,033 - mmcls - INFO - Epoch [54][200/671]	lr: 7.223e-04, eta: 7:44:12, time: 0.486, data_time: 0.001, memory: 7111, loss: 1.5428, grad_norm: 1.3652
2023-10-09 15:11:33,422 - mmcls - INFO - Epoch [54][300/671]	lr: 7.209e-04, eta: 7:43:39, time: 0.484, data_time: 0.001, memory: 7111, loss: 1.5700, grad_norm: 1.2576
2023-10-09 15:12:21,901 - mmcls - INFO - Epoch [54][400/671]	lr: 7.196e-04, eta: 7:43:06, time: 0.485, data_time: 0.001, memory: 7111, loss: 1.5578, grad_norm: 1.1693
2023-10-09 15:13:10,476 - mmcls - INFO - Epoch [54][500/671]	lr: 7.182e-04, eta: 7:42:33, time: 0.486, data_time: 0.002, memory: 7111, loss: 1.5358, grad_norm: 1.3475
2023-10-09 15:13:59,023 - mmcls - INFO - Epoch [54][600/671]	lr: 7.168e-04, eta: 7:42:00, time: 0.485, data_time: 0.001, memory: 7111, loss: 1.5477, grad_norm: 1.2748
2023-10-09 15:15:23,533 - mmcls - INFO - Epoch [55][100/671]	lr: 7.144e-04, eta: 7:40:06, time: 0.511, data_time: 0.027, memory: 7111, loss: 1.5804, grad_norm: 1.2878
2023-10-09 15:16:12,111 - mmcls - INFO - Epoch [55][200/671]	lr: 7.130e-04, eta: 7:39:33, time: 0.486, data_time: 0.001, memory: 7111, loss: 1.5317, grad_norm: 1.3652
2023-10-09 15:17:00,565 - mmcls - INFO - Epoch [55][300/671]	lr: 7.116e-04, eta: 7:39:00, time: 0.485, data_time: 0.001, memory: 7111, loss: 1.5409, grad_norm: 1.2681
2023-10-09 15:17:49,056 - mmcls - INFO - Epoch [55][400/671]	lr: 7.102e-04, eta: 7:38:27, time: 0.485, data_time: 0.001, memory: 7111, loss: 1.5381, grad_norm: 1.3000
2023-10-09 15:18:37,130 - mmcls - INFO - Epoch [55][500/671]	lr: 7.088e-04, eta: 7:37:53, time: 0.481, data_time: 0.002, memory: 7111, loss: 1.5697, grad_norm: 1.2909
2023-10-09 15:19:25,566 - mmcls - INFO - Epoch [55][600/671]	lr: 7.074e-04, eta: 7:37:19, time: 0.484, data_time: 0.001, memory: 7111, loss: 1.5715, grad_norm: 1.3210
2023-10-09 15:20:50,560 - mmcls - INFO - Epoch [56][100/671]	lr: 7.049e-04, eta: 7:35:27, time: 0.509, data_time: 0.027, memory: 7111, loss: 1.5528, grad_norm: 1.2981
2023-10-09 15:21:39,004 - mmcls - INFO - Epoch [56][200/671]	lr: 7.035e-04, eta: 7:34:53, time: 0.484, data_time: 0.001, memory: 7111, loss: 1.5299, grad_norm: 1.4177
2023-10-09 15:22:27,466 - mmcls - INFO - Epoch [56][300/671]	lr: 7.021e-04, eta: 7:34:20, time: 0.485, data_time: 0.001, memory: 7111, loss: 1.5431, grad_norm: 1.2772
2023-10-09 15:23:16,115 - mmcls - INFO - Epoch [56][400/671]	lr: 7.007e-04, eta: 7:33:47, time: 0.486, data_time: 0.001, memory: 7111, loss: 1.5572, grad_norm: 1.2700
2023-10-09 15:24:04,566 - mmcls - INFO - Epoch [56][500/671]	lr: 6.993e-04, eta: 7:33:13, time: 0.485, data_time: 0.002, memory: 7111, loss: 1.5994, grad_norm: 1.2809
2023-10-09 15:24:53,207 - mmcls - INFO - Epoch [56][600/671]	lr: 6.978e-04, eta: 7:32:39, time: 0.486, data_time: 0.001, memory: 7111, loss: 1.5243, grad_norm: 1.2389
2023-10-09 15:26:18,015 - mmcls - INFO - Epoch [57][100/671]	lr: 6.954e-04, eta: 7:30:48, time: 0.509, data_time: 0.026, memory: 7111, loss: 1.5553, grad_norm: 1.2290
2023-10-09 15:27:06,614 - mmcls - INFO - Epoch [57][200/671]	lr: 6.940e-04, eta: 7:30:14, time: 0.486, data_time: 0.001, memory: 7111, loss: 1.4997, grad_norm: 1.2339
2023-10-09 15:27:55,174 - mmcls - INFO - Epoch [57][300/671]	lr: 6.926e-04, eta: 7:29:41, time: 0.486, data_time: 0.001, memory: 7111, loss: 1.5190, grad_norm: 1.2676
2023-10-09 15:28:43,558 - mmcls - INFO - Epoch [57][400/671]	lr: 6.911e-04, eta: 7:29:07, time: 0.484, data_time: 0.001, memory: 7111, loss: 1.5425, grad_norm: 1.1423
2023-10-09 15:29:31,968 - mmcls - INFO - Epoch [57][500/671]	lr: 6.897e-04, eta: 7:28:32, time: 0.484, data_time: 0.002, memory: 7111, loss: 1.5352, grad_norm: 1.2064
2023-10-09 15:30:20,383 - mmcls - INFO - Epoch [57][600/671]	lr: 6.883e-04, eta: 7:27:58, time: 0.484, data_time: 0.001, memory: 7111, loss: 1.5198, grad_norm: 1.3060
2023-10-09 15:31:45,385 - mmcls - INFO - Epoch [58][100/671]	lr: 6.858e-04, eta: 7:26:08, time: 0.512, data_time: 0.027, memory: 7111, loss: 1.5261, grad_norm: 1.2548
2023-10-09 15:32:33,988 - mmcls - INFO - Epoch [58][200/671]	lr: 6.844e-04, eta: 7:25:35, time: 0.486, data_time: 0.001, memory: 7111, loss: 1.5430, grad_norm: 1.2952
2023-10-09 15:33:22,345 - mmcls - INFO - Epoch [58][300/671]	lr: 6.829e-04, eta: 7:25:00, time: 0.484, data_time: 0.001, memory: 7111, loss: 1.5011, grad_norm: 1.2246
2023-10-09 15:34:10,912 - mmcls - INFO - Epoch [58][400/671]	lr: 6.815e-04, eta: 7:24:26, time: 0.486, data_time: 0.001, memory: 7111, loss: 1.5749, grad_norm: 1.3053
2023-10-09 15:34:59,577 - mmcls - INFO - Epoch [58][500/671]	lr: 6.800e-04, eta: 7:23:52, time: 0.487, data_time: 0.002, memory: 7111, loss: 1.5473, grad_norm: 1.3271
2023-10-09 15:35:48,117 - mmcls - INFO - Epoch [58][600/671]	lr: 6.786e-04, eta: 7:23:18, time: 0.485, data_time: 0.001, memory: 7111, loss: 1.6035, grad_norm: 1.2971
2023-10-09 15:37:13,362 - mmcls - INFO - Epoch [59][100/671]	lr: 6.761e-04, eta: 7:21:29, time: 0.510, data_time: 0.027, memory: 7111, loss: 1.5159, grad_norm: 1.3014
2023-10-09 15:38:01,864 - mmcls - INFO - Epoch [59][200/671]	lr: 6.747e-04, eta: 7:20:54, time: 0.485, data_time: 0.001, memory: 7111, loss: 1.5180, grad_norm: 1.2390
2023-10-09 15:38:50,408 - mmcls - INFO - Epoch [59][300/671]	lr: 6.732e-04, eta: 7:20:20, time: 0.485, data_time: 0.001, memory: 7111, loss: 1.5502, grad_norm: 1.2829
2023-10-09 15:39:38,919 - mmcls - INFO - Epoch [59][400/671]	lr: 6.718e-04, eta: 7:19:46, time: 0.485, data_time: 0.001, memory: 7111, loss: 1.5406, grad_norm: 1.2006
2023-10-09 15:40:27,581 - mmcls - INFO - Epoch [59][500/671]	lr: 6.703e-04, eta: 7:19:11, time: 0.487, data_time: 0.003, memory: 7111, loss: 1.5408, grad_norm: 1.2778
2023-10-09 15:41:16,204 - mmcls - INFO - Epoch [59][600/671]	lr: 6.688e-04, eta: 7:18:37, time: 0.486, data_time: 0.001, memory: 7111, loss: 1.5612, grad_norm: 1.3320
2023-10-09 15:42:42,144 - mmcls - INFO - Epoch [60][100/671]	lr: 6.663e-04, eta: 7:16:50, time: 0.517, data_time: 0.027, memory: 7111, loss: 1.4933, grad_norm: 1.2495
2023-10-09 15:43:30,617 - mmcls - INFO - Epoch [60][200/671]	lr: 6.649e-04, eta: 7:16:15, time: 0.485, data_time: 0.001, memory: 7111, loss: 1.5314, grad_norm: 1.2717
2023-10-09 15:44:18,593 - mmcls - INFO - Epoch [60][300/671]	lr: 6.634e-04, eta: 7:15:40, time: 0.480, data_time: 0.001, memory: 7111, loss: 1.5592, grad_norm: 1.3134
2023-10-09 15:45:07,190 - mmcls - INFO - Epoch [60][400/671]	lr: 6.620e-04, eta: 7:15:05, time: 0.486, data_time: 0.001, memory: 7111, loss: 1.5211, grad_norm: 1.2317
2023-10-09 15:45:55,631 - mmcls - INFO - Epoch [60][500/671]	lr: 6.605e-04, eta: 7:14:30, time: 0.484, data_time: 0.002, memory: 7111, loss: 1.5555, grad_norm: 1.2456
2023-10-09 15:46:44,316 - mmcls - INFO - Epoch [60][600/671]	lr: 6.590e-04, eta: 7:13:56, time: 0.487, data_time: 0.001, memory: 7111, loss: 1.5467, grad_norm: 1.3369
2023-10-09 15:47:18,877 - mmcls - INFO - Saving checkpoint at 60 epochs
2023-10-09 15:47:54,735 - mmcls - INFO - Epoch(val) [60][256]	accuracy_top-1: 92.0500, accuracy_top-5: 99.8697
2023-10-09 15:48:47,539 - mmcls - INFO - Epoch [61][100/671]	lr: 6.565e-04, eta: 7:12:08, time: 0.511, data_time: 0.026, memory: 7111, loss: 1.5203, grad_norm: 1.2864
2023-10-09 15:49:36,198 - mmcls - INFO - Epoch [61][200/671]	lr: 6.550e-04, eta: 7:11:34, time: 0.487, data_time: 0.001, memory: 7111, loss: 1.5006, grad_norm: 1.2840
2023-10-09 15:50:24,676 - mmcls - INFO - Epoch [61][300/671]	lr: 6.536e-04, eta: 7:10:59, time: 0.485, data_time: 0.001, memory: 7111, loss: 1.4980, grad_norm: 1.2476
2023-10-09 15:51:13,154 - mmcls - INFO - Epoch [61][400/671]	lr: 6.521e-04, eta: 7:10:24, time: 0.485, data_time: 0.001, memory: 7111, loss: 1.5456, grad_norm: 1.2108
2023-10-09 15:52:01,873 - mmcls - INFO - Epoch [61][500/671]	lr: 6.506e-04, eta: 7:09:49, time: 0.487, data_time: 0.002, memory: 7111, loss: 1.5748, grad_norm: 1.1790
2023-10-09 15:52:50,397 - mmcls - INFO - Epoch [61][600/671]	lr: 6.491e-04, eta: 7:09:14, time: 0.485, data_time: 0.001, memory: 7111, loss: 1.5388, grad_norm: 1.3660
