{"env_info": "sys.platform: linux\nPython: 3.8.17 | packaged by conda-forge | (default, Jun 16 2023, 07:06:00) [GCC 11.4.0]\nCUDA available: True\nGPU 0,1: NVIDIA GeForce RTX 3090\nCUDA_HOME: /usr/local/cuda-11.6\nNVCC: Build cuda_11.6.r11.6/compiler.31057947_0\nGCC: gcc (GCC) 7.3.0\nPyTorch: 1.8.0+cu111\nPyTorch compiling details: PyTorch built with:\n  - GCC 7.3\n  - C++ Version: 201402\n  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n  - Intel(R) MKL-DNN v1.7.0 (Git Hash 7aed236906b1f7a05c0917e5257a1af05e9ff683)\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n  - NNPACK is enabled\n  - CPU capability usage: AVX2\n  - CUDA Runtime 11.1\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n  - CuDNN 8.0.5\n  - Magma 2.5.2\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.8.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n\nTorchVision: 0.9.0+cu111\nOpenCV: 4.8.0\nMMCV: 1.4.2\nMMCV Compiler: n/a\nMMCV CUDA Compiler: n/a\nMMClassification: 0.24.0+", "seed": 320190695, "mmcls_version": "0.24.0", "config": "train_data_root = '/data4/lj/forgery_Detect/Forgery_train_20231106'\ntest_data_root = '/data4/lj/forgery_Detect/Forgery_test_20231106'\nwork_dir = 'work_dirs/swin_tiny/FP/11_13'\nnum_classes = 2\nbatch_size = 70\nmax_epochs = 200\ninterval_save = 50\nmodel = dict(\n    type='ImageClassifier',\n    backbone=dict(\n        type='SwinTransformer',\n        arch='tiny',\n        init_cfg=dict(\n            type='Pretrained',\n            checkpoint=\n            'pretrain_model/swin_tiny_224_b16x64_300e_imagenet_20210616_090925-66df6be6.pth',\n            prefix='backbone'),\n        img_size=224,\n        drop_path_rate=0.2),\n    neck=dict(type='GlobalAveragePooling'),\n    head=dict(\n        type='LinearClsHead',\n        num_classes=2,\n        in_channels=768,\n        init_cfg=None,\n        loss=dict(type='FocalLoss', gamma=2.0, alpha=0.25, reduction='mean'),\n        cal_acc=False),\n    init_cfg=[\n        dict(type='TruncNormal', layer='Linear', std=0.02, bias=0.0),\n        dict(type='Constant', layer='LayerNorm', val=1.0, bias=0.0)\n    ])\ndataset_type = 'CustomDataset'\nimg_norm_cfg = dict(\n    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\ntrain_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(type='Rotate', angle=8.0, interpolation='bicubic'),\n    dict(\n        type='Rotate',\n        angle=90.0,\n        interpolation='bicubic',\n        prob=0.1,\n        random_negative_prob=0.5),\n    dict(\n        type='Rotate',\n        angle=180.0,\n        interpolation='bicubic',\n        prob=0.1,\n        random_negative_prob=0.5),\n    dict(type='Resize', size=224),\n    dict(\n        type='Normalize',\n        mean=[123.675, 116.28, 103.53],\n        std=[58.395, 57.12, 57.375],\n        to_rgb=True),\n    dict(type='ImageToTensor', keys=['img']),\n    dict(type='ToTensor', keys=['gt_label']),\n    dict(type='Collect', keys=['img', 'gt_label'])\n]\ntest_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(type='Resize', size=224),\n    dict(\n        type='Normalize',\n        mean=[123.675, 116.28, 103.53],\n        std=[58.395, 57.12, 57.375],\n        to_rgb=True),\n    dict(type='ImageToTensor', keys=['img']),\n    dict(type='Collect', keys=['img'])\n]\ndata = dict(\n    samples_per_gpu=190,\n    workers_per_gpu=4,\n    train=dict(\n        type='CustomDataset',\n        data_prefix='/data4/lj/forgery_Detect/Forgery_train_20231113',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(type='Rotate', angle=8.0, interpolation='bicubic'),\n            dict(\n                type='Rotate',\n                angle=90.0,\n                interpolation='bicubic',\n                prob=0.1,\n                random_negative_prob=0.5),\n            dict(\n                type='Rotate',\n                angle=180.0,\n                interpolation='bicubic',\n                prob=0.1,\n                random_negative_prob=0.5),\n            dict(type='Resize', size=224),\n            dict(\n                type='Normalize',\n                mean=[123.675, 116.28, 103.53],\n                std=[58.395, 57.12, 57.375],\n                to_rgb=True),\n            dict(type='ImageToTensor', keys=['img']),\n            dict(type='ToTensor', keys=['gt_label']),\n            dict(type='Collect', keys=['img', 'gt_label'])\n        ],\n        Batch_size=190),\n    val=dict(\n        type='CustomDataset',\n        data_prefix='/data4/lj/forgery_Detect/Forgery_test_20231113',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(type='Resize', size=224),\n            dict(\n                type='Normalize',\n                mean=[123.675, 116.28, 103.53],\n                std=[58.395, 57.12, 57.375],\n                to_rgb=True),\n            dict(type='ImageToTensor', keys=['img']),\n            dict(type='Collect', keys=['img'])\n        ]),\n    test=dict(\n        type='CustomDataset',\n        data_prefix='/data4/lj/forgery_Detect/Forgery_test_20231113',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(type='Resize', size=224),\n            dict(\n                type='Normalize',\n                mean=[123.675, 116.28, 103.53],\n                std=[58.395, 57.12, 57.375],\n                to_rgb=True),\n            dict(type='ImageToTensor', keys=['img']),\n            dict(type='Collect', keys=['img'])\n        ]))\nevaluation = dict(interval=10, metric='accuracy')\nparamwise_cfg = dict(\n    norm_decay_mult=0.0,\n    bias_decay_mult=0.0,\n    custom_keys=dict({\n        '.absolute_pos_embed': dict(decay_mult=0.0),\n        '.relative_position_bias_table': dict(decay_mult=0.0)\n    }))\noptimizer = dict(\n    type='AdamW',\n    lr=0.001,\n    weight_decay=0.01,\n    eps=1e-08,\n    betas=(0.9, 0.999),\n    paramwise_cfg=dict(\n        norm_decay_mult=0.0,\n        bias_decay_mult=0.0,\n        custom_keys=dict({\n            '.absolute_pos_embed': dict(decay_mult=0.0),\n            '.relative_position_bias_table': dict(decay_mult=0.0)\n        })))\noptimizer_config = dict(grad_clip=dict(max_norm=5.0))\nlr_config = dict(\n    policy='CosineAnnealing',\n    by_epoch=False,\n    min_lr_ratio=0.005,\n    warmup='linear',\n    warmup_ratio=0.001,\n    warmup_iters=20,\n    warmup_by_epoch=True)\nrunner = dict(type='EpochBasedRunner', max_epochs=200)\ncheckpoint_config = dict(interval=10, save_optimizer=True)\nlog_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\ndist_params = dict(backend='nccl')\nlog_level = 'INFO'\nload_from = None\nresume_from = None\nworkflow = [('train', 1)]\ngpu_ids = range(0, 2)\ndevice = 'cuda'\nseed = 320190695\n", "CLASSES": ["qualified", "unqualified"]}
{"mode": "train", "epoch": 1, "iter": 50, "lr": 1e-05, "memory": 21614, "data_time": 3.96248, "loss": 0.06987, "time": 6.88499}
{"mode": "train", "epoch": 1, "iter": 100, "lr": 3e-05, "memory": 21614, "data_time": 0.21638, "loss": 0.00585, "time": 7.18015}
{"mode": "train", "epoch": 1, "iter": 150, "lr": 4e-05, "memory": 21614, "data_time": 0.00099, "loss": 0.00202, "time": 7.32805}
{"mode": "train", "epoch": 2, "iter": 50, "lr": 6e-05, "memory": 21614, "data_time": 0.8804, "loss": 0.00109, "time": 1.76762}
{"mode": "train", "epoch": 2, "iter": 100, "lr": 8e-05, "memory": 21614, "data_time": 0.55269, "loss": 0.00069, "time": 1.57553}
{"mode": "train", "epoch": 2, "iter": 150, "lr": 9e-05, "memory": 21614, "data_time": 0.38456, "loss": 0.00081, "time": 1.66299}
{"mode": "train", "epoch": 3, "iter": 50, "lr": 0.00011, "memory": 21614, "data_time": 1.1012, "loss": 0.0006, "time": 1.82261}
{"mode": "train", "epoch": 3, "iter": 100, "lr": 0.00013, "memory": 21614, "data_time": 0.89417, "loss": 0.00084, "time": 1.61033}
{"mode": "train", "epoch": 3, "iter": 150, "lr": 0.00014, "memory": 21614, "data_time": 0.94435, "loss": 0.00103, "time": 1.6609}
{"mode": "train", "epoch": 4, "iter": 50, "lr": 0.00016, "memory": 21614, "data_time": 0.68499, "loss": 0.00053, "time": 1.75028}
{"mode": "train", "epoch": 4, "iter": 100, "lr": 0.00018, "memory": 21614, "data_time": 0.14191, "loss": 0.00068, "time": 1.57323}
{"mode": "train", "epoch": 4, "iter": 150, "lr": 0.00019, "memory": 21614, "data_time": 0.00099, "loss": 0.00031, "time": 1.592}
{"mode": "train", "epoch": 5, "iter": 50, "lr": 0.00021, "memory": 21614, "data_time": 0.7801, "loss": 0.00056, "time": 1.79103}
{"mode": "train", "epoch": 5, "iter": 100, "lr": 0.00023, "memory": 21614, "data_time": 0.17985, "loss": 0.00131, "time": 1.55613}
{"mode": "train", "epoch": 5, "iter": 150, "lr": 0.00024, "memory": 21614, "data_time": 0.32847, "loss": 0.0006, "time": 1.6218}
{"mode": "train", "epoch": 6, "iter": 50, "lr": 0.00026, "memory": 21614, "data_time": 0.95514, "loss": 0.00087, "time": 1.74218}
{"mode": "train", "epoch": 6, "iter": 100, "lr": 0.00028, "memory": 21614, "data_time": 0.60481, "loss": 0.00087, "time": 1.563}
{"mode": "train", "epoch": 6, "iter": 150, "lr": 0.00029, "memory": 21614, "data_time": 0.70901, "loss": 0.00098, "time": 1.66145}
{"mode": "train", "epoch": 7, "iter": 50, "lr": 0.00031, "memory": 21614, "data_time": 1.08111, "loss": 0.00145, "time": 1.80613}
{"mode": "train", "epoch": 7, "iter": 100, "lr": 0.00033, "memory": 21614, "data_time": 0.8943, "loss": 0.00048, "time": 1.61217}
{"mode": "train", "epoch": 7, "iter": 150, "lr": 0.00034, "memory": 21614, "data_time": 0.87924, "loss": 0.00157, "time": 1.59812}
{"mode": "train", "epoch": 8, "iter": 50, "lr": 0.00036, "memory": 21614, "data_time": 0.79488, "loss": 0.00452, "time": 1.74575}
{"mode": "train", "epoch": 8, "iter": 100, "lr": 0.00037, "memory": 21614, "data_time": 0.36441, "loss": 0.00264, "time": 1.55854}
{"mode": "train", "epoch": 8, "iter": 150, "lr": 0.00039, "memory": 21614, "data_time": 0.42758, "loss": 0.00134, "time": 1.62144}
{"mode": "train", "epoch": 9, "iter": 50, "lr": 0.00041, "memory": 21614, "data_time": 0.947, "loss": 0.00129, "time": 1.76298}
{"mode": "train", "epoch": 9, "iter": 100, "lr": 0.00042, "memory": 21614, "data_time": 0.59487, "loss": 0.00138, "time": 1.55604}
{"mode": "train", "epoch": 9, "iter": 150, "lr": 0.00044, "memory": 21614, "data_time": 0.76204, "loss": 0.0013, "time": 1.6183}
{"mode": "train", "epoch": 10, "iter": 50, "lr": 0.00046, "memory": 21614, "data_time": 0.69828, "loss": 0.00135, "time": 1.78699}
{"mode": "train", "epoch": 10, "iter": 100, "lr": 0.00047, "memory": 21614, "data_time": 0.17702, "loss": 0.0006, "time": 1.55521}
{"mode": "train", "epoch": 10, "iter": 150, "lr": 0.00049, "memory": 21614, "data_time": 0.02056, "loss": 0.00145, "time": 1.61727}
{"mode": "val", "epoch": 10, "iter": 22, "lr": 0.0005, "accuracy_top-1": 99.87839, "accuracy_top-2": 100.0}
{"mode": "train", "epoch": 11, "iter": 50, "lr": 0.00051, "memory": 21614, "data_time": 1.10208, "loss": 0.00556, "time": 1.82042}
{"mode": "train", "epoch": 11, "iter": 100, "lr": 0.00052, "memory": 21614, "data_time": 0.77976, "loss": 0.00287, "time": 1.54991}
{"mode": "train", "epoch": 11, "iter": 150, "lr": 0.00053, "memory": 21614, "data_time": 0.91319, "loss": 0.00205, "time": 1.64411}
{"mode": "train", "epoch": 12, "iter": 50, "lr": 0.00056, "memory": 21614, "data_time": 1.02231, "loss": 0.00112, "time": 1.78876}
{"mode": "train", "epoch": 12, "iter": 100, "lr": 0.00057, "memory": 21614, "data_time": 0.58657, "loss": 0.0009, "time": 1.59528}
{"mode": "train", "epoch": 12, "iter": 150, "lr": 0.00058, "memory": 21614, "data_time": 0.75148, "loss": 0.00157, "time": 1.61755}
{"mode": "train", "epoch": 13, "iter": 50, "lr": 0.00061, "memory": 21614, "data_time": 0.98211, "loss": 0.00224, "time": 1.76996}
{"mode": "train", "epoch": 13, "iter": 100, "lr": 0.00062, "memory": 21614, "data_time": 0.83599, "loss": 0.0022, "time": 1.55876}
{"mode": "train", "epoch": 13, "iter": 150, "lr": 0.00063, "memory": 21614, "data_time": 0.96434, "loss": 0.00174, "time": 1.6889}
{"mode": "train", "epoch": 14, "iter": 50, "lr": 0.00066, "memory": 21614, "data_time": 0.78246, "loss": 0.00139, "time": 1.82733}
{"mode": "train", "epoch": 14, "iter": 100, "lr": 0.00067, "memory": 21614, "data_time": 0.55664, "loss": 0.00142, "time": 1.55239}
{"mode": "train", "epoch": 14, "iter": 150, "lr": 0.00068, "memory": 21614, "data_time": 0.75664, "loss": 0.00132, "time": 1.61801}
{"mode": "train", "epoch": 15, "iter": 50, "lr": 0.0007, "memory": 21614, "data_time": 0.98201, "loss": 0.00216, "time": 1.79973}
{"mode": "train", "epoch": 15, "iter": 100, "lr": 0.00072, "memory": 21614, "data_time": 0.5922, "loss": 0.00238, "time": 1.62011}
{"mode": "train", "epoch": 15, "iter": 150, "lr": 0.00073, "memory": 21614, "data_time": 0.66989, "loss": 0.00164, "time": 1.67032}
{"mode": "train", "epoch": 16, "iter": 50, "lr": 0.00075, "memory": 21614, "data_time": 0.95912, "loss": 0.00172, "time": 1.78883}
{"mode": "train", "epoch": 16, "iter": 100, "lr": 0.00076, "memory": 21614, "data_time": 0.57934, "loss": 0.00158, "time": 1.54357}
{"mode": "train", "epoch": 16, "iter": 150, "lr": 0.00078, "memory": 21614, "data_time": 0.64372, "loss": 0.00086, "time": 1.60901}
{"mode": "train", "epoch": 17, "iter": 50, "lr": 0.0008, "memory": 21614, "data_time": 0.62079, "loss": 0.00098, "time": 1.75841}
{"mode": "train", "epoch": 17, "iter": 100, "lr": 0.00081, "memory": 21614, "data_time": 0.07213, "loss": 0.00084, "time": 1.54641}
{"mode": "train", "epoch": 17, "iter": 150, "lr": 0.00082, "memory": 21614, "data_time": 0.0283, "loss": 0.0016, "time": 1.6113}
{"mode": "train", "epoch": 18, "iter": 50, "lr": 0.00085, "memory": 21614, "data_time": 0.8002, "loss": 0.00057, "time": 1.76831}
{"mode": "train", "epoch": 18, "iter": 100, "lr": 0.00086, "memory": 21614, "data_time": 0.15601, "loss": 0.00104, "time": 1.5658}
{"mode": "train", "epoch": 18, "iter": 150, "lr": 0.00087, "memory": 21614, "data_time": 0.00105, "loss": 0.00089, "time": 1.5659}
{"mode": "train", "epoch": 19, "iter": 50, "lr": 0.00089, "memory": 21614, "data_time": 0.83545, "loss": 0.00115, "time": 1.76544}
{"mode": "train", "epoch": 19, "iter": 100, "lr": 0.00091, "memory": 21614, "data_time": 0.7754, "loss": 0.00182, "time": 1.57896}
{"mode": "train", "epoch": 19, "iter": 150, "lr": 0.00092, "memory": 21614, "data_time": 0.85906, "loss": 0.00223, "time": 1.60076}
{"mode": "train", "epoch": 20, "iter": 50, "lr": 0.00094, "memory": 21614, "data_time": 0.9304, "loss": 0.00254, "time": 1.76434}
{"mode": "train", "epoch": 20, "iter": 100, "lr": 0.00095, "memory": 21614, "data_time": 0.69337, "loss": 0.14883, "time": 1.5302}
{"mode": "train", "epoch": 20, "iter": 150, "lr": 0.00096, "memory": 21614, "data_time": 0.73918, "loss": 0.13116, "time": 1.58628}
{"mode": "val", "epoch": 20, "iter": 22, "lr": 0.00098, "accuracy_top-1": 68.27192, "accuracy_top-2": 100.0}
{"mode": "train", "epoch": 21, "iter": 50, "lr": 0.00098, "memory": 21614, "data_time": 0.86423, "loss": 0.13164, "time": 1.76306}
{"mode": "train", "epoch": 21, "iter": 100, "lr": 0.00097, "memory": 21614, "data_time": 0.687, "loss": 0.13145, "time": 1.56954}
{"mode": "train", "epoch": 21, "iter": 150, "lr": 0.00097, "memory": 21614, "data_time": 0.78877, "loss": 0.13215, "time": 1.61904}
{"mode": "train", "epoch": 22, "iter": 50, "lr": 0.00097, "memory": 21614, "data_time": 0.88461, "loss": 0.13151, "time": 1.75478}
{"mode": "train", "epoch": 22, "iter": 100, "lr": 0.00097, "memory": 21614, "data_time": 0.17762, "loss": 0.13248, "time": 1.56832}
{"mode": "train", "epoch": 22, "iter": 150, "lr": 0.00097, "memory": 21614, "data_time": 0.03015, "loss": 0.13098, "time": 1.61838}
{"mode": "train", "epoch": 23, "iter": 50, "lr": 0.00097, "memory": 21614, "data_time": 0.96331, "loss": 0.13176, "time": 1.78326}
{"mode": "train", "epoch": 23, "iter": 100, "lr": 0.00097, "memory": 21614, "data_time": 0.84591, "loss": 0.13155, "time": 1.58338}
{"mode": "train", "epoch": 23, "iter": 150, "lr": 0.00097, "memory": 21614, "data_time": 0.83234, "loss": 0.13096, "time": 1.59685}
{"mode": "train", "epoch": 24, "iter": 50, "lr": 0.00097, "memory": 21614, "data_time": 0.73772, "loss": 0.1319, "time": 1.77816}
{"mode": "train", "epoch": 24, "iter": 100, "lr": 0.00097, "memory": 21614, "data_time": 0.54632, "loss": 0.13219, "time": 1.58455}
{"mode": "train", "epoch": 24, "iter": 150, "lr": 0.00097, "memory": 21614, "data_time": 0.89387, "loss": 0.13109, "time": 1.65038}
{"mode": "train", "epoch": 25, "iter": 50, "lr": 0.00096, "memory": 21614, "data_time": 0.59901, "loss": 0.13204, "time": 1.78538}
{"mode": "train", "epoch": 25, "iter": 100, "lr": 0.00096, "memory": 21614, "data_time": 0.02737, "loss": 0.13104, "time": 1.56959}
{"mode": "train", "epoch": 25, "iter": 150, "lr": 0.00096, "memory": 21614, "data_time": 0.00099, "loss": 0.13152, "time": 1.62273}
