2023-11-08 11:03:33,461 - mmcls - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.17 | packaged by conda-forge | (default, Jun 16 2023, 07:06:00) [GCC 11.4.0]
CUDA available: True
GPU 0: NVIDIA GeForce RTX 3090
CUDA_HOME: /usr/local/cuda-11.6
NVCC: Build cuda_11.6.r11.6/compiler.31057947_0
GCC: gcc (GCC) 7.3.0
PyTorch: 1.8.0+cu111
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.7.0 (Git Hash 7aed236906b1f7a05c0917e5257a1af05e9ff683)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.8.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.9.0+cu111
OpenCV: 4.8.0
MMCV: 1.4.2
MMCV Compiler: n/a
MMCV CUDA Compiler: n/a
MMClassification: 0.24.0+
------------------------------------------------------------

2023-11-08 11:03:33,462 - mmcls - INFO - Distributed training: False
2023-11-08 11:03:34,476 - mmcls - INFO - Config:
model = dict(
    type='ImageClassifier',
    backbone=dict(
        type='SwinTransformer',
        arch='tiny',
        init_cfg=dict(
            type='Pretrained',
            checkpoint=
            '/data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth',
            prefix='backbone'),
        img_size=224,
        drop_path_rate=0.2),
    neck=dict(type='GlobalAveragePooling'),
    head=dict(
        type='LinearClsHead',
        num_classes=44,
        in_channels=768,
        init_cfg=None,
        loss=dict(
            type='LabelSmoothLoss', label_smooth_val=0.1, mode='original'),
        cal_acc=False),
    init_cfg=[
        dict(type='TruncNormal', layer='Linear', std=0.02, bias=0.0),
        dict(type='Constant', layer='LayerNorm', val=1.0, bias=0.0)
    ],
    train_cfg=dict(augments=[
        dict(type='BatchMixup', alpha=0.8, num_classes=44, prob=0.5),
        dict(type='BatchCutMix', alpha=1.0, num_classes=44, prob=0.5)
    ]))
rand_increasing_policies = [
    dict(type='AutoContrast'),
    dict(type='Equalize'),
    dict(type='Invert'),
    dict(type='Rotate', magnitude_key='angle', magnitude_range=(0, 90)),
    dict(type='Posterize', magnitude_key='bits', magnitude_range=(4, 0)),
    dict(type='Solarize', magnitude_key='thr', magnitude_range=(256, 0)),
    dict(
        type='SolarizeAdd',
        magnitude_key='magnitude',
        magnitude_range=(0, 110)),
    dict(
        type='ColorTransform',
        magnitude_key='magnitude',
        magnitude_range=(0, 0.9)),
    dict(type='Contrast', magnitude_key='magnitude', magnitude_range=(0, 0.9)),
    dict(
        type='Brightness', magnitude_key='magnitude',
        magnitude_range=(0, 0.9)),
    dict(
        type='Sharpness', magnitude_key='magnitude', magnitude_range=(0, 0.9)),
    dict(
        type='Shear',
        magnitude_key='magnitude',
        magnitude_range=(0, 0.3),
        direction='horizontal'),
    dict(
        type='Shear',
        magnitude_key='magnitude',
        magnitude_range=(0, 0.3),
        direction='vertical'),
    dict(
        type='Translate',
        magnitude_key='magnitude',
        magnitude_range=(0, 0.45),
        direction='horizontal'),
    dict(
        type='Translate',
        magnitude_key='magnitude',
        magnitude_range=(0, 0.45),
        direction='vertical')
]
dataset_type = 'CustomDataset'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
data = dict(
    samples_per_gpu=120,
    workers_per_gpu=4,
    train=dict(
        type='CustomDataset',
        data_prefix=
        '/data4/lj/Dataset/JML/Experiment_negative/train_withoutNegativeOther',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='Jie_Pad', pad_size_h=224, pad_size_w=224),
            dict(type='RandomFlip', flip_prob=0.5, direction='horizontal'),
            dict(
                type='RandAugment',
                policies=[
                    dict(type='AutoContrast'),
                    dict(type='Equalize'),
                    dict(type='Invert'),
                    dict(
                        type='Rotate',
                        magnitude_key='angle',
                        magnitude_range=(0, 180)),
                    dict(
                        type='Posterize',
                        magnitude_key='bits',
                        magnitude_range=(4, 0)),
                    dict(
                        type='Solarize',
                        magnitude_key='thr',
                        magnitude_range=(256, 0)),
                    dict(
                        type='SolarizeAdd',
                        magnitude_key='magnitude',
                        magnitude_range=(0, 110)),
                    dict(
                        type='ColorTransform',
                        magnitude_key='magnitude',
                        magnitude_range=(0, 0.9)),
                    dict(
                        type='Contrast',
                        magnitude_key='magnitude',
                        magnitude_range=(0, 0.9)),
                    dict(
                        type='Brightness',
                        magnitude_key='magnitude',
                        magnitude_range=(0, 0.9)),
                    dict(
                        type='Sharpness',
                        magnitude_key='magnitude',
                        magnitude_range=(0, 0.9)),
                    dict(
                        type='Shear',
                        magnitude_key='magnitude',
                        magnitude_range=(0, 0.7),
                        direction='horizontal'),
                    dict(
                        type='Shear',
                        magnitude_key='magnitude',
                        magnitude_range=(0, 0.7),
                        direction='vertical'),
                    dict(
                        type='Translate',
                        magnitude_key='magnitude',
                        magnitude_range=(0, 0.45),
                        direction='horizontal'),
                    dict(
                        type='Translate',
                        magnitude_key='magnitude',
                        magnitude_range=(0, 0.45),
                        direction='vertical')
                ],
                num_policies=2,
                total_level=10,
                magnitude_level=9,
                magnitude_std=0.5,
                hparams=dict(pad_val=[104, 116, 124],
                             interpolation='bicubic')),
            dict(
                type='RandomErasing',
                erase_prob=0.25,
                mode='rand',
                min_area_ratio=0.02,
                max_area_ratio=0.3333333333333333,
                fill_color=[103.53, 116.28, 123.675],
                fill_std=[57.375, 57.12, 58.395]),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='ToTensor', keys=['gt_label']),
            dict(type='Collect', keys=['img', 'gt_label'])
        ]),
    val=dict(
        type='CustomDataset',
        data_prefix=
        '/data4/lj/Dataset/JML/Experiment_negative/test_withoutNegativeOther',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='Jie_Pad', pad_size_h=224, pad_size_w=224),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ]),
    test=dict(
        type='CustomDataset',
        data_prefix=
        '/data4/lj/Dataset/JML/Experiment_negative/test_withoutNegativeOther',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='Jie_Pad', pad_size_h=224, pad_size_w=224),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ]))
evaluation = dict(interval=10, metric='accuracy')
paramwise_cfg = dict(
    norm_decay_mult=0.0,
    bias_decay_mult=0.0,
    custom_keys=dict({
        '.absolute_pos_embed': dict(decay_mult=0.0),
        '.relative_position_bias_table': dict(decay_mult=0.0)
    }))
optimizer = dict(
    type='AdamW',
    lr=0.001,
    weight_decay=0.05,
    eps=1e-08,
    betas=(0.9, 0.999),
    paramwise_cfg=dict(
        norm_decay_mult=0.0,
        bias_decay_mult=0.0,
        custom_keys=dict({
            '.absolute_pos_embed': dict(decay_mult=0.0),
            '.relative_position_bias_table': dict(decay_mult=0.0)
        })))
optimizer_config = dict(grad_clip=dict(max_norm=5.0))
lr_config = dict(
    policy='CosineAnnealing',
    by_epoch=False,
    min_lr_ratio=0.01,
    warmup='linear',
    warmup_ratio=0.001,
    warmup_iters=20,
    warmup_by_epoch=True)
runner = dict(type='EpochBasedRunner', max_epochs=200)
checkpoint_config = dict(interval=50, save_optimizer=True)
log_config = dict(interval=100, hooks=[dict(type='TextLoggerHook')])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
work_dir = 'work_dirs/swin_tiny/Experiment_negative/withoutNegativeOther'
gpu_ids = [0]

2023-11-08 11:03:34,478 - mmcls - INFO - Set random seed to 1332774213, deterministic: False
2023-11-08 11:03:34,731 - mmcls - INFO - initialize ImageClassifier with init_cfg [{'type': 'TruncNormal', 'layer': 'Linear', 'std': 0.02, 'bias': 0.0}, {'type': 'Constant', 'layer': 'LayerNorm', 'val': 1.0, 'bias': 0.0}]
2023-11-08 11:03:34,985 - mmcls - INFO - initialize SwinTransformer with init_cfg {'type': 'Pretrained', 'checkpoint': '/data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth', 'prefix': 'backbone'}
2023-11-08 11:03:39,707 - mmcls - INFO - Resize the relative_position_bias_table from torch.Size([49, 3]) to torch.Size([169, 3])
2023-11-08 11:03:39,708 - mmcls - INFO - Resize the relative_position_bias_table from torch.Size([49, 3]) to torch.Size([169, 3])
2023-11-08 11:03:39,709 - mmcls - INFO - Resize the relative_position_bias_table from torch.Size([49, 6]) to torch.Size([169, 6])
2023-11-08 11:03:39,711 - mmcls - INFO - Resize the relative_position_bias_table from torch.Size([49, 6]) to torch.Size([169, 6])
2023-11-08 11:03:39,713 - mmcls - INFO - Resize the relative_position_bias_table from torch.Size([49, 12]) to torch.Size([169, 12])
2023-11-08 11:03:39,715 - mmcls - INFO - Resize the relative_position_bias_table from torch.Size([49, 12]) to torch.Size([169, 12])
2023-11-08 11:03:39,717 - mmcls - INFO - Resize the relative_position_bias_table from torch.Size([49, 12]) to torch.Size([169, 12])
2023-11-08 11:03:39,719 - mmcls - INFO - Resize the relative_position_bias_table from torch.Size([49, 12]) to torch.Size([169, 12])
2023-11-08 11:03:39,721 - mmcls - INFO - Resize the relative_position_bias_table from torch.Size([49, 12]) to torch.Size([169, 12])
2023-11-08 11:03:39,723 - mmcls - INFO - Resize the relative_position_bias_table from torch.Size([49, 12]) to torch.Size([169, 12])
2023-11-08 11:03:39,727 - mmcls - INFO - Resize the relative_position_bias_table from torch.Size([49, 24]) to torch.Size([169, 24])
2023-11-08 11:03:39,731 - mmcls - INFO - Resize the relative_position_bias_table from torch.Size([49, 24]) to torch.Size([169, 24])
Name of parameter - Initialization information

backbone.patch_embed.projection.weight - torch.Size([96, 3, 4, 4]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.patch_embed.projection.bias - torch.Size([96]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.patch_embed.norm.weight - torch.Size([96]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.patch_embed.norm.bias - torch.Size([96]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.0.blocks.0.norm1.weight - torch.Size([96]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.0.blocks.0.norm1.bias - torch.Size([96]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([169, 3]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.0.blocks.0.attn.w_msa.qkv.weight - torch.Size([288, 96]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.0.blocks.0.attn.w_msa.qkv.bias - torch.Size([288]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.0.blocks.0.attn.w_msa.proj.weight - torch.Size([96, 96]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.0.blocks.0.attn.w_msa.proj.bias - torch.Size([96]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.0.blocks.0.norm2.weight - torch.Size([96]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.0.blocks.0.norm2.bias - torch.Size([96]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.0.blocks.0.ffn.layers.0.0.weight - torch.Size([384, 96]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.0.blocks.0.ffn.layers.0.0.bias - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.0.blocks.0.ffn.layers.1.weight - torch.Size([96, 384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.0.blocks.0.ffn.layers.1.bias - torch.Size([96]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.0.blocks.1.norm1.weight - torch.Size([96]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.0.blocks.1.norm1.bias - torch.Size([96]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([169, 3]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.0.blocks.1.attn.w_msa.qkv.weight - torch.Size([288, 96]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.0.blocks.1.attn.w_msa.qkv.bias - torch.Size([288]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.0.blocks.1.attn.w_msa.proj.weight - torch.Size([96, 96]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.0.blocks.1.attn.w_msa.proj.bias - torch.Size([96]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.0.blocks.1.norm2.weight - torch.Size([96]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.0.blocks.1.norm2.bias - torch.Size([96]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.0.blocks.1.ffn.layers.0.0.weight - torch.Size([384, 96]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.0.blocks.1.ffn.layers.0.0.bias - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.0.blocks.1.ffn.layers.1.weight - torch.Size([96, 384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.0.blocks.1.ffn.layers.1.bias - torch.Size([96]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.0.downsample.norm.weight - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.0.downsample.norm.bias - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.0.downsample.reduction.weight - torch.Size([192, 384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.1.blocks.0.norm1.weight - torch.Size([192]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.1.blocks.0.norm1.bias - torch.Size([192]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([169, 6]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.1.blocks.0.attn.w_msa.qkv.weight - torch.Size([576, 192]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.1.blocks.0.attn.w_msa.qkv.bias - torch.Size([576]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.1.blocks.0.attn.w_msa.proj.weight - torch.Size([192, 192]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.1.blocks.0.attn.w_msa.proj.bias - torch.Size([192]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.1.blocks.0.norm2.weight - torch.Size([192]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.1.blocks.0.norm2.bias - torch.Size([192]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.1.blocks.0.ffn.layers.0.0.weight - torch.Size([768, 192]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.1.blocks.0.ffn.layers.0.0.bias - torch.Size([768]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.1.blocks.0.ffn.layers.1.weight - torch.Size([192, 768]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.1.blocks.0.ffn.layers.1.bias - torch.Size([192]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.1.blocks.1.norm1.weight - torch.Size([192]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.1.blocks.1.norm1.bias - torch.Size([192]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([169, 6]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.1.blocks.1.attn.w_msa.qkv.weight - torch.Size([576, 192]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.1.blocks.1.attn.w_msa.qkv.bias - torch.Size([576]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.1.blocks.1.attn.w_msa.proj.weight - torch.Size([192, 192]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.1.blocks.1.attn.w_msa.proj.bias - torch.Size([192]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.1.blocks.1.norm2.weight - torch.Size([192]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.1.blocks.1.norm2.bias - torch.Size([192]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.1.blocks.1.ffn.layers.0.0.weight - torch.Size([768, 192]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.1.blocks.1.ffn.layers.0.0.bias - torch.Size([768]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.1.blocks.1.ffn.layers.1.weight - torch.Size([192, 768]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.1.blocks.1.ffn.layers.1.bias - torch.Size([192]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.1.downsample.norm.weight - torch.Size([768]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.1.downsample.norm.bias - torch.Size([768]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.1.downsample.reduction.weight - torch.Size([384, 768]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.0.norm1.weight - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.0.norm1.bias - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.0.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.0.attn.w_msa.qkv.bias - torch.Size([1152]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.0.attn.w_msa.proj.weight - torch.Size([384, 384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.0.attn.w_msa.proj.bias - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.0.norm2.weight - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.0.norm2.bias - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.0.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.0.ffn.layers.0.0.bias - torch.Size([1536]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.0.ffn.layers.1.weight - torch.Size([384, 1536]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.0.ffn.layers.1.bias - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.1.norm1.weight - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.1.norm1.bias - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.1.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.1.attn.w_msa.qkv.bias - torch.Size([1152]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.1.attn.w_msa.proj.weight - torch.Size([384, 384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.1.attn.w_msa.proj.bias - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.1.norm2.weight - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.1.norm2.bias - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.1.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.1.ffn.layers.0.0.bias - torch.Size([1536]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.1.ffn.layers.1.weight - torch.Size([384, 1536]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.1.ffn.layers.1.bias - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.2.norm1.weight - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.2.norm1.bias - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.2.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.2.attn.w_msa.qkv.bias - torch.Size([1152]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.2.attn.w_msa.proj.weight - torch.Size([384, 384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.2.attn.w_msa.proj.bias - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.2.norm2.weight - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.2.norm2.bias - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.2.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.2.ffn.layers.0.0.bias - torch.Size([1536]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.2.ffn.layers.1.weight - torch.Size([384, 1536]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.2.ffn.layers.1.bias - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.3.norm1.weight - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.3.norm1.bias - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.3.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.3.attn.w_msa.qkv.bias - torch.Size([1152]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.3.attn.w_msa.proj.weight - torch.Size([384, 384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.3.attn.w_msa.proj.bias - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.3.norm2.weight - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.3.norm2.bias - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.3.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.3.ffn.layers.0.0.bias - torch.Size([1536]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.3.ffn.layers.1.weight - torch.Size([384, 1536]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.3.ffn.layers.1.bias - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.4.norm1.weight - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.4.norm1.bias - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.4.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.4.attn.w_msa.qkv.bias - torch.Size([1152]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.4.attn.w_msa.proj.weight - torch.Size([384, 384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.4.attn.w_msa.proj.bias - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.4.norm2.weight - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.4.norm2.bias - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.4.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.4.ffn.layers.0.0.bias - torch.Size([1536]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.4.ffn.layers.1.weight - torch.Size([384, 1536]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.4.ffn.layers.1.bias - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.5.norm1.weight - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.5.norm1.bias - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.5.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.5.attn.w_msa.qkv.bias - torch.Size([1152]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.5.attn.w_msa.proj.weight - torch.Size([384, 384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.5.attn.w_msa.proj.bias - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.5.norm2.weight - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.5.norm2.bias - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.5.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.5.ffn.layers.0.0.bias - torch.Size([1536]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.5.ffn.layers.1.weight - torch.Size([384, 1536]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.blocks.5.ffn.layers.1.bias - torch.Size([384]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.downsample.norm.weight - torch.Size([1536]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.downsample.norm.bias - torch.Size([1536]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.2.downsample.reduction.weight - torch.Size([768, 1536]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.3.blocks.0.norm1.weight - torch.Size([768]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.3.blocks.0.norm1.bias - torch.Size([768]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([169, 24]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.3.blocks.0.attn.w_msa.qkv.weight - torch.Size([2304, 768]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.3.blocks.0.attn.w_msa.qkv.bias - torch.Size([2304]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.3.blocks.0.attn.w_msa.proj.weight - torch.Size([768, 768]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.3.blocks.0.attn.w_msa.proj.bias - torch.Size([768]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.3.blocks.0.norm2.weight - torch.Size([768]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.3.blocks.0.norm2.bias - torch.Size([768]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.3.blocks.0.ffn.layers.0.0.weight - torch.Size([3072, 768]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.3.blocks.0.ffn.layers.0.0.bias - torch.Size([3072]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.3.blocks.0.ffn.layers.1.weight - torch.Size([768, 3072]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.3.blocks.0.ffn.layers.1.bias - torch.Size([768]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.3.blocks.1.norm1.weight - torch.Size([768]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.3.blocks.1.norm1.bias - torch.Size([768]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([169, 24]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.3.blocks.1.attn.w_msa.qkv.weight - torch.Size([2304, 768]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.3.blocks.1.attn.w_msa.qkv.bias - torch.Size([2304]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.3.blocks.1.attn.w_msa.proj.weight - torch.Size([768, 768]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.3.blocks.1.attn.w_msa.proj.bias - torch.Size([768]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.3.blocks.1.norm2.weight - torch.Size([768]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.3.blocks.1.norm2.bias - torch.Size([768]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.3.blocks.1.ffn.layers.0.0.weight - torch.Size([3072, 768]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.3.blocks.1.ffn.layers.0.0.bias - torch.Size([3072]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.3.blocks.1.ffn.layers.1.weight - torch.Size([768, 3072]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.stages.3.blocks.1.ffn.layers.1.bias - torch.Size([768]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.norm3.weight - torch.Size([768]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

backbone.norm3.bias - torch.Size([768]): 
PretrainedInit: load from /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experience3/Test_Cluster/best_accuracy_top-1_epoch_36.pth 

head.fc.weight - torch.Size([44, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

head.fc.bias - torch.Size([44]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 
2023-11-08 11:03:41,354 - mmcls - INFO - Start running, host: root@8F-02-37u-AItest29, work_dir: /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experiment_negative/withoutNegativeOther
2023-11-08 11:03:41,354 - mmcls - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2023-11-08 11:03:41,355 - mmcls - INFO - workflow: [('train', 1)], max: 200 epochs
2023-11-08 11:03:41,355 - mmcls - INFO - Checkpoints will be saved to /data4/lj/Classification/1.7/work_dirs/swin_tiny/Experiment_negative/withoutNegativeOther by HardDiskBackend.
2023-11-08 11:04:33,057 - mmcls - INFO - Epoch [1][100/131]	lr: 3.875e-05, eta: 3:44:53, time: 0.517, data_time: 0.034, memory: 13758, loss: 3.7337, grad_norm: 1.0736
2023-11-08 11:05:38,646 - mmcls - INFO - Epoch [2][100/131]	lr: 8.868e-05, eta: 3:12:06, time: 0.508, data_time: 0.031, memory: 13758, loss: 2.7955, grad_norm: 2.5546
2023-11-08 11:06:44,252 - mmcls - INFO - Epoch [3][100/131]	lr: 1.386e-04, eta: 3:02:32, time: 0.509, data_time: 0.031, memory: 13758, loss: 2.3995, grad_norm: 2.4422
2023-11-08 11:07:49,893 - mmcls - INFO - Epoch [4][100/131]	lr: 1.884e-04, eta: 2:57:37, time: 0.509, data_time: 0.032, memory: 13758, loss: 2.1829, grad_norm: 2.2171
2023-11-08 11:08:55,360 - mmcls - INFO - Epoch [5][100/131]	lr: 2.382e-04, eta: 2:54:19, time: 0.508, data_time: 0.032, memory: 13758, loss: 2.2275, grad_norm: 2.1168
2023-11-08 11:10:00,985 - mmcls - INFO - Epoch [6][100/131]	lr: 2.879e-04, eta: 2:51:59, time: 0.510, data_time: 0.033, memory: 13758, loss: 2.0821, grad_norm: 2.1001
2023-11-08 11:11:06,527 - mmcls - INFO - Epoch [7][100/131]	lr: 3.375e-04, eta: 2:50:02, time: 0.509, data_time: 0.031, memory: 13758, loss: 2.0406, grad_norm: 2.0322
2023-11-08 11:12:12,004 - mmcls - INFO - Epoch [8][100/131]	lr: 3.870e-04, eta: 2:48:21, time: 0.508, data_time: 0.031, memory: 13758, loss: 2.0940, grad_norm: 2.0803
2023-11-08 11:13:17,630 - mmcls - INFO - Epoch [9][100/131]	lr: 4.363e-04, eta: 2:46:53, time: 0.509, data_time: 0.032, memory: 13758, loss: 1.9698, grad_norm: 2.0518
2023-11-08 11:14:23,292 - mmcls - INFO - Epoch [10][100/131]	lr: 4.855e-04, eta: 2:45:33, time: 0.510, data_time: 0.032, memory: 13758, loss: 1.9750, grad_norm: 1.8592
2023-11-08 11:15:04,435 - mmcls - INFO - Epoch(val) [10][53]	accuracy_top-1: 98.5751, accuracy_top-2: 99.5517
2023-11-08 11:15:54,947 - mmcls - INFO - Epoch [11][100/131]	lr: 5.345e-04, eta: 2:44:11, time: 0.505, data_time: 0.031, memory: 13758, loss: 2.0015, grad_norm: 1.9074
2023-11-08 11:17:00,545 - mmcls - INFO - Epoch [12][100/131]	lr: 5.832e-04, eta: 2:43:01, time: 0.510, data_time: 0.031, memory: 13758, loss: 1.9155, grad_norm: 1.8255
2023-11-08 11:18:06,259 - mmcls - INFO - Epoch [13][100/131]	lr: 6.318e-04, eta: 2:41:56, time: 0.510, data_time: 0.031, memory: 13758, loss: 1.9297, grad_norm: 1.8285
2023-11-08 11:19:11,952 - mmcls - INFO - Epoch [14][100/131]	lr: 6.802e-04, eta: 2:40:52, time: 0.510, data_time: 0.032, memory: 13758, loss: 1.9084, grad_norm: 1.7012
2023-11-08 11:20:17,699 - mmcls - INFO - Epoch [15][100/131]	lr: 7.283e-04, eta: 2:39:51, time: 0.511, data_time: 0.032, memory: 13758, loss: 1.9387, grad_norm: 1.8237
2023-11-08 11:21:23,332 - mmcls - INFO - Epoch [16][100/131]	lr: 7.761e-04, eta: 2:38:50, time: 0.510, data_time: 0.032, memory: 13758, loss: 1.9190, grad_norm: 1.7245
2023-11-08 11:22:28,712 - mmcls - INFO - Epoch [17][100/131]	lr: 8.237e-04, eta: 2:37:47, time: 0.507, data_time: 0.032, memory: 13758, loss: 1.9176, grad_norm: 1.8004
2023-11-08 11:23:34,481 - mmcls - INFO - Epoch [18][100/131]	lr: 8.709e-04, eta: 2:36:49, time: 0.511, data_time: 0.032, memory: 13758, loss: 1.8491, grad_norm: 1.8134
2023-11-08 11:24:40,136 - mmcls - INFO - Epoch [19][100/131]	lr: 9.178e-04, eta: 2:35:51, time: 0.510, data_time: 0.032, memory: 13758, loss: 1.9955, grad_norm: 1.6042
2023-11-08 11:25:45,780 - mmcls - INFO - Epoch [20][100/131]	lr: 9.644e-04, eta: 2:34:54, time: 0.509, data_time: 0.030, memory: 13758, loss: 1.9506, grad_norm: 1.7211
2023-11-08 11:26:09,010 - mmcls - INFO - Epoch(val) [20][53]	accuracy_top-1: 98.1748, accuracy_top-2: 99.3116
2023-11-08 11:27:00,090 - mmcls - INFO - Epoch [21][100/131]	lr: 9.739e-04, eta: 2:33:58, time: 0.511, data_time: 0.032, memory: 13758, loss: 1.9106, grad_norm: 1.7115
2023-11-08 11:28:05,680 - mmcls - INFO - Epoch [22][100/131]	lr: 9.714e-04, eta: 2:33:02, time: 0.510, data_time: 0.032, memory: 13758, loss: 1.9275, grad_norm: 1.6219
2023-11-08 11:29:11,055 - mmcls - INFO - Epoch [23][100/131]	lr: 9.687e-04, eta: 2:32:04, time: 0.507, data_time: 0.032, memory: 13758, loss: 1.9089, grad_norm: 1.6216
2023-11-08 11:30:16,905 - mmcls - INFO - Epoch [24][100/131]	lr: 9.659e-04, eta: 2:31:10, time: 0.512, data_time: 0.032, memory: 13758, loss: 1.8267, grad_norm: 1.4722
2023-11-08 11:31:22,764 - mmcls - INFO - Epoch [25][100/131]	lr: 9.630e-04, eta: 2:30:17, time: 0.512, data_time: 0.032, memory: 13758, loss: 1.9031, grad_norm: 1.5639
2023-11-08 11:32:28,763 - mmcls - INFO - Epoch [26][100/131]	lr: 9.600e-04, eta: 2:29:23, time: 0.512, data_time: 0.032, memory: 13758, loss: 1.9188, grad_norm: 1.6068
2023-11-08 11:33:34,671 - mmcls - INFO - Epoch [27][100/131]	lr: 9.569e-04, eta: 2:28:30, time: 0.511, data_time: 0.032, memory: 13758, loss: 1.8497, grad_norm: 1.5496
2023-11-08 11:34:40,655 - mmcls - INFO - Epoch [28][100/131]	lr: 9.537e-04, eta: 2:27:37, time: 0.512, data_time: 0.032, memory: 13758, loss: 1.8970, grad_norm: 1.5027
2023-11-08 11:35:46,729 - mmcls - INFO - Epoch [29][100/131]	lr: 9.504e-04, eta: 2:26:45, time: 0.513, data_time: 0.033, memory: 13758, loss: 1.8359, grad_norm: 1.5976
2023-11-08 11:36:52,595 - mmcls - INFO - Epoch [30][100/131]	lr: 9.469e-04, eta: 2:25:51, time: 0.511, data_time: 0.032, memory: 13758, loss: 1.8615, grad_norm: 1.4885
2023-11-08 11:37:15,864 - mmcls - INFO - Epoch(val) [30][53]	accuracy_top-1: 97.9507, accuracy_top-2: 99.1835
2023-11-08 11:38:07,063 - mmcls - INFO - Epoch [31][100/131]	lr: 9.433e-04, eta: 2:24:59, time: 0.512, data_time: 0.031, memory: 13758, loss: 1.8952, grad_norm: 1.4345
2023-11-08 11:39:16,052 - mmcls - INFO - Epoch [32][100/131]	lr: 9.397e-04, eta: 2:24:22, time: 0.542, data_time: 0.032, memory: 13758, loss: 1.8403, grad_norm: 1.4786
2023-11-08 11:40:20,598 - mmcls - INFO - Epoch [33][100/131]	lr: 9.359e-04, eta: 2:23:24, time: 0.501, data_time: 0.031, memory: 13758, loss: 1.8265, grad_norm: 1.5455
2023-11-08 11:41:25,704 - mmcls - INFO - Epoch [34][100/131]	lr: 9.320e-04, eta: 2:22:29, time: 0.507, data_time: 0.031, memory: 13758, loss: 1.8885, grad_norm: 1.4246
2023-11-08 11:42:36,781 - mmcls - INFO - Epoch [35][100/131]	lr: 9.280e-04, eta: 2:21:56, time: 0.553, data_time: 0.031, memory: 13758, loss: 1.8213, grad_norm: 1.3871
2023-11-08 11:43:41,883 - mmcls - INFO - Epoch [36][100/131]	lr: 9.240e-04, eta: 2:21:00, time: 0.507, data_time: 0.031, memory: 13758, loss: 1.9118, grad_norm: 1.4882
2023-11-08 11:44:47,695 - mmcls - INFO - Epoch [37][100/131]	lr: 9.198e-04, eta: 2:20:07, time: 0.511, data_time: 0.031, memory: 13758, loss: 1.8212, grad_norm: 1.4724
2023-11-08 11:45:53,554 - mmcls - INFO - Epoch [38][100/131]	lr: 9.155e-04, eta: 2:19:14, time: 0.511, data_time: 0.032, memory: 13758, loss: 1.8571, grad_norm: 1.4260
2023-11-08 11:46:59,385 - mmcls - INFO - Epoch [39][100/131]	lr: 9.111e-04, eta: 2:18:20, time: 0.511, data_time: 0.032, memory: 13758, loss: 1.6966, grad_norm: 1.3991
2023-11-08 11:48:05,349 - mmcls - INFO - Epoch [40][100/131]	lr: 9.066e-04, eta: 2:17:28, time: 0.512, data_time: 0.031, memory: 13758, loss: 1.7591, grad_norm: 1.3839
2023-11-08 11:48:28,465 - mmcls - INFO - Epoch(val) [40][53]	accuracy_top-1: 98.4470, accuracy_top-2: 99.3916
2023-11-08 11:49:19,556 - mmcls - INFO - Epoch [41][100/131]	lr: 9.020e-04, eta: 2:16:35, time: 0.511, data_time: 0.032, memory: 13758, loss: 1.8069, grad_norm: 1.4080
2023-11-08 11:50:25,422 - mmcls - INFO - Epoch [42][100/131]	lr: 8.973e-04, eta: 2:15:42, time: 0.511, data_time: 0.032, memory: 13758, loss: 1.8512, grad_norm: 1.3725
2023-11-08 11:51:31,288 - mmcls - INFO - Epoch [43][100/131]	lr: 8.925e-04, eta: 2:14:49, time: 0.511, data_time: 0.032, memory: 13758, loss: 1.8003, grad_norm: 1.3098
2023-11-08 11:52:36,916 - mmcls - INFO - Epoch [44][100/131]	lr: 8.876e-04, eta: 2:13:56, time: 0.509, data_time: 0.031, memory: 13758, loss: 1.7411, grad_norm: 1.3269
2023-11-08 11:53:42,797 - mmcls - INFO - Epoch [45][100/131]	lr: 8.826e-04, eta: 2:13:04, time: 0.512, data_time: 0.033, memory: 13758, loss: 1.7810, grad_norm: 1.3756
2023-11-08 11:54:48,557 - mmcls - INFO - Epoch [46][100/131]	lr: 8.776e-04, eta: 2:12:11, time: 0.511, data_time: 0.032, memory: 13758, loss: 1.8187, grad_norm: 1.3751
2023-11-08 11:55:54,415 - mmcls - INFO - Epoch [47][100/131]	lr: 8.724e-04, eta: 2:11:19, time: 0.512, data_time: 0.032, memory: 13758, loss: 1.8078, grad_norm: 1.3216
2023-11-08 11:57:00,249 - mmcls - INFO - Epoch [48][100/131]	lr: 8.671e-04, eta: 2:10:26, time: 0.511, data_time: 0.031, memory: 13758, loss: 1.8074, grad_norm: 1.2618
2023-11-08 11:58:05,919 - mmcls - INFO - Epoch [49][100/131]	lr: 8.618e-04, eta: 2:09:33, time: 0.510, data_time: 0.031, memory: 13758, loss: 1.7745, grad_norm: 1.2830
2023-11-08 11:59:11,541 - mmcls - INFO - Epoch [50][100/131]	lr: 8.564e-04, eta: 2:08:41, time: 0.510, data_time: 0.031, memory: 13758, loss: 1.7561, grad_norm: 1.3927
2023-11-08 11:59:26,231 - mmcls - INFO - Saving checkpoint at 50 epochs
2023-11-08 11:59:36,018 - mmcls - INFO - Epoch(val) [50][53]	accuracy_top-1: 98.5911, accuracy_top-2: 99.4076
2023-11-08 12:00:27,151 - mmcls - INFO - Epoch [51][100/131]	lr: 8.508e-04, eta: 2:07:49, time: 0.511, data_time: 0.031, memory: 13758, loss: 1.8746, grad_norm: 1.3976
2023-11-08 12:01:33,110 - mmcls - INFO - Epoch [52][100/131]	lr: 8.452e-04, eta: 2:06:57, time: 0.512, data_time: 0.032, memory: 13758, loss: 1.8168, grad_norm: 1.2969
2023-11-08 12:02:39,145 - mmcls - INFO - Epoch [53][100/131]	lr: 8.395e-04, eta: 2:06:05, time: 0.512, data_time: 0.030, memory: 13758, loss: 1.7324, grad_norm: 1.2701
2023-11-08 12:03:45,251 - mmcls - INFO - Epoch [54][100/131]	lr: 8.338e-04, eta: 2:05:13, time: 0.512, data_time: 0.031, memory: 13758, loss: 1.7121, grad_norm: 1.3754
2023-11-08 12:04:51,231 - mmcls - INFO - Epoch [55][100/131]	lr: 8.279e-04, eta: 2:04:21, time: 0.512, data_time: 0.031, memory: 13758, loss: 1.7355, grad_norm: 1.2801
2023-11-08 12:05:57,376 - mmcls - INFO - Epoch [56][100/131]	lr: 8.220e-04, eta: 2:03:30, time: 0.514, data_time: 0.032, memory: 13758, loss: 1.7935, grad_norm: 1.3161
2023-11-08 12:07:03,438 - mmcls - INFO - Epoch [57][100/131]	lr: 8.160e-04, eta: 2:02:38, time: 0.513, data_time: 0.032, memory: 13758, loss: 1.7624, grad_norm: 1.2785
2023-11-08 12:08:09,427 - mmcls - INFO - Epoch [58][100/131]	lr: 8.099e-04, eta: 2:01:47, time: 0.513, data_time: 0.031, memory: 13758, loss: 1.7278, grad_norm: 1.2788
2023-11-08 12:09:15,536 - mmcls - INFO - Epoch [59][100/131]	lr: 8.037e-04, eta: 2:00:55, time: 0.513, data_time: 0.031, memory: 13758, loss: 1.7203, grad_norm: 1.2066
2023-11-08 12:10:21,494 - mmcls - INFO - Epoch [60][100/131]	lr: 7.975e-04, eta: 2:00:03, time: 0.512, data_time: 0.031, memory: 13758, loss: 1.7767, grad_norm: 1.2629
2023-11-08 12:10:44,741 - mmcls - INFO - Epoch(val) [60][53]	accuracy_top-1: 98.5591, accuracy_top-2: 99.4076
2023-11-08 12:11:36,003 - mmcls - INFO - Epoch [61][100/131]	lr: 7.912e-04, eta: 1:59:12, time: 0.513, data_time: 0.032, memory: 13758, loss: 1.7106, grad_norm: 1.2787
2023-11-08 12:12:42,146 - mmcls - INFO - Epoch [62][100/131]	lr: 7.848e-04, eta: 1:58:20, time: 0.514, data_time: 0.032, memory: 13758, loss: 1.6969, grad_norm: 1.3477
2023-11-08 12:13:48,435 - mmcls - INFO - Epoch [63][100/131]	lr: 7.784e-04, eta: 1:57:29, time: 0.515, data_time: 0.033, memory: 13758, loss: 1.7852, grad_norm: 1.2451
2023-11-08 12:14:54,612 - mmcls - INFO - Epoch [64][100/131]	lr: 7.718e-04, eta: 1:56:38, time: 0.514, data_time: 0.031, memory: 13758, loss: 1.7512, grad_norm: 1.3305
2023-11-08 12:16:00,764 - mmcls - INFO - Epoch [65][100/131]	lr: 7.653e-04, eta: 1:55:46, time: 0.513, data_time: 0.031, memory: 13758, loss: 1.8176, grad_norm: 1.3437
2023-11-08 12:17:07,001 - mmcls - INFO - Epoch [66][100/131]	lr: 7.586e-04, eta: 1:54:55, time: 0.515, data_time: 0.032, memory: 13758, loss: 1.7246, grad_norm: 1.2112
2023-11-08 12:18:13,172 - mmcls - INFO - Epoch [67][100/131]	lr: 7.519e-04, eta: 1:54:04, time: 0.514, data_time: 0.032, memory: 13758, loss: 1.7756, grad_norm: 1.2655
2023-11-08 12:19:19,468 - mmcls - INFO - Epoch [68][100/131]	lr: 7.451e-04, eta: 1:53:13, time: 0.514, data_time: 0.031, memory: 13758, loss: 1.7306, grad_norm: 1.3485
2023-11-08 12:20:25,836 - mmcls - INFO - Epoch [69][100/131]	lr: 7.383e-04, eta: 1:52:22, time: 0.515, data_time: 0.032, memory: 13758, loss: 1.8040, grad_norm: 1.2335
2023-11-08 12:21:32,344 - mmcls - INFO - Epoch [70][100/131]	lr: 7.314e-04, eta: 1:51:31, time: 0.517, data_time: 0.032, memory: 13758, loss: 1.7591, grad_norm: 1.2659
2023-11-08 12:21:55,824 - mmcls - INFO - Epoch(val) [70][53]	accuracy_top-1: 98.5110, accuracy_top-2: 99.3596
2023-11-08 12:22:47,319 - mmcls - INFO - Epoch [71][100/131]	lr: 7.245e-04, eta: 1:50:40, time: 0.515, data_time: 0.032, memory: 13758, loss: 1.6778, grad_norm: 1.2181
2023-11-08 12:23:53,763 - mmcls - INFO - Epoch [72][100/131]	lr: 7.175e-04, eta: 1:49:49, time: 0.516, data_time: 0.033, memory: 13758, loss: 1.7704, grad_norm: 1.2918
2023-11-08 12:24:59,919 - mmcls - INFO - Epoch [73][100/131]	lr: 7.104e-04, eta: 1:48:57, time: 0.513, data_time: 0.030, memory: 13758, loss: 1.6786, grad_norm: 1.2206
2023-11-08 12:26:06,192 - mmcls - INFO - Epoch [74][100/131]	lr: 7.033e-04, eta: 1:48:06, time: 0.515, data_time: 0.030, memory: 13758, loss: 1.7513, grad_norm: 1.2900
2023-11-08 12:27:12,476 - mmcls - INFO - Epoch [75][100/131]	lr: 6.962e-04, eta: 1:47:15, time: 0.515, data_time: 0.031, memory: 13758, loss: 1.6889, grad_norm: 1.2674
2023-11-08 12:28:18,903 - mmcls - INFO - Epoch [76][100/131]	lr: 6.890e-04, eta: 1:46:23, time: 0.516, data_time: 0.033, memory: 13758, loss: 1.7409, grad_norm: 1.2087
2023-11-08 12:29:25,448 - mmcls - INFO - Epoch [77][100/131]	lr: 6.817e-04, eta: 1:45:33, time: 0.517, data_time: 0.032, memory: 13758, loss: 1.7785, grad_norm: 1.2600
2023-11-08 12:30:31,819 - mmcls - INFO - Epoch [78][100/131]	lr: 6.745e-04, eta: 1:44:41, time: 0.515, data_time: 0.032, memory: 13758, loss: 1.7049, grad_norm: 1.1958
2023-11-08 12:31:38,354 - mmcls - INFO - Epoch [79][100/131]	lr: 6.671e-04, eta: 1:43:50, time: 0.516, data_time: 0.031, memory: 13758, loss: 1.6277, grad_norm: 1.2588
2023-11-08 12:32:44,822 - mmcls - INFO - Epoch [80][100/131]	lr: 6.598e-04, eta: 1:42:59, time: 0.516, data_time: 0.032, memory: 13758, loss: 1.6785, grad_norm: 1.2313
2023-11-08 12:33:08,270 - mmcls - INFO - Epoch(val) [80][53]	accuracy_top-1: 98.3189, accuracy_top-2: 99.3756
2023-11-08 12:33:59,900 - mmcls - INFO - Epoch [81][100/131]	lr: 6.524e-04, eta: 1:42:08, time: 0.516, data_time: 0.032, memory: 13758, loss: 1.6812, grad_norm: 1.2409
2023-11-08 12:35:06,462 - mmcls - INFO - Epoch [82][100/131]	lr: 6.449e-04, eta: 1:41:17, time: 0.517, data_time: 0.032, memory: 13758, loss: 1.7460, grad_norm: 1.2317
2023-11-08 12:36:13,251 - mmcls - INFO - Epoch [83][100/131]	lr: 6.374e-04, eta: 1:40:26, time: 0.516, data_time: 0.032, memory: 13758, loss: 1.6709, grad_norm: 1.2826
2023-11-08 12:37:19,684 - mmcls - INFO - Epoch [84][100/131]	lr: 6.299e-04, eta: 1:39:35, time: 0.515, data_time: 0.031, memory: 13758, loss: 1.7377, grad_norm: 1.3060
2023-11-08 12:38:26,122 - mmcls - INFO - Epoch [85][100/131]	lr: 6.224e-04, eta: 1:38:44, time: 0.516, data_time: 0.032, memory: 13758, loss: 1.6776, grad_norm: 1.2634
2023-11-08 12:39:32,486 - mmcls - INFO - Epoch [86][100/131]	lr: 6.148e-04, eta: 1:37:52, time: 0.515, data_time: 0.032, memory: 13758, loss: 1.6832, grad_norm: 1.2143
2023-11-08 12:40:38,896 - mmcls - INFO - Epoch [87][100/131]	lr: 6.072e-04, eta: 1:37:01, time: 0.516, data_time: 0.032, memory: 13758, loss: 1.6273, grad_norm: 1.1321
2023-11-08 12:41:45,190 - mmcls - INFO - Epoch [88][100/131]	lr: 5.996e-04, eta: 1:36:10, time: 0.514, data_time: 0.031, memory: 13758, loss: 1.6905, grad_norm: 1.1546
2023-11-08 12:42:51,462 - mmcls - INFO - Epoch [89][100/131]	lr: 5.920e-04, eta: 1:35:18, time: 0.515, data_time: 0.031, memory: 13758, loss: 1.7479, grad_norm: 1.2434
2023-11-08 12:43:57,923 - mmcls - INFO - Epoch [90][100/131]	lr: 5.843e-04, eta: 1:34:27, time: 0.516, data_time: 0.032, memory: 13758, loss: 1.7192, grad_norm: 1.2670
2023-11-08 12:44:21,425 - mmcls - INFO - Epoch(val) [90][53]	accuracy_top-1: 98.6551, accuracy_top-2: 99.4877
2023-11-08 12:45:12,645 - mmcls - INFO - Epoch [91][100/131]	lr: 5.766e-04, eta: 1:33:36, time: 0.512, data_time: 0.030, memory: 13758, loss: 1.6375, grad_norm: 1.2006
2023-11-08 12:46:19,111 - mmcls - INFO - Epoch [92][100/131]	lr: 5.689e-04, eta: 1:32:45, time: 0.516, data_time: 0.032, memory: 13758, loss: 1.6820, grad_norm: 1.2621
2023-11-08 12:47:25,411 - mmcls - INFO - Epoch [93][100/131]	lr: 5.612e-04, eta: 1:31:53, time: 0.515, data_time: 0.032, memory: 13758, loss: 1.7026, grad_norm: 1.2490
2023-11-08 12:48:31,696 - mmcls - INFO - Epoch [94][100/131]	lr: 5.535e-04, eta: 1:31:02, time: 0.515, data_time: 0.032, memory: 13758, loss: 1.6269, grad_norm: 1.1377
2023-11-08 12:49:37,794 - mmcls - INFO - Epoch [95][100/131]	lr: 5.457e-04, eta: 1:30:10, time: 0.513, data_time: 0.031, memory: 13758, loss: 1.6508, grad_norm: 1.2395
2023-11-08 12:50:46,402 - mmcls - INFO - Epoch [96][100/131]	lr: 5.380e-04, eta: 1:29:19, time: 0.513, data_time: 0.030, memory: 13758, loss: 1.7009, grad_norm: 1.2313
2023-11-08 12:51:52,648 - mmcls - INFO - Epoch [97][100/131]	lr: 5.302e-04, eta: 1:28:27, time: 0.514, data_time: 0.032, memory: 13758, loss: 1.6675, grad_norm: 1.2903
2023-11-08 12:52:58,806 - mmcls - INFO - Epoch [98][100/131]	lr: 5.224e-04, eta: 1:27:36, time: 0.514, data_time: 0.030, memory: 13758, loss: 1.6286, grad_norm: 1.1858
2023-11-08 12:54:05,058 - mmcls - INFO - Epoch [99][100/131]	lr: 5.147e-04, eta: 1:26:44, time: 0.514, data_time: 0.031, memory: 13758, loss: 1.6658, grad_norm: 1.2655
2023-11-08 12:55:14,889 - mmcls - INFO - Epoch [100][100/131]	lr: 5.069e-04, eta: 1:25:53, time: 0.514, data_time: 0.032, memory: 13758, loss: 1.7071, grad_norm: 1.2546
2023-11-08 12:55:29,738 - mmcls - INFO - Saving checkpoint at 100 epochs
2023-11-08 12:55:42,140 - mmcls - INFO - Epoch(val) [100][53]	accuracy_top-1: 98.7352, accuracy_top-2: 99.4557
2023-11-08 12:56:33,517 - mmcls - INFO - Epoch [101][100/131]	lr: 4.991e-04, eta: 1:25:02, time: 0.514, data_time: 0.032, memory: 13758, loss: 1.6495, grad_norm: 1.1869
2023-11-08 12:57:39,794 - mmcls - INFO - Epoch [102][100/131]	lr: 4.914e-04, eta: 1:24:10, time: 0.515, data_time: 0.032, memory: 13758, loss: 1.6336, grad_norm: 1.2286
2023-11-08 12:58:45,987 - mmcls - INFO - Epoch [103][100/131]	lr: 4.836e-04, eta: 1:23:19, time: 0.514, data_time: 0.033, memory: 13758, loss: 1.6250, grad_norm: 1.1585
2023-11-08 12:59:51,894 - mmcls - INFO - Epoch [104][100/131]	lr: 4.758e-04, eta: 1:22:27, time: 0.512, data_time: 0.032, memory: 13758, loss: 1.6166, grad_norm: 1.1715
2023-11-08 13:00:57,839 - mmcls - INFO - Epoch [105][100/131]	lr: 4.681e-04, eta: 1:21:36, time: 0.512, data_time: 0.031, memory: 13758, loss: 1.6332, grad_norm: 1.2690
2023-11-08 13:02:03,454 - mmcls - INFO - Epoch [106][100/131]	lr: 4.603e-04, eta: 1:20:44, time: 0.509, data_time: 0.032, memory: 13758, loss: 1.6341, grad_norm: 1.2045
2023-11-08 13:03:11,573 - mmcls - INFO - Epoch [107][100/131]	lr: 4.526e-04, eta: 1:19:52, time: 0.510, data_time: 0.032, memory: 13758, loss: 1.6313, grad_norm: 1.1811
2023-11-08 13:04:17,366 - mmcls - INFO - Epoch [108][100/131]	lr: 4.448e-04, eta: 1:19:00, time: 0.511, data_time: 0.032, memory: 13758, loss: 1.6165, grad_norm: 1.3494
2023-11-08 13:05:23,200 - mmcls - INFO - Epoch [109][100/131]	lr: 4.371e-04, eta: 1:18:09, time: 0.511, data_time: 0.032, memory: 13758, loss: 1.6243, grad_norm: 1.2758
2023-11-08 13:06:29,069 - mmcls - INFO - Epoch [110][100/131]	lr: 4.294e-04, eta: 1:17:17, time: 0.512, data_time: 0.033, memory: 13758, loss: 1.6221, grad_norm: 1.2844
2023-11-08 13:06:52,509 - mmcls - INFO - Epoch(val) [110][53]	accuracy_top-1: 98.7352, accuracy_top-2: 99.4396
2023-11-08 13:07:43,725 - mmcls - INFO - Epoch [111][100/131]	lr: 4.218e-04, eta: 1:16:26, time: 0.512, data_time: 0.032, memory: 13758, loss: 1.6184, grad_norm: 1.1316
2023-11-08 13:08:49,459 - mmcls - INFO - Epoch [112][100/131]	lr: 4.141e-04, eta: 1:15:34, time: 0.510, data_time: 0.031, memory: 13758, loss: 1.5816, grad_norm: 1.1260
2023-11-08 13:09:55,070 - mmcls - INFO - Epoch [113][100/131]	lr: 4.065e-04, eta: 1:14:42, time: 0.510, data_time: 0.032, memory: 13758, loss: 1.6100, grad_norm: 1.1934
2023-11-08 13:11:00,709 - mmcls - INFO - Epoch [114][100/131]	lr: 3.989e-04, eta: 1:13:50, time: 0.510, data_time: 0.033, memory: 13758, loss: 1.6350, grad_norm: 1.1791
2023-11-08 13:12:06,493 - mmcls - INFO - Epoch [115][100/131]	lr: 3.913e-04, eta: 1:12:59, time: 0.511, data_time: 0.032, memory: 13758, loss: 1.6032, grad_norm: 1.1253
2023-11-08 13:13:12,553 - mmcls - INFO - Epoch [116][100/131]	lr: 3.837e-04, eta: 1:12:07, time: 0.513, data_time: 0.033, memory: 13758, loss: 1.6481, grad_norm: 1.2372
2023-11-08 13:14:18,484 - mmcls - INFO - Epoch [117][100/131]	lr: 3.762e-04, eta: 1:11:16, time: 0.512, data_time: 0.032, memory: 13758, loss: 1.5824, grad_norm: 1.2601
2023-11-08 13:15:24,379 - mmcls - INFO - Epoch [118][100/131]	lr: 3.687e-04, eta: 1:10:24, time: 0.511, data_time: 0.031, memory: 13758, loss: 1.6385, grad_norm: 1.1261
2023-11-08 13:16:30,357 - mmcls - INFO - Epoch [119][100/131]	lr: 3.613e-04, eta: 1:09:33, time: 0.512, data_time: 0.031, memory: 13758, loss: 1.6127, grad_norm: 1.2176
2023-11-08 13:17:36,445 - mmcls - INFO - Epoch [120][100/131]	lr: 3.538e-04, eta: 1:08:42, time: 0.513, data_time: 0.032, memory: 13758, loss: 1.5497, grad_norm: 1.2703
2023-11-08 13:17:59,763 - mmcls - INFO - Epoch(val) [120][53]	accuracy_top-1: 98.7512, accuracy_top-2: 99.4076
2023-11-08 13:18:51,028 - mmcls - INFO - Epoch [121][100/131]	lr: 3.465e-04, eta: 1:07:50, time: 0.513, data_time: 0.032, memory: 13758, loss: 1.6772, grad_norm: 1.1471
2023-11-08 13:19:57,049 - mmcls - INFO - Epoch [122][100/131]	lr: 3.391e-04, eta: 1:06:59, time: 0.512, data_time: 0.031, memory: 13758, loss: 1.6207, grad_norm: 1.3185
2023-11-08 13:21:03,222 - mmcls - INFO - Epoch [123][100/131]	lr: 3.318e-04, eta: 1:06:07, time: 0.514, data_time: 0.033, memory: 13758, loss: 1.5918, grad_norm: 1.2121
2023-11-08 13:22:09,121 - mmcls - INFO - Epoch [124][100/131]	lr: 3.245e-04, eta: 1:05:16, time: 0.512, data_time: 0.031, memory: 13758, loss: 1.5986, grad_norm: 1.2246
2023-11-08 13:23:15,160 - mmcls - INFO - Epoch [125][100/131]	lr: 3.173e-04, eta: 1:04:24, time: 0.513, data_time: 0.033, memory: 13758, loss: 1.6480, grad_norm: 1.2244
2023-11-08 13:24:21,138 - mmcls - INFO - Epoch [126][100/131]	lr: 3.102e-04, eta: 1:03:33, time: 0.512, data_time: 0.032, memory: 13758, loss: 1.5513, grad_norm: 1.1548
2023-11-08 13:25:27,049 - mmcls - INFO - Epoch [127][100/131]	lr: 3.030e-04, eta: 1:02:41, time: 0.512, data_time: 0.032, memory: 13758, loss: 1.5827, grad_norm: 1.1928
2023-11-08 13:26:33,043 - mmcls - INFO - Epoch [128][100/131]	lr: 2.960e-04, eta: 1:01:50, time: 0.513, data_time: 0.031, memory: 13758, loss: 1.5749, grad_norm: 1.1795
2023-11-08 13:27:39,054 - mmcls - INFO - Epoch [129][100/131]	lr: 2.889e-04, eta: 1:00:59, time: 0.512, data_time: 0.032, memory: 13758, loss: 1.6497, grad_norm: 1.1691
2023-11-08 13:28:44,559 - mmcls - INFO - Epoch [130][100/131]	lr: 2.820e-04, eta: 1:00:07, time: 0.509, data_time: 0.032, memory: 13758, loss: 1.6138, grad_norm: 1.2629
2023-11-08 13:30:03,971 - mmcls - INFO - Epoch(val) [130][53]	accuracy_top-1: 98.7672, accuracy_top-2: 99.4717
2023-11-08 13:30:54,296 - mmcls - INFO - Epoch [131][100/131]	lr: 2.751e-04, eta: 0:59:15, time: 0.503, data_time: 0.031, memory: 13758, loss: 1.5289, grad_norm: 1.1455
2023-11-08 13:32:00,275 - mmcls - INFO - Epoch [132][100/131]	lr: 2.682e-04, eta: 0:58:24, time: 0.513, data_time: 0.032, memory: 13758, loss: 1.6136, grad_norm: 1.2199
2023-11-08 13:33:06,391 - mmcls - INFO - Epoch [133][100/131]	lr: 2.614e-04, eta: 0:57:32, time: 0.513, data_time: 0.032, memory: 13758, loss: 1.5144, grad_norm: 1.1627
2023-11-08 13:34:12,365 - mmcls - INFO - Epoch [134][100/131]	lr: 2.547e-04, eta: 0:56:41, time: 0.512, data_time: 0.031, memory: 13758, loss: 1.6275, grad_norm: 1.1939
2023-11-08 13:35:18,419 - mmcls - INFO - Epoch [135][100/131]	lr: 2.480e-04, eta: 0:55:49, time: 0.513, data_time: 0.032, memory: 13758, loss: 1.5872, grad_norm: 1.1959
2023-11-08 13:36:24,591 - mmcls - INFO - Epoch [136][100/131]	lr: 2.414e-04, eta: 0:54:58, time: 0.514, data_time: 0.032, memory: 13758, loss: 1.5989, grad_norm: 1.1787
2023-11-08 13:37:30,602 - mmcls - INFO - Epoch [137][100/131]	lr: 2.348e-04, eta: 0:54:07, time: 0.513, data_time: 0.033, memory: 13758, loss: 1.5599, grad_norm: 1.2814
2023-11-08 13:38:36,625 - mmcls - INFO - Epoch [138][100/131]	lr: 2.283e-04, eta: 0:53:15, time: 0.513, data_time: 0.032, memory: 13758, loss: 1.5450, grad_norm: 1.1339
2023-11-08 13:39:42,437 - mmcls - INFO - Epoch [139][100/131]	lr: 2.219e-04, eta: 0:52:24, time: 0.511, data_time: 0.031, memory: 13758, loss: 1.5833, grad_norm: 1.2008
2023-11-08 13:40:48,551 - mmcls - INFO - Epoch [140][100/131]	lr: 2.156e-04, eta: 0:51:32, time: 0.513, data_time: 0.032, memory: 13758, loss: 1.5144, grad_norm: 1.1923
2023-11-08 13:41:11,840 - mmcls - INFO - Epoch(val) [140][53]	accuracy_top-1: 98.8633, accuracy_top-2: 99.3756
2023-11-08 13:42:03,016 - mmcls - INFO - Epoch [141][100/131]	lr: 2.093e-04, eta: 0:50:41, time: 0.512, data_time: 0.031, memory: 13758, loss: 1.5472, grad_norm: 1.2143
2023-11-08 13:43:09,131 - mmcls - INFO - Epoch [142][100/131]	lr: 2.031e-04, eta: 0:49:50, time: 0.514, data_time: 0.033, memory: 13758, loss: 1.6323, grad_norm: 1.1882
2023-11-08 13:44:15,198 - mmcls - INFO - Epoch [143][100/131]	lr: 1.970e-04, eta: 0:48:58, time: 0.513, data_time: 0.033, memory: 13758, loss: 1.5695, grad_norm: 1.1352
2023-11-08 13:45:21,081 - mmcls - INFO - Epoch [144][100/131]	lr: 1.909e-04, eta: 0:48:07, time: 0.513, data_time: 0.032, memory: 13758, loss: 1.5576, grad_norm: 1.1805
2023-11-08 13:46:27,227 - mmcls - INFO - Epoch [145][100/131]	lr: 1.850e-04, eta: 0:47:16, time: 0.513, data_time: 0.032, memory: 13758, loss: 1.5192, grad_norm: 1.1592
2023-11-08 13:47:33,324 - mmcls - INFO - Epoch [146][100/131]	lr: 1.791e-04, eta: 0:46:24, time: 0.513, data_time: 0.032, memory: 13758, loss: 1.5863, grad_norm: 1.2337
2023-11-08 13:48:39,409 - mmcls - INFO - Epoch [147][100/131]	lr: 1.733e-04, eta: 0:45:33, time: 0.513, data_time: 0.032, memory: 13758, loss: 1.5228, grad_norm: 1.1331
2023-11-08 13:49:45,383 - mmcls - INFO - Epoch [148][100/131]	lr: 1.675e-04, eta: 0:44:42, time: 0.512, data_time: 0.031, memory: 13758, loss: 1.5524, grad_norm: 1.1783
2023-11-08 13:50:51,376 - mmcls - INFO - Epoch [149][100/131]	lr: 1.619e-04, eta: 0:43:50, time: 0.513, data_time: 0.031, memory: 13758, loss: 1.5944, grad_norm: 1.1937
2023-11-08 13:51:57,377 - mmcls - INFO - Epoch [150][100/131]	lr: 1.563e-04, eta: 0:42:59, time: 0.512, data_time: 0.031, memory: 13758, loss: 1.5867, grad_norm: 1.1663
2023-11-08 13:52:12,126 - mmcls - INFO - Saving checkpoint at 150 epochs
2023-11-08 13:52:21,477 - mmcls - INFO - Epoch(val) [150][53]	accuracy_top-1: 98.9753, accuracy_top-2: 99.5197
2023-11-08 13:53:12,923 - mmcls - INFO - Epoch [151][100/131]	lr: 1.509e-04, eta: 0:42:07, time: 0.514, data_time: 0.032, memory: 13758, loss: 1.4773, grad_norm: 1.1440
2023-11-08 13:54:19,036 - mmcls - INFO - Epoch [152][100/131]	lr: 1.455e-04, eta: 0:41:16, time: 0.513, data_time: 0.032, memory: 13758, loss: 1.5650, grad_norm: 1.2128
2023-11-08 13:55:25,320 - mmcls - INFO - Epoch [153][100/131]	lr: 1.402e-04, eta: 0:40:25, time: 0.514, data_time: 0.031, memory: 13758, loss: 1.5327, grad_norm: 1.1966
2023-11-08 13:56:31,754 - mmcls - INFO - Epoch [154][100/131]	lr: 1.350e-04, eta: 0:39:34, time: 0.515, data_time: 0.031, memory: 13758, loss: 1.5158, grad_norm: 1.2499
2023-11-08 13:57:41,094 - mmcls - INFO - Epoch [155][100/131]	lr: 1.298e-04, eta: 0:38:43, time: 0.544, data_time: 0.032, memory: 13758, loss: 1.5429, grad_norm: 1.2238
2023-11-08 13:58:47,457 - mmcls - INFO - Epoch [156][100/131]	lr: 1.248e-04, eta: 0:37:52, time: 0.516, data_time: 0.032, memory: 13758, loss: 1.5222, grad_norm: 1.2126
2023-11-08 13:59:53,647 - mmcls - INFO - Epoch [157][100/131]	lr: 1.199e-04, eta: 0:37:00, time: 0.514, data_time: 0.033, memory: 13758, loss: 1.5291, grad_norm: 1.2486
2023-11-08 14:00:59,986 - mmcls - INFO - Epoch [158][100/131]	lr: 1.150e-04, eta: 0:36:09, time: 0.515, data_time: 0.032, memory: 13758, loss: 1.4979, grad_norm: 1.2108
2023-11-08 14:02:06,333 - mmcls - INFO - Epoch [159][100/131]	lr: 1.103e-04, eta: 0:35:18, time: 0.515, data_time: 0.032, memory: 13758, loss: 1.5858, grad_norm: 1.1355
2023-11-08 14:03:12,692 - mmcls - INFO - Epoch [160][100/131]	lr: 1.057e-04, eta: 0:34:26, time: 0.515, data_time: 0.033, memory: 13758, loss: 1.5109, grad_norm: 1.2180
2023-11-08 14:03:36,292 - mmcls - INFO - Epoch(val) [160][53]	accuracy_top-1: 98.9433, accuracy_top-2: 99.4877
2023-11-08 14:04:27,720 - mmcls - INFO - Epoch [161][100/131]	lr: 1.011e-04, eta: 0:33:35, time: 0.514, data_time: 0.032, memory: 13758, loss: 1.4924, grad_norm: 1.2071
2023-11-08 14:05:33,758 - mmcls - INFO - Epoch [162][100/131]	lr: 9.667e-05, eta: 0:32:44, time: 0.513, data_time: 0.032, memory: 13758, loss: 1.5559, grad_norm: 1.2643
2023-11-08 14:06:39,564 - mmcls - INFO - Epoch [163][100/131]	lr: 9.232e-05, eta: 0:31:52, time: 0.510, data_time: 0.030, memory: 13758, loss: 1.5283, grad_norm: 1.2697
2023-11-08 14:07:45,566 - mmcls - INFO - Epoch [164][100/131]	lr: 8.808e-05, eta: 0:31:01, time: 0.512, data_time: 0.031, memory: 13758, loss: 1.4887, grad_norm: 1.2248
2023-11-08 14:08:51,651 - mmcls - INFO - Epoch [165][100/131]	lr: 8.394e-05, eta: 0:30:09, time: 0.513, data_time: 0.032, memory: 13758, loss: 1.5135, grad_norm: 1.2623
2023-11-08 14:09:57,799 - mmcls - INFO - Epoch [166][100/131]	lr: 7.990e-05, eta: 0:29:18, time: 0.514, data_time: 0.031, memory: 13758, loss: 1.4762, grad_norm: 1.1112
2023-11-08 14:11:07,181 - mmcls - INFO - Epoch [167][100/131]	lr: 7.597e-05, eta: 0:28:27, time: 0.546, data_time: 0.033, memory: 13758, loss: 1.5163, grad_norm: 1.2542
2023-11-08 14:12:13,446 - mmcls - INFO - Epoch [168][100/131]	lr: 7.215e-05, eta: 0:27:36, time: 0.515, data_time: 0.032, memory: 13758, loss: 1.5242, grad_norm: 1.2358
2023-11-08 14:13:19,522 - mmcls - INFO - Epoch [169][100/131]	lr: 6.843e-05, eta: 0:26:45, time: 0.513, data_time: 0.031, memory: 13758, loss: 1.5573, grad_norm: 1.2641
2023-11-08 14:14:25,523 - mmcls - INFO - Epoch [170][100/131]	lr: 6.482e-05, eta: 0:25:53, time: 0.513, data_time: 0.032, memory: 13758, loss: 1.5809, grad_norm: 1.3374
2023-11-08 14:14:48,910 - mmcls - INFO - Epoch(val) [170][53]	accuracy_top-1: 99.0074, accuracy_top-2: 99.5517
2023-11-08 14:15:40,114 - mmcls - INFO - Epoch [171][100/131]	lr: 6.132e-05, eta: 0:25:02, time: 0.512, data_time: 0.031, memory: 13758, loss: 1.5557, grad_norm: 1.2150
2023-11-08 14:16:46,195 - mmcls - INFO - Epoch [172][100/131]	lr: 5.792e-05, eta: 0:24:10, time: 0.513, data_time: 0.032, memory: 13758, loss: 1.5117, grad_norm: 1.2223
2023-11-08 14:17:52,213 - mmcls - INFO - Epoch [173][100/131]	lr: 5.464e-05, eta: 0:23:19, time: 0.512, data_time: 0.032, memory: 13758, loss: 1.5061, grad_norm: 1.2275
2023-11-08 14:18:58,248 - mmcls - INFO - Epoch [174][100/131]	lr: 5.147e-05, eta: 0:22:28, time: 0.513, data_time: 0.031, memory: 13758, loss: 1.4756, grad_norm: 1.3071
2023-11-08 14:20:04,303 - mmcls - INFO - Epoch [175][100/131]	lr: 4.841e-05, eta: 0:21:36, time: 0.512, data_time: 0.031, memory: 13758, loss: 1.4535, grad_norm: 1.2187
2023-11-08 14:21:10,293 - mmcls - INFO - Epoch [176][100/131]	lr: 4.546e-05, eta: 0:20:45, time: 0.512, data_time: 0.032, memory: 13758, loss: 1.5580, grad_norm: 1.1997
2023-11-08 14:22:16,145 - mmcls - INFO - Epoch [177][100/131]	lr: 4.263e-05, eta: 0:19:53, time: 0.510, data_time: 0.031, memory: 13758, loss: 1.5648, grad_norm: 1.1829
2023-11-08 14:23:21,924 - mmcls - INFO - Epoch [178][100/131]	lr: 3.991e-05, eta: 0:19:02, time: 0.513, data_time: 0.032, memory: 13758, loss: 1.4621, grad_norm: 1.2011
2023-11-08 14:24:28,152 - mmcls - INFO - Epoch [179][100/131]	lr: 3.731e-05, eta: 0:18:11, time: 0.514, data_time: 0.031, memory: 13758, loss: 1.4844, grad_norm: 1.1676
2023-11-08 14:25:34,295 - mmcls - INFO - Epoch [180][100/131]	lr: 3.482e-05, eta: 0:17:19, time: 0.513, data_time: 0.032, memory: 13758, loss: 1.4879, grad_norm: 1.2408
2023-11-08 14:25:57,579 - mmcls - INFO - Epoch(val) [180][53]	accuracy_top-1: 98.9433, accuracy_top-2: 99.4717
2023-11-08 14:26:48,797 - mmcls - INFO - Epoch [181][100/131]	lr: 3.244e-05, eta: 0:16:28, time: 0.512, data_time: 0.030, memory: 13758, loss: 1.5450, grad_norm: 1.2029
2023-11-08 14:27:55,087 - mmcls - INFO - Epoch [182][100/131]	lr: 3.019e-05, eta: 0:15:36, time: 0.515, data_time: 0.031, memory: 13758, loss: 1.5160, grad_norm: 1.2525
2023-11-08 14:29:01,229 - mmcls - INFO - Epoch [183][100/131]	lr: 2.805e-05, eta: 0:14:45, time: 0.513, data_time: 0.031, memory: 13758, loss: 1.4849, grad_norm: 1.2464
2023-11-08 14:30:07,429 - mmcls - INFO - Epoch [184][100/131]	lr: 2.603e-05, eta: 0:13:54, time: 0.514, data_time: 0.032, memory: 13758, loss: 1.5193, grad_norm: 1.2683
2023-11-08 14:31:13,693 - mmcls - INFO - Epoch [185][100/131]	lr: 2.412e-05, eta: 0:13:02, time: 0.515, data_time: 0.033, memory: 13758, loss: 1.5911, grad_norm: 1.3541
2023-11-08 14:32:19,980 - mmcls - INFO - Epoch [186][100/131]	lr: 2.234e-05, eta: 0:12:11, time: 0.515, data_time: 0.033, memory: 13758, loss: 1.4427, grad_norm: 1.2432
2023-11-08 14:33:26,165 - mmcls - INFO - Epoch [187][100/131]	lr: 2.067e-05, eta: 0:11:20, time: 0.514, data_time: 0.033, memory: 13758, loss: 1.4739, grad_norm: 1.2327
2023-11-08 14:34:32,541 - mmcls - INFO - Epoch [188][100/131]	lr: 1.913e-05, eta: 0:10:28, time: 0.516, data_time: 0.032, memory: 13758, loss: 1.5245, grad_norm: 1.2650
2023-11-08 14:35:38,744 - mmcls - INFO - Epoch [189][100/131]	lr: 1.770e-05, eta: 0:09:37, time: 0.514, data_time: 0.032, memory: 13758, loss: 1.5220, grad_norm: 1.2456
2023-11-08 14:36:44,852 - mmcls - INFO - Epoch [190][100/131]	lr: 1.639e-05, eta: 0:08:45, time: 0.513, data_time: 0.031, memory: 13758, loss: 1.4842, grad_norm: 1.2277
2023-11-08 14:37:08,302 - mmcls - INFO - Epoch(val) [190][53]	accuracy_top-1: 98.9914, accuracy_top-2: 99.4877
2023-11-08 14:37:59,936 - mmcls - INFO - Epoch [191][100/131]	lr: 1.521e-05, eta: 0:07:54, time: 0.516, data_time: 0.033, memory: 13758, loss: 1.5085, grad_norm: 1.2664
2023-11-08 14:39:06,339 - mmcls - INFO - Epoch [192][100/131]	lr: 1.414e-05, eta: 0:07:03, time: 0.515, data_time: 0.033, memory: 13758, loss: 1.5168, grad_norm: 1.2716
2023-11-08 14:40:12,405 - mmcls - INFO - Epoch [193][100/131]	lr: 1.320e-05, eta: 0:06:11, time: 0.512, data_time: 0.032, memory: 13758, loss: 1.5287, grad_norm: 1.2744
2023-11-08 14:41:18,741 - mmcls - INFO - Epoch [194][100/131]	lr: 1.238e-05, eta: 0:05:20, time: 0.515, data_time: 0.032, memory: 13758, loss: 1.4956, grad_norm: 1.2081
2023-11-08 14:42:24,831 - mmcls - INFO - Epoch [195][100/131]	lr: 1.168e-05, eta: 0:04:29, time: 0.513, data_time: 0.032, memory: 13758, loss: 1.5344, grad_norm: 1.2663
2023-11-08 14:43:31,088 - mmcls - INFO - Epoch [196][100/131]	lr: 1.110e-05, eta: 0:03:37, time: 0.515, data_time: 0.031, memory: 13758, loss: 1.4882, grad_norm: 1.2553
2023-11-08 14:44:37,417 - mmcls - INFO - Epoch [197][100/131]	lr: 1.064e-05, eta: 0:02:46, time: 0.515, data_time: 0.032, memory: 13758, loss: 1.4903, grad_norm: 1.2545
2023-11-08 14:45:43,639 - mmcls - INFO - Epoch [198][100/131]	lr: 1.031e-05, eta: 0:01:54, time: 0.514, data_time: 0.032, memory: 13758, loss: 1.5309, grad_norm: 1.2358
2023-11-08 14:46:49,579 - mmcls - INFO - Epoch [199][100/131]	lr: 1.009e-05, eta: 0:01:03, time: 0.512, data_time: 0.031, memory: 13758, loss: 1.5013, grad_norm: 1.3211
2023-11-08 14:47:55,341 - mmcls - INFO - Epoch [200][100/131]	lr: 1.000e-05, eta: 0:00:12, time: 0.510, data_time: 0.031, memory: 13758, loss: 1.4560, grad_norm: 1.2998
2023-11-08 14:48:10,090 - mmcls - INFO - Saving checkpoint at 200 epochs
2023-11-08 14:48:19,491 - mmcls - INFO - Epoch(val) [200][53]	accuracy_top-1: 98.9914, accuracy_top-2: 99.5037
